{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Chapter 17*<br> Thermodynamic Simulations & Feynman Path Integrals \n",
    "\n",
    "| | | |\n",
    "|:---:|:---:|:---:|\n",
    "| ![image](Figs/Cover.png)|[From **COMPUTATIONAL PHYSICS**, 3rd Ed, 2015](http://physics.oregonstate.edu/~rubin/Books/CPbook/index.html) <br>RH Landau, MJ Paez, and CC Bordeianu (deceased) <br>Copyrights: <br> [Wiley-VCH, Berlin;](http://www.wiley-vch.de/publish/en/books/ISBN3-527-41315-4/) and [Wiley & Sons, New York](http://www.wiley.com/WileyCDA/WileyTitle/productCd-3527413154.html)<br>  R Landau, Oregon State Unv, <br>MJ Paez, Univ Antioquia,<br> C Bordeianu, Univ Bucharest, 2015.<br> Support by National Science Foundation.|![image](Figs/BackCover.png)|\n",
    "\n",
    "**17 Thermodynamic Simulations & Feynman Path Integrals**<br>\n",
    "[17.1 Magnets via Metropolis Algorithm](#17.1)<br>\n",
    "[17.2 An Ising Chain (Model)](#17.2)<br>\n",
    "[17.3 Statistical Mechanics (Theory)](#17.3)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[17.3.1 Analytic Solution](#17.3.1)<br>\n",
    "[17.4 Metropolis Algorithm](#17.4)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[17.4.1 Metropolis Algorithm Implementation](#17.4.1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[17.4.2 Equilibration, Thermodynamic Properties](#17.4.2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[17.4.3 Beyond Nearest Neighbors, 1-D (Exploration)](#17.4.3)<br>\n",
    "[17.5 Magnets viaWang-Landau Sampling](#17.5)<br>\n",
    "[17.6 Wang-Landau Algorithm](#17.6)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[17.6.1 Ising Model Implementation](#17.6.1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[17.6.2 Assessment](#17.6.2)<br>\n",
    "[17.7 Feynman Path Integral Quantum Mechanics](#17.7)<br>\n",
    "[17.8 Feynman’s Space-Time Propagation (Theory)](#17.8)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[17.8.1 Bound-State Wave Function (Theory)](#17.8.1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[17.8.2 Lattice Path Integration (Algorithm)](#17.8.2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[17.8.3 Lattice Implementation](#17.8.3)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[17.8.4 Assessment and Exploration](#17.8.4)<br>\n",
    "[17.9 Exploration: Quantum Bouncer’s Paths](#17.9)<br>\n",
    "\n",
    "*This chapter describes how magnetic materials can be simulated by\n",
    "applying the Metropolis algorithm to the Ising model. This extends the\n",
    "Monte Carlo techniques studied in [Chapter 4](CP04.ipynb) now to include\n",
    "now thermodynamics. Not only do thermodynamic simulations have important\n",
    "practical applications, but they also give us insight into what is\n",
    "“dynamic” in thermodynamics. Towards the middle of the chapter we\n",
    "describe a recent Monte Carlo algorithm known as Wang-Landau sampling\n",
    "that has shown itself to be far more efficient than the 60-\n",
    "plus-year-old Metropolis algorithm. Wang-Landau sampling is an active\n",
    "subject in present research, and it is nice to see it fitting well into\n",
    "an elementary textbook. We end the chapter by applying the Metropolis\n",
    "algorithm to Feynman’s path integral formulation of quantum mechanics\n",
    "\\[[Feynman & Hibbs(65)](BiblioLinked.html#feyn)\\]. The theory, while the most advanced to be found\n",
    "in this book, forms the basis for field-theoretic computations of\n",
    "quantum chromodynamics, some of the most fundamental and most\n",
    "time-consuming computations in existence. Basic discussions can be found\n",
    "in \\[[Mannheim(83)](BiblioLinked.html#man), [MacKeown(85)](BiblioLinked.html#mac2), [MacKeown & Newman(87)](BiblioLinked.html#mac)\\], with a recent\n",
    "review in \\[[Potvin(93)](BiblioLinked.html#potvin)\\].*\n",
    "\n",
    "** This Chapter’s Lecture, Slide Web Links, Applets & Animations**\n",
    "\n",
    "| | |\n",
    "|---|---|\n",
    "|[All Lectures](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/index.html)|[![anything](Figs/RHLlectureMod4.png)](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/index.html)|\n",
    "\n",
    "| <span>*Lecture (Flash)*</span>| *Slides* | *Sections*|<span>*Lecture (Flash)*</span>| *Slides* | *Sections*|  \n",
    "|- - -|:- - -:|:- - -:|- - -|:- - -:|:- - -:|\n",
    "|[Ising Model Magnets](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Ising/Ising.html)|[pdf](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pdf/Ising_NEW.pdf)|15.1-.6 |[Feynman Quantum Paths I](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Path_I/Path_I.html)|[pdf](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pdf/FeynmanPath_05Mar09.pdf)| 15.7 |\n",
    "| [Feynman Quantum Paths II](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Path_II/Path_II.html)|[pdf](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pdf/FeynmanPath_05Mar09.pdf)| 15.8| [Feynman Path Applet](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Applets/index.html)|-|15.7-15.8|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17.1  Magnets via Metropolis Algorithm <a id=\"17.1\"></a>\n",
    "\n",
    "Ferromagnets contain finite-size *domains* in which the spins of all the\n",
    "atoms point in the same direction. When an external magnetic field is\n",
    "applied to these materials, the different domains align and the\n",
    "materials become “magnetized.” Yet as the temperature is raised, the\n",
    "total magnetism decreases, and at the Curie temperature the system goes\n",
    "through a *phase transition* beyond which all magnetization vanishes.\n",
    "Your **problem** is to explain the thermal behavior of ferromagnets.\n",
    "\n",
    "## 17.2  An Ising Chain (Model) <a id=\"17.2\"></a>\n",
    "\n",
    "As our model we consider $N$ magnetic dipoles fixed in place on the\n",
    "links of a linear chain (Figure 17.1). (It is a straightforward\n",
    "generalization to handle 2-D and 3-D lattices.) Because the particles\n",
    "are fixed, their positions and momenta are not dynamic variables, and we\n",
    "need worry only about their spins. We assume that the particle at site\n",
    "$i$ has spin $s_{i}$, which is either up or down:\n",
    "\n",
    "$$\\tag*{17.1} s_{i} \\equiv s_{z,i} = \\pm \\frac{1}{2}.$$\n",
    "\n",
    "Each configuration of the $N$ particles is described by a quantum state\n",
    "vector\n",
    "\n",
    "$$\\tag*{17.2}\n",
    "\\left|alpha_{j}\\right \\rangle   = \\left|s_{1}, s_{2}, \\ldots ,\n",
    "s_{N} \\right \\rangle = \\left\\{\\pm\\frac{1}{2},\n",
    "  \\pm\\frac{1}{2},   \\ldots \\right\\}, \\quad\n",
    "j=1,\\ldots, 2^{N}.$$\n",
    "\n",
    "Because the spin of each particle can assume any one of *two* values,\n",
    "there are $2^{N}$ different possible states for the $N$ particles in the\n",
    "system. Because fixed particles cannot be interchanged, we do not need\n",
    "to concern ourselves with the symmetry of the wave function.\n",
    "\n",
    "![image](Figs/Fig17_1.png)\n",
    "\n",
    "**Figure 17.1** The 1-D lattice of $\\textit{N}$ spins used in the Ising model of\n",
    "magnetism. The interaction energy between nearest-neighbor pairs $\\textit{E} =\n",
    "\\pm \\textit{J}$ is shown for aligned and opposing spins.\n",
    "\n",
    "The energy of the system arises from the interaction of the spins with\n",
    "each other and with the external magnetic field $B$. We know from\n",
    "quantum mechanics that an electron’s spin and magnetic moment are\n",
    "proportional to each other, so a magnetic <span>*dipole-dipole*</span>\n",
    "interaction is equivalent to a <span>*spin-spin*</span> interaction. We\n",
    "assume that each dipole interacts with the external magnetic field and\n",
    "with its nearest neighbor through the potential:\n",
    "\n",
    "$$\\tag*{17.3} V_{i} = - J\\textbf{s}_{i}\\cdot\\textbf{s}_{i+1} - g \\mu_b\n",
    "\\textbf{s}_{i}\\cdot \\textbf{B}.$$\n",
    "\n",
    "Here the constant $J$ is called the *exchange energy* and is a measure\n",
    "of the strength of the spin-spin interaction. The constant $g$ is the\n",
    "gyromagnetic ratio, that is, the proportionality constant between a\n",
    "particle’s angular momentum and magnetic moment. The constant\n",
    "$\\mu_b = e\\hbar/(2m_ec)$ is the Bohr magneton, the basic measure for\n",
    "magnetic moments.\n",
    "\n",
    "Even for small numbers of particles, the $2^{N}$ possible spin\n",
    "configurations gets to be very large ($2^{20} > 10^6$), and it is\n",
    "expensive for the computer to examine them all. Realistic samples with\n",
    "${\\sim}10^{23}$ particles are beyond imagination. Consequently,\n",
    "statistical approaches are usually assumed, even for moderate values of\n",
    "$N$. Just how large $N$ must be for this to be accurate is one of the\n",
    "things we want you to explore with your simulations.\n",
    "\n",
    "The energy of this system in state $\\alpha_k$ is the expectation value\n",
    "of the sum of the potential $V$ over the spins of the particles:\n",
    "\n",
    "$$\\tag*{17.4} E_{\\alpha_k} = \\Big\\langle \\alpha_k \\Big|sum_{i}V_{i}\n",
    "\\Big|alpha_k \\Big\\rangle = -J \\sum_{i=1}^{N-1} s_{i}s_{i+1} - B\n",
    "\\mu_b\\sum_{i=1}^{N} s_{i}.$$\n",
    "\n",
    "An apparent paradox in the Ising model occurs when we turn off the\n",
    "external magnetic field and thereby eliminate a preferred direction in\n",
    "space.This means that the average magnetization should vanish despite\n",
    "the fact that the lowest energy state would have all spins aligned. The\n",
    "answer to this paradox is that the system with $B=0$ is unstable; even\n",
    "if all the spins are aligned, there is nothing to stop their spontaneous\n",
    "reversal. The instabilities are a type of Bloch-wall transitions in\n",
    "which regions of different spin orientations change size. Indeed,\n",
    "natural magnetic materials have multiple domains with all the spins\n",
    "aligned, but with the different domains pointing in different\n",
    "directions.\n",
    "\n",
    "For simplicity we assume $B=0$, which means that there are just spin-spin\n",
    "interactions. However, be cognizant of the fact that this means there is no\n",
    "preferred direction in space, and so you may have to be careful how you\n",
    "calculate observables when averaging over domains. For example, you may need\n",
    "to take an absolute value of the total spin when calculating the magnetization,\n",
    "that is, to calculate $\\langle \\left | \\sum_i s_{i}\\right|rangle$ rather than\n",
    "$\\langle \\sum_i s_{i}\\rangle$.\n",
    "\n",
    "The equilibrium alignment of the spins depends critically on the sign of\n",
    "the exchange energy $J$. If $J>0$, the lowest energy state will tend to\n",
    "have neighboring spins aligned. If the temperature is low enough, the\n",
    "ground state will be a *ferromagnet* with all the spins aligned. Yet if\n",
    "$J<0$, the lowest energy state will tend to have neighbors with opposite\n",
    "spins. If the temperature is low enough, the ground state will be a\n",
    "*antiferromagnet* with alternating spins.\n",
    "\n",
    "The simple 1-D Ising model has its limitations. Although the model is\n",
    "accurate in describing a system in thermal equilibrium, it is not\n",
    "accurate in describing the *approach* to thermal equilibrium. Second, we\n",
    "have postulated that only one spin is flipped at a time, while real\n",
    "magnetic materials tend to flip many spins at a time. Other limitations\n",
    "are straightforward to improve, for example, the addition of\n",
    "longer-range interactions than just nearest neighbors, the motion of the\n",
    "centers, higher-multiplicity spin states, and extension to two and three\n",
    "dimensions.\n",
    "\n",
    "A fascinating aspect of magnetic materials is the existence of a\n",
    "critical temperature, the *Curie temperature*, above which the gross\n",
    "magnetization essentially vanishes. Below the Curie temperature the\n",
    "system is in a quantum state with macroscopic order; above the Curie\n",
    "temperature there is only short-range order extending over atomic\n",
    "dimensions. Although the 1-D Ising model predicts realistic temperature\n",
    "dependences for the thermodynamic quantities, the model is too simple to\n",
    "support a phase transition. However, the 2-D and 3-D Ising models do\n",
    "support the Curie temperature phase transition \\[[Yang(52)](BiblioLinked.html#Yang)\\].\n",
    "\n",
    "## 17.3  Statistical Mechanics (Theory) <a id=\"17.3\"></a>\n",
    "\n",
    "Statistical mechanics starts with the elementary interactions among a\n",
    "system’s particles and constructs the macroscopic thermodynamic\n",
    "properties such as specific heats. The essential assumption is that all\n",
    "configurations of the system consistent with the constraints are\n",
    "possible. In some simulations, such as the molecular dynamics ones in\n",
    "[Chapter 18, *Molecular Dynamics Simulations*](CP18.ipynb), the problem\n",
    "is set up such that the *energy* of the system is fixed. The states of\n",
    "this type of system are described by what is called a *microcanonical\n",
    "ensemble*.In contrast, for the thermodynamic simulations we study in\n",
    "this chapter, the temperature, volume, and number of particles remain\n",
    "fixed, and so we have what is called a *canonical ensemble*.\n",
    "\n",
    "When we say that an object is *at* temperature $T$, we mean that the\n",
    "object’s atoms are in thermodynamic equilibrium with an average kinetic\n",
    "energy proportional to $T$. Although this may be an equilibrium state,\n",
    "it is also a dynamic one in which the object’s energy fluctuates as it\n",
    "exchanges energy with its environment (it is thermo*dynamics* after\n",
    "all). Indeed, one of the most illuminating aspects of the simulation to\n",
    "follow its visualization of the continual and random interchange of\n",
    "energy that occurs at equilibrium.\n",
    "\n",
    "The energy $E_{\\alpha_j}$ of state $\\alpha_{j}$ in a canonical ensemble\n",
    "is not constant but is distributed with probabilities $P(\\alpha_{j})$\n",
    "given by the Boltzmann distribution:\n",
    "\n",
    "$$\\tag*{17.5}\n",
    " {\\cal P}(E_{\\alpha_{j}},T)= \\frac{e^{-E_{\\alpha_j}/k_BT}}\n",
    "{Z(T)},\\quad Z(T)=\n",
    "\\sum_{\\alpha_{j}}e^{-E_{\\alpha_j}/k_BT}.$$\n",
    "\n",
    "Here $k$ is Boltzmann’s constant, $T$ the temperature, and $Z(T)$ the\n",
    "partition function, a weighted sum over the individual *states* or\n",
    "*configurations* of the system. Another formulation, such as the\n",
    "Wang-Landau algorithm discussed in § 17.5, sums over the *energies* of\n",
    "the states of the system and includes a density-of-states factor\n",
    "$g(E_i)$ to account for degenerate states with the same energy. While\n",
    "the present sum over states is a simpler way to express the problem (one\n",
    "less function), we shall see that the sum over energies is more\n",
    "efficient numerically. In fact, we are even able to ignore the partition\n",
    "function $Z(T)$ because it cancels out in our forming the *ratio* of\n",
    "probabilities.\n",
    "\n",
    "### 17.3.1  Analytic Solution<a id=\"17.3.1\"></a>\n",
    "\n",
    "For very large numbers of particles, the thermodynamic properties of the 1-D\n",
    "Ising model can be solved analytically and yields \\[Plischke & B. Bergersen(94)\\]\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.6}\n",
    "&\\displaystyle U = \\langle E \\rangle &\\\\\n",
    " &\\displaystyle  \\frac{U}{J} = - N \\tanh \\frac{J}{k_BT} =\n",
    "-N\\frac{e^{J/k_BT} -e^{-J/k_BT}}{e^{J/k_BT}+e^{-J/k_BT}}   =\n",
    "\\begin{cases}\n",
    "   N, &   k_BT\\rightarrow 0 ,\\\\\n",
    "   0, &   k_BT\\rightarrow \\infty .\\end{cases}&\\tag*{17.7}\\end{align}$$\n",
    "\n",
    "The analytic results for the specific heat per particle and the magnetization are\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.8}\n",
    "C(k_BT) & = \\frac{1}{N} \\frac{dU}{dT}= \\frac{(J/k_BT)^{2}} {\\cosh^{2}(J/k_BT)} \\\\\n",
    "M(k_BT) & = \\frac{N e^{J/k_BT}\\sinh (B/k_BT)}{\n",
    "\\sqrt{e^{2J/k_BT}\\sinh^2(B/k_BT) + e^{-2J/k_BT}} } .\\tag*{17.9}\\end{align}$$\n",
    "\n",
    "The **2-D Ising model** has an analytic solution, but it is not easy to derive it\n",
    "\\[Yang(52), Huang(87)\\]. Whereas the internal energy and heat capacity are\n",
    "expressed in terms of elliptic integrals, the spontaneous magnetization per\n",
    "particle has the simple form \n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.10}\n",
    " {\\cal M}(T) &=\\begin{cases} 0, &  T>T_c\\\\\n",
    "   \\frac{(1+z^2)^{1/4}(1-6z^2+z^4)^{1/8}} {\\sqrt{1-z^2}}, &   T<T_c\n",
    "   ,\\end{cases}\\\\\n",
    "k T_c &\\simeq 2.269185 J, \\quad z= e^{-2J/k_BT},\\tag*{17.11}\\end{align}$$\n",
    "\n",
    "where the temperature is measured in units of the Curie temperature $T_c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.4  Metropolis Algorithm <a id=\"17.4\"></a>\n",
    "\n",
    "In trying to devise an algorithm that simulates thermal equilibrium, it\n",
    "is important to understand that the Boltzmann distribution (17.5) does\n",
    "not require a system to remain always in the state of lowest energy, but\n",
    "says that it is less likely for the system to be found in a\n",
    "higher-energy state than in a lower-energy one. Of course, as\n",
    "$T \\rightarrow 0$ only the lowest energy state will be populated. For\n",
    "finite temperatures we expect the energy to fluctuate by approximately\n",
    "$k_BT$ about the equilibrium value.\n",
    "\n",
    "In their simulation of neutron transmission through matter, Metropolis,\n",
    "Rosenbluth, Teller, and Teller \\[[Metropolis et al.(53)](BiblioLinked.html#metrop)\\] invented an\n",
    "algorithm to improve the Monte Carlo calculation of averages. This\n",
    "*Metropolis algorithm* is now a cornerstone of computational physics\n",
    "because the sequence of configurations it produces (a *Markov chain*)\n",
    "accurately simulates the fluctuations that occur during thermal\n",
    "equilibrium. The algorithm randomly changes the individual spins such\n",
    "that, on the average, the probability of a configuration occurring\n",
    "follows a Boltzmann distribution. (We do not find the proof\n",
    "illuminating.)\n",
    "\n",
    "The Metropolis algorithm is a combination of the variance reduction\n",
    "technique discussed in §5.19 and the von Neumann rejection technique\n",
    "discussed in § 5.21. There we showed how to make Monte Carlo integration\n",
    "more efficient by sampling random points predominantly where the\n",
    "integrand is large and how to generate random points with an arbitrary\n",
    "probability distribution. Now we would like to have spins flip randomly,\n",
    "have a system that can reach any energy in a finite number of steps\n",
    "(*ergodic* sampling), and have a distribution of energies described by a\n",
    "Boltzmann distribution, yet have systems that equilibrate quickly enough\n",
    "to compute in reasonable times.\n",
    "\n",
    "The Metropolis algorithm is implemented via a number of steps. We start\n",
    "with a fixed temperature and an initial spin configuration, and apply\n",
    "the algorithm until a thermal equilibrium is reached (equilibration).\n",
    "Continued application of the algorithm generates the statistical\n",
    "fluctuations about equilibrium from which we deduce the thermodynamic\n",
    "quantities such as the magnetization $M(T)$. Then the temperature is\n",
    "changed, and the whole process is repeated in order to deduce the $T$\n",
    "dependence of the thermodynamic quantities. The accuracy of the deduced\n",
    "temperature dependences provides convincing evidence of the validity of\n",
    "the algorithm. Because the $2^N$ possible configurations of $N$\n",
    "particles can be a very large number, the amount of computer time needed\n",
    "can be very long. Typically, a small number of iterations $\\simeq\\! 10N$\n",
    "is adequate for equilibration.\n",
    "\n",
    "The explicit steps of the Metropolis algorithm are:\n",
    "\n",
    "1.  Start with an arbitrary spin configuration $\\alpha_{k}=\\{s_1,\n",
    "    s_2, \\ldots, s_N\\}$.\n",
    "\n",
    "2.  Generate a trial configuration $\\alpha_{k+1}$ by\n",
    "\n",
    "    -   picking a particle $i$ randomly and\n",
    "\n",
    "    -   flipping its spin.\\[*Note:* Large-scale, practical computations\n",
    "        make a full sweep in which every spin is updated once, and then\n",
    "        use this as the new trial configuration. This is found to be\n",
    "        efficient and useful in removing some autocorrelations.\\]\n",
    "\n",
    "3.  Calculate the energy $E_{\\alpha_{\\text{tr}}}$ of the\n",
    "    trial configuration.\n",
    "\n",
    "4.  If $E_{\\alpha_{\\text{tr}}} \\leq E_{\\alpha_{k}}$, accept the trial by\n",
    "    setting $\\alpha_{k+1} = \\alpha_{\\text{tr}}$.\n",
    "\n",
    "5.  If $E_{\\alpha_{\\text{tr}}} > E_{\\alpha_{k}}$, accept with relative\n",
    "    probability $ {\\cal R} = \\exp(-\\Delta E/k_BT)$:\n",
    "\n",
    "    -   Choose a uniform random number $0 \\leq r_i \\leq\n",
    "           1$.\\\n",
    "\n",
    "    -   Set $\\alpha_{k+1} = \\begin{cases}\n",
    "        \\alpha_{\\text{tr}}, & \\mbox{if} \\ \\  {\\cal R} \\geq r_j  \\ \\\n",
    "        \\mbox{(accept)},\\\\\n",
    "        \\alpha_{k}, & \\mbox{if}\\ \\  {\\cal R} < r_j \\ \\\n",
    "        \\mbox{(reject)}.\n",
    "        \\end{cases}$\n",
    "\n",
    "The heart of this algorithm is its generation of a random spin configuration\n",
    "$\\alpha_{j}$ (17.2) with probability \n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.12}\n",
    " {\\cal P}(E_{\\alpha_{j}},T) \\propto e^{-\n",
    "E_{\\alpha_j}/k_BT}.\\end{align}$$ \n",
    "\n",
    "The technique is a variation of von Neumann\n",
    "rejection (stone throwing) in which a random *trial* configuration is either\n",
    "accepted or rejected depending upon the value of the Boltzmann factor.\n",
    "Explicitly, the ratio of probabilities for a trial configuration of energy $E_t$ to\n",
    "that of an initial configuration of energy $E_i$ is\n",
    "\n",
    "$$\\tag*{17.13}\n",
    " {\\cal R} = \\frac{{\\cal P}_{\\text{tr}}} { {\\cal P}_i}\\ =\n",
    "e^{-\\Delta E/k_BT},\\quad   \\Delta E =\n",
    "E_{\\alpha_{\\text{tr}}}-E_{\\alpha_i}.$$\n",
    "\n",
    "If the trial configuration has a lower energy ($\\Delta E\\le 0$), the\n",
    "relative probability will be greater than 1 and we will accept the trial\n",
    "configuration as the new initial configuration without further ado.\n",
    "However, if the trial configuration has a higher energy\n",
    "($\\Delta E > 0$), we will not reject it out of hand, but instead accept\n",
    "it with relative probability $  {\\cal R} =\n",
    "\\exp(-\\Delta E/k_BT) <1$. To accept a configuration with a probability,\n",
    "we pick a uniform random number between $0$ and $1$, and if the\n",
    "probability is greater than this number, we accept the trial\n",
    "configuration; if the probability is smaller than the chosen random\n",
    "number, we reject it. (You can remember which way this goes by letting\n",
    "$E_{\\alpha_{\\text{tr}}}\\rightarrow \\infty$, in which case $\n",
    " {\\cal P} \\rightarrow 0$ and nothing is accepted.) When the trial\n",
    "configuration is rejected, the next configuration is identical to the\n",
    "preceding one.\n",
    "\n",
    "![image](Figs/Fig17_2.png)\n",
    "\n",
    "**Figure 17.2** An Ising model simulation on a 1-D lattice of 100 initially\n",
    "aligned spins (on the left). Up spins are indicated by circles, and down spins by\n",
    "blank spaces. Although the system starts with all up spins (a “cold” start), the\n",
    "system is seen to form domains of up and down spins as time progresses.\n",
    "\n",
    "How do you start? One possibility is to start with random values of the\n",
    "spins (a “hot” start). Another possibility (Figure 17.2) is a “cold”\n",
    "start in which you start with all spins parallel ($J>0$) or antiparallel\n",
    "($J<0$). In general, one tries to remove the importance of the starting\n",
    "configuration by letting the calculation run a while (${\\simeq}10N$\n",
    "rearrangements) before calculating the equilibrium thermodynamic\n",
    "quantities. You should get similar results for hot, cold, or arbitrary\n",
    "starts, and by taking their average you remove some of the statistical\n",
    "fluctuations.\n",
    "\n",
    "### 17.4.1  Metropolis Algorithm Implementation<a id=\"17.4.1\"></a>\n",
    "\n",
    "1.  Write a program that implements the Metropolis algorithm, that is,\n",
    "    that produces a new configuration $\\alpha_{k+1}$ from the present\n",
    "    configuration $\\alpha_{k}$. (Alternatively, use the program\n",
    "    `IsingViz.py` shown in Listing 17.1.)\n",
    "\n",
    "2.  Make the key data structure in your program an array `s[N]`\n",
    "    containing the values of the spins $s_{i}$. For debugging, print out\n",
    "    $+$ and $-$ to give the spin at each lattice point and examine the\n",
    "    pattern for different trial numbers.\n",
    "\n",
    "3.  The value for the exchange energy $J$ fixes the energy scale. Keep\n",
    "    it fixed at $J=1$. (You may also wish to study antiferromagnets with\n",
    "    $J=-1$, but first examine ferromagnets whose domains are easier\n",
    "    to understand.)\n",
    "\n",
    "4.  The thermal energy $k_BT$ is in units of $J$ and is the\n",
    "    independent variable. Use $k_BT=1$ for debugging.\n",
    "\n",
    "5.  Use periodic boundary conditions on your chain to minimize\n",
    "    end effects. This means that the chain is a circle with the first\n",
    "    and last spins adjacent to each other.\n",
    "\n",
    "6.  Try $N \\simeq 20$ for debugging, and larger values for\n",
    "    production runs.\n",
    "\n",
    "7.  Use the printout to check that the system equilibrates for\n",
    "\n",
    "    -   a totally ordered initial configuration (cold start); your\n",
    "        simulation should resemble Figure 17.2.\n",
    "\n",
    "    -   a random initial configuration (hot start)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.4.2  Equilibration, Thermodynamic Properties (Assessment)<a id=\"17.4.2\"></a>\n",
    "\n",
    "1.  Watch a chain of $N$ atoms attain thermal equilibrium when in\n",
    "    contact with a heat bath. At high temperatures, or for small numbers\n",
    "    of atoms, you should see large fluctuations, while at lower\n",
    "    temperatures you should see smaller fluctuations.\n",
    "\n",
    "2.  Look for evidence of instabilities in which there is a spontaneous\n",
    "    flipping of a large number of spins. This becomes more likely for\n",
    "    larger $k_BT$ values.\n",
    "\n",
    "3.  Note how at thermal equilibrium the system is still quite dynamic,\n",
    "    with spins flipping all the time. It is this energy exchange that\n",
    "    determines the thermodynamic properties.\n",
    "\n",
    "4.  You may well find that simulations at small $k_BT$ (say,\n",
    "    $k_BT \\simeq\n",
    "    0.1$ for $N=200$) are slow to equilibrate. Higher $k_BT$ values\n",
    "    equilibrate faster yet have larger fluctuations.\n",
    "\n",
    "5.  Observe the formation of domains and the effect they have on the\n",
    "    total energy. Regardless of the direction of spin within a domain,\n",
    "    the atom-atom interactions are attractive and so contribute negative\n",
    "    amounts to the energy of the system when aligned. However, the\n",
    "    $\\uparrow\\downarrow$ or $\\downarrow\\uparrow$ interactions between\n",
    "    domains contribute positive energy. Therefore you should expect a\n",
    "    more negative energy at lower temperatures where there are larger\n",
    "    and fewer domains.\n",
    "\n",
    "6.  Make a graph of average domain size\n",
    "    <span>*versus*</span> temperature.\n",
    "\n",
    "[**Listing 17.1  IsingViz.py** ]( http://www.science.oregonstate.edu/~rubin/Books/CPbook/Codes/PythonCodes/IsingViz.py)implements the Metropolis algorithm for a 1-D Ising chain.\n",
    "\n",
    "**Thermodynamic Properties:** For a given spin configuration $\\alpha_j$,\n",
    "the energy and magnetization are given by\n",
    "\n",
    "$$\\tag*{17.14} E_{\\alpha_j} = - J\\sum_{i=1} ^{N-1} s_{i}s_{i+1},\\quad {\\cal M}_{j}\n",
    "= \\sum_{i=1}^{N} s_{i}.$$\n",
    "\n",
    "The internal energy $U(T)$ is just the average value of the energy,\n",
    "\n",
    "$$\\tag*{17.15} U(T) = \\langle E \\rangle,$$\n",
    "\n",
    "where the average is taken over a system in equilibrium. At high\n",
    "temperatures we expect a random assortment of spins and so a vanishing\n",
    "magnetization. At low temperatures when all the spins are aligned, we\n",
    "expect ${\\cal M}$ to approach $N/2$. Although the specific heat can be\n",
    "computed from the elementary definition,\n",
    "\n",
    "$$\\tag*{17.16} C = \\frac{1}{N} \\frac{dU}{dT},$$\n",
    "\n",
    "the numerical differentiation may be inaccurate because $U$ has\n",
    "statistical fluctuations. A better way to calculate the specific heat is\n",
    "to first calculate the fluctuations in energy occurring during $M$\n",
    "trials and then determine the specific heat from the fluctuations:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.17}\n",
    "U_{2} & = \\frac{1} {M} \\sum_{t=1}^{M} (E_{t} )^{2},\\\\ \n",
    "C & = \\frac{1}{N^2}\\frac{U_{2} - (U)^{2}}{k_BT^{2}} =\n",
    "\\frac{1}{N^2} \\frac{\\langle E^2 \\rangle-\\langle E \\rangle^2}\n",
    "{k_BT^2}.\\tag*{17.18}\\end{align}$$\n",
    "\n",
    "![image](Figs/Fig17_3.png)\n",
    "\n",
    "**Figure 17.3** Simulation results from a     1-D Ising model of 100 spins. *Top:* energy and specific heat as\n",
    "    functions of temperature; *Bottom:* magnetization as a function    of temperature.\n",
    "\n",
    "1.  Extend your program to calculate the internal energy $U$ and the\n",
    "    magnetization ${\\cal M}$ for the chain. Do not recalculate entire\n",
    "    sums when only one spin changes.\n",
    "\n",
    "2.  Make sure to wait for your system to equilibrate before you\n",
    "    calculate thermodynamic quantities. (You can check that $U$ is\n",
    "    fluctuating about its average.) Your results should resemble\n",
    "    Figure 17.3.\n",
    "\n",
    "3.  Reduce statistical fluctuations by running the simulation a number\n",
    "    of times with different seeds and taking the average of the results.\n",
    "\n",
    "4.  The simulations you run for small $N$ may be realistic but may not\n",
    "    agree with statistical mechanics, which assumes $N\\simeq \\infty$\n",
    "    (you may assume that $N\\simeq 2000$ is close to infinity). Check\n",
    "    that agreement with the analytic results for the thermodynamic limit\n",
    "    is better for large $N$ than small $N$.\n",
    "\n",
    "5.  Check that the simulated thermodynamic quantities are independent of\n",
    "    initial conditions (within statistical uncertainties). In practice,\n",
    "    your cold and hot start results should agree.\n",
    "\n",
    "6.  Make a plot of the internal energy $U$ as a function of $k_BT$ and\n",
    "    compare it to the analytic result (17.56).\n",
    "\n",
    "7.  Make a plot of the magnetization ${\\cal M}$ as a function of $k_BT$\n",
    "    and compare it to the analytic result. Does this agree with how you\n",
    "    expect a heated magnet to behave?\n",
    "\n",
    "8.  Compute the energy fluctuations $U_{2}$ (17.17) and the specific\n",
    "    heat $C$ (17.18). Compare the simulated specific heat to the\n",
    "    analytic result (17.8).\n",
    "\n",
    "### 17.4.3  Beyond Nearest Neighbors, 1-D (Exploration)<a id=\"17.4.3\"></a>\n",
    "\n",
    "-   Extend the model so that the spin-spin interaction (17.3) extends to\n",
    "    next-nearest neighbors as well as nearest neighbors. For the\n",
    "    ferromagnetic case this should lead to more binding and less\n",
    "    fluctuation because we have increased the couplings among spins, and\n",
    "    thus increased the thermal inertia.\n",
    "\n",
    "-   Extend the model so that the ferromagnetic spin-spin\n",
    "    interaction (17.3) extends to nearest neighbors in two dimensions,\n",
    "    and for the truly ambitious, three dimensions. Continue using\n",
    "    periodic boundary conditions and keep the number of particles small,\n",
    "    at least to start with \\[[Gould et al.(06)](BiblioLinked.html#GTC)\\].\n",
    "\n",
    "1.  Form a square lattice and place $\\sqrt{N}$ spins on each side.\n",
    "\n",
    "2.  Examine the mean energy and magnetization as the\n",
    "    system equilibrates.\n",
    "\n",
    "3.  Is the temperature dependence of the average energy qualitatively\n",
    "    different from that of the 1-D model?\n",
    "\n",
    "4.  Make a print out of the spin configuration for small $N$, and\n",
    "    identify domains.\n",
    "\n",
    "5.  Once your system appears to be behaving properly, calculate the heat\n",
    "    capacity and magnetization of the 2-D Ising model with the same\n",
    "    technique used for the 1-D model. Use a total number of particles of\n",
    "    $100 \\leq N \\leq 2000$.\n",
    "\n",
    "6.  Look for a phase transition from ordered to unordered configurations\n",
    "    by examining the heat capacity and magnetization as functions\n",
    "    of temperature. The former should diverge, while the latter should\n",
    "    vanish at the phase transition (Figure 17.5).\n",
    "\n",
    "**Exercise:** Three fixed spin-$\\frac {1}{2}$ particles interact with\n",
    "each other at temperature $T =1/k_b$ such that the energy of the system\n",
    "is\n",
    "\n",
    "$$\\tag*{17.19} E = -(s_1 s_2 + s_2 s_3).$$\n",
    "\n",
    "The system starts in the configuration $\\uparrow\\downarrow\\uparrow$. Do a\n",
    "simulation by hand that uses the Metropolis algorithm and the series of random\n",
    "numbers 0.5, 0.1, 0.9, 0.3 to determine the results of just two thermal\n",
    "fluctuations of these three spins.\n",
    "\n",
    "|A|B|\n",
    "|:- - -:|:- - -:|\n",
    "|![image](Figs/Fig17_4a.png)|![image](Figs/Fig17_4b.png)|\n",
    "\n",
    "**Figure 17.4** Wang-Landau sampling used in the Ising model 2-D Ising model\n",
    "on an $8\\times 8$ lattice. *Top:* Logarithm of the density of states log\n",
    "$\\textit{g}(\\textit{E}) \\propto \\textit{S}$ *versus* the energy per particle.\n",
    "*Bottom:* The histogram $\\textit{H}(\\textit{E})$ showing the number of states\n",
    "visited as a function of the energy per particle. The aim of WLS is to make this\n",
    "function flat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.5 Magnets via Wang-Landau Sampling $\\odot$ <a id=\"17.5\"></a>\n",
    "\n",
    "We have used a Boltzmann distribution to simulate the thermal properties\n",
    "of an Ising model. We described the probabilities for explicit spin\n",
    "*states* $\\alpha$ with energy $E_{\\alpha}$ for a system at temperature\n",
    "$T$, and summed over various configurations. An equivalent formulation\n",
    "describes the probability that the system will have the explicit\n",
    "*energy* $E$ at temperature $T$:\n",
    "\n",
    "$$\\tag*{17.20} {\\cal P}(E_i,T)= g(E_i)\\ \\frac{e^{-E_i/k_BT}} {Z(T)}, \\quad\n",
    "   Z(T) =\\sum_{E_i} g(E_i)\\ e^{-E_i/k_BT}.$$\n",
    "\n",
    "Here $k_B$ is Boltzmann’s constant, $T$ is the temperature, $g(E_i)$ is\n",
    "the number of states of energy $E_i$ ($i=1,\\ldots, M$), $Z(T)$ is the\n",
    "partition function, and the sum is still over all $M$ states of the\n",
    "system, but now with states of the same energy entering just once owing\n",
    "to $g(E_i)$ accounting for their degeneracy. Because we again apply the\n",
    "theory to the Ising model with its discrete spin states, the energy\n",
    "assumes only discrete values. If the physical system had an energy that\n",
    "varied continuously, then the number of states in the interval $E\n",
    "\\rightarrow E + dE$ would be given by $g(E) dE$ and $g(E)$ would be\n",
    "called the *density of states*. As a matter of convenience, we call\n",
    "$g(E_i)$ the density of states even when dealing with discrete systems,\n",
    "although the term “degeneracy factor” may be more precise.\n",
    "\n",
    "Even as the Metropolis algorithm has been providing excellent service\n",
    "for more than 60 years, recent literature shows increasing use of\n",
    "Wang-Landau sampling (WLS) \\[*Note:* We thank Oscar A. Restrepo of the\n",
    "Universidad de Antioquia for letting us use some of his material here.\\]\n",
    "\\[[Landau & Wang(01)](BiblioLinked.html#WL), [Clark(11)](BiblioLinked.html#clark)\\]. Because WLS determines the density of\n",
    "states and the associated partition function, it is not a direct\n",
    "substitute for the Metropolis algorithm and its simulation of thermal\n",
    "fluctuations. However, we will see that WLS provides an equivalent\n",
    "simulation for the Ising model.\n",
    "\n",
    "The advantages of WLS is that it requires much shorter simulation times\n",
    "than the Metropolis algorithm and provides a direct determination of\n",
    "$g(E_i)$. For these reasons it has shown itself to be particularly\n",
    "useful for first-order phase transitions where systems spend long times\n",
    "trapped in metastable states, as well as in areas as diverse as spin\n",
    "systems, fluids, liquid crystals, polymers, and proteins. The time\n",
    "required for a simulation becomes crucial when large systems are\n",
    "modeled. Even a spin lattice as small as $8\\times 8$ has\n",
    "$2^{64}\\simeq 1.84\\times 10^{19}$ configurations, which makes visiting\n",
    "them all too expensive.\n",
    "\n",
    "![image](Figs/Fig17_5.png)\n",
    "\n",
    "**Figure 17.5** The energy, specific heat, and magnetization as a function of\n",
    "temperature from a 2-D Ising model simulation with 40,000 spins. Evidence of a\n",
    "phase transition at the Curie temperature $kT =\\simeq 2.5$ is seen in all three\n",
    "functions. The values of $\\textit{C}$ and $\\textit{E}$ have been scaled to fit on\n",
    "the same plot as $\\textit{M}$. (Courtesy of J. Wetzel.)\n",
    "\n",
    "In our discussion of the Ising model we ignored the partition function when\n",
    "applying the Metropolis algorithm. Now we focus on the partition function\n",
    "$Z(T)$ and the density-of-states function $g(E)$. Because $g(E)$ is a function of\n",
    "energy but not temperature, once it has been deduced, $Z(T)$ and all\n",
    "thermodynamic quantities can be calculated from it without having to repeat\n",
    "the simulation for each temperature. For example, the internal energy and the\n",
    "entropy are calculated directly as \n",
    "\n",
    "$$\\begin{align} \\tag*{17.21}\n",
    "U(T) & = \\left<E\\right> = \\frac{\\sum_{E_i} E_i g(E_i) e^{-E_i/k_BT}} {\\sum_{E_i}\n",
    "g(E_i) e^{-E_i/k_BT}},\\\\\n",
    " S &=  k_B \\ \\ln  g(E_i).\\tag*{17.22}\\end{align}$$ \n",
    " \n",
    "The density of\n",
    "states $g(E_i)$ will be determined by taking the equivalent of a random\n",
    "walk in *energy* space. We flip a randomly-chosen spin, record the\n",
    "energy of the new configuration, and then keep flipping more spins to\n",
    "change the energy. The table $H(E_i)$ of the number of times each energy\n",
    "$E_i$ is attained is called the energy *histogram* (Figure 17.4 right).\n",
    "If the walk were continued for a very long time, the histogram $H(E_i)$\n",
    "would converge to the density of states $g(E_i)$. Yet with\n",
    "$10^{19}\\mbox{-}10^{30}$ steps required even for small systems, this\n",
    "direct approach is unrealistically inefficient because the walk would\n",
    "rarely ever get away from the most probable energies.\n",
    "\n",
    "Clever idea number 1 behind the Wang-Landau algorithm is to explore more\n",
    "of the energy space by increasing the likelihood of walking into less\n",
    "probable configurations. This is carried out by increasing the\n",
    "acceptance of less likely configurations while simultaneously decreasing\n",
    "the acceptance of more likely ones. In other words, we want to accept\n",
    "more states for which the density $g(E_i)$ is small and reject more\n",
    "states for which $g(E_i)$ is large (fret not these words, the equations\n",
    "are simple). To accomplish this trick, we accept a new energy $E_i$ with\n",
    "a probability inversely proportional to the (initially unknown) density\n",
    "of states,\n",
    "\n",
    "$$\\tag*{17.23} {\\cal P}(E_i) = \\frac{1}{g(E_i)} ,$$\n",
    "\n",
    "and then build up a histogram of visited states via a random walk.\n",
    "\n",
    "The problem with clever idea number 1 is that $g(E_i)$ is unknown. WLS’s\n",
    "clever idea 2 is to determine the unknown $g(E_i)$ simultaneously with\n",
    "the construction of the random walk. This is accomplished by improving\n",
    "the value of $g(E_i)$ via the multiplication\n",
    "$g(E_i) \\rightarrow f g(E_i)$, where $f>1$ is an empirical factor. When\n",
    "this works, the resulting histogram $H(E_i)$ becomes “flatter” because\n",
    "making the small $g(E_i)$ values larger makes it more likely to reach\n",
    "states with small $g(E_i)$ values. As the histogram gets flatter, we\n",
    "keep decreasing the multiplicative factor $f$ until it is satisfactory\n",
    "close to 1. At that point we have a flat histogram and a determination\n",
    "of $g(E_i)$.\n",
    "\n",
    "At this point you may be asking yourself, “Why does a flat histogram\n",
    "mean that we have determined $g(E_i$)?” Flat means that all energies are\n",
    "visited equally, in contrast to the peaked histogram that would be\n",
    "obtained normally without the $1/g(E_i)$ weighting factor. Thus, if by\n",
    "including this weighting factor we produce a flat histogram, then we\n",
    "have perfectly counteracted the actual peaking in $g(E_i)$, which means\n",
    "that we have arrived at the correct $g(E_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.6  Wang-Landau Algorithm <a id=\"17.6\"></a>\n",
    "\n",
    "The steps in WLS are similar to those in the Metropolis algorithm, but\n",
    "now with use of the density-of-states function $g(E_i)$ rather than a\n",
    "Boltzmann factor:\n",
    "\n",
    "1.  Start with an arbitrary spin configuration\n",
    "    $\\alpha_{k}=\\{s_1,s_2, \\ldots, s_N\\}$ and with arbitrary values for\n",
    "    the density of states $g(E_{i})=1,\\ i=1,\\ldots, M$, where $M=2^N$ is\n",
    "    the number of states of the system.\n",
    "\n",
    "2.  Generate a trial configuration $\\alpha_{k+1}$ by\n",
    "\n",
    "    -   picking a particle $i$ randomly and\n",
    "\n",
    "    -   flipping $i$’s spin.\n",
    "\n",
    "3.  Calculate the energy $E_{\\alpha_{\\text{tr}}}$ of the\n",
    "    trial configuration.\n",
    "\n",
    "4.  If $g(E_{\\alpha_{\\text{tr}}}) \\leq g(E_{\\alpha_k}),$ accept the\n",
    "    trial, that is, set $\\alpha_{k+1} = \\alpha_{\\text{tr}}$.\n",
    "\n",
    "5.  If $g(E_{\\alpha_{\\text{tr}}}) > g(E_{\\alpha_k}),$ accept the trial\n",
    "    with probability ${\\cal P} = g(E_{\\alpha_k})/(g(E_{\\alpha\n",
    "    _{\\text{tr}}})$:\n",
    "\n",
    "    -   choose a uniform random number $0 \\leq r_i \\leq\n",
    "           1$.\n",
    "\n",
    "    -   set $\\alpha_{k+1} =\n",
    "        \\begin{cases}\n",
    "           \\alpha_{\\text{tr}}, & \\mbox{if} \\ \\ {\\cal P} \\geq r_j  \\ \\ \\mbox{(accept)},\\\\\n",
    "           \\alpha_{k}, & \\mbox{if}\\ \\ {\\cal P} < r_j \\ \\ \\mbox{(reject)}.\n",
    "        \\end{cases}$\n",
    "\n",
    "    This acceptance rule can be expressed succinctly as \n",
    "    \n",
    "    $$\\tag*{17.24}\n",
    "    {\\cal P}(E_{\\alpha_k} \\rightarrow E_{\\alpha_{\\text{tr}}})\n",
    "       = \\min\\!\\left[1, \\frac{g(E_{\\alpha_k})}{g(E_{\\alpha_{\\text{tr}}})}\\right],$$\n",
    "\n",
    "    which manifestly always accepts low-density (improbable) states.\n",
    "\n",
    "6.  One we have a new state, we modify the current density of states\n",
    "    $g(E_i)$ via the multiplicative factor $f$:\n",
    "\n",
    "    $$\\tag*{17.25}\n",
    "    g(E_{\\alpha_{k+1}}) \\rightarrow f\n",
    "    g(E_{\\alpha_{k+1}}),$$\n",
    "\n",
    "    and add 1 to the bin in the histogram corresponding to the new\n",
    "    energy:\n",
    "\n",
    "    $$\\tag*{17.26}\n",
    "       H(E_{\\alpha_{k+1}}) \\rightarrow H(E_{\\alpha_{k+1}}) +1.$$\n",
    "\n",
    "7.  The value of the multiplier $f$ is empirical. We start with Euler’s\n",
    "    number $f=e= 2.71828$, which appears to strike a good balance\n",
    "    between very large numbers of small steps (small $f$) and too rapid\n",
    "    a set of jumps through energy space (large $f$). Because the entropy\n",
    "    $S=k_B \\ln g(E_i)  \\rightarrow   k_B [\\ln  g(E_i)+ \\ln  f]$, (17.25)\n",
    "    corresponds to a uniform increase by $k_B$ in entropy.\n",
    "\n",
    "8.  Even with reasonable values for $f$, the repeated multiplications\n",
    "    in (17.25) lead to exponential growth in the magnitude of $g$. This\n",
    "    may cause floating-point overflows and a concordant loss of\n",
    "    information \\[in the end, the magnitude of $g(E_i)$ does not matter\n",
    "    because the function is normalized\\]. These overflows are avoided by\n",
    "    working with logarithms of the function values, in which case the\n",
    "    update of the density of states (17.25) becomes\n",
    "\n",
    "    $$\\tag*{17.27}\n",
    "       \\ln  g(E_i) \\rightarrow   \\ln  g(E_i) + \\ln  f.$$\n",
    "\n",
    "9.  The difficulty with storing $\\ln  g(E_i)$ is that we need the ratio\n",
    "    of $g(E_i)$ values to calculate the probability in (17.24). This is\n",
    "    circumvented by employing the identity $x \\equiv\n",
    "    \\exp(\\ln x)$ to express the ratio as\n",
    "\n",
    "    $$\\tag*{17.28}\n",
    "    \\frac{g(E_{\\alpha_k})} {g(E_{\\alpha_{\\text{tr}}})} = \\exp\\left[\\ln\n",
    "    \\frac{g(E_{\\alpha_k})} {g(E_{\\alpha_{\\text{tr}}})} \\right] =\n",
    "    \\exp\\left[\\ln  g(E_{\\alpha_k})\\right] -\n",
    "    \\exp\\left[\\ln g(E_{\\alpha_{\\text{tr}}})\\right] .$$\n",
    "\n",
    "    In turn, $g(E_k)= f\\times g(E_k)$ is modified to $\\ln\n",
    "    g(E_k)\\rightarrow \\ln  g(E_k) +\\ln f$.\n",
    "\n",
    "10. The random walk in $E_i$ continues until a flat histogram of visited\n",
    "    energy values is obtained. The flatness of the histogram is tested\n",
    "    regularly (every 10,000 iterations), and the walk is terminated once\n",
    "    the histogram is sufficiently flat. The value of $f$ is then reduced\n",
    "    so that the next walk provides a better approximation to $g(E_i)$.\n",
    "    Flatness is measured by comparing the variance in $H(E_i)$ to\n",
    "    its average. Although 90%-95% flatness can be achieved for small\n",
    "    problems like ours, we demand only 80% (Figure 17.4):\n",
    "\n",
    "    $$\\tag*{17.29}\n",
    "    \\mbox{If}\\quad \\frac{H_{\\text{max}}-H_{\\min}}{H_{\\text{max}}+H_{\\min}}<0.2,\n",
    "    \\mbox{stop,} \\ \\ \\mbox{let }\\ f \\rightarrow \\sqrt{f}  (\\ln  f \\rightarrow\n",
    "    \\ln f/2).$$\n",
    "\n",
    "11. Keep the generated $g(E_i)$ and reset the histogram values $h(E_i)$\n",
    "    to zero.\n",
    "\n",
    "12. The walks are terminated and new ones initiated until no significant\n",
    "    correction to the density of states is obtained. This is measured by\n",
    "    requiring the multiplicative factor $f\\simeq 1$ within some level of\n",
    "    tolerance, for example, $f\\leq 1+10^{-8}$. If the algorithm is\n",
    "    successful, the histogram should be flat (Figure 17.4) within the\n",
    "    bounds set by (17.29).\n",
    "\n",
    "13. The final step in the simulation is normalization of the deduced\n",
    "    density of states $g(E_i)$. For the Ising model with $N$ up or down\n",
    "    spins, a normalization condition follows from knowledge of the total\n",
    "    number of states \\[[Clark(11)](BiblioLinked.html#clark)\\]:\n",
    "\n",
    "    $$\\tag*{17.30}\n",
    "    \\sum_{E_i} g(E_i) = 2^N \\quad\\Rightarrow\\quad\n",
    "       g^{ \\mbox{(norm)}}(E_i)= \\frac{2^N}{\\sum_{E_i} g(E_i)} g(E_i).$$\n",
    "\n",
    "    Because the sum in (17.30) is most affected by those values of\n",
    "    energy where $g(E_i)$ is large, it may not be precise for the\n",
    "    low-$E_i$ densities that contribute little to the sum. Accordingly,\n",
    "    a more precise normalization, at least if your simulation has\n",
    "    performed a good job in occupying all energy states, is to require\n",
    "    that there are just two grounds states with energies $E\n",
    "    = -2N$ (one with all spins up and one with all spins down):\n",
    "\n",
    "    $$\\tag*{17.31}\n",
    "       \\sum_{E_i=-2N} g(E_i) = 2.$$\n",
    "\n",
    "    In either case it is good practice to normalize $g(E_i)$ with one\n",
    "    condition and then use the other as a check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### WangLandau.py, Notebook Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait ....\n",
      "(' iter ', 0, '   log(f) ', 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rubin Landau\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:74: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' iter ', 60000, '   log(f) ', 0.5)\n",
      "(' iter ', 100000, '   log(f) ', 0.25)\n",
      "(' iter ', 130000, '   log(f) ', 0.125)\n",
      "(' iter ', 180000, '   log(f) ', 0.0625)\n",
      "(' iter ', 240000, '   log(f) ', 0.03125)\n",
      "(' iter ', 300000, '   log(f) ', 0.015625)\n",
      "(' iter ', 390000, '   log(f) ', 0.0078125)\n",
      "(' iter ', 480000, '   log(f) ', 0.00390625)\n",
      "(' iter ', 650000, '   log(f) ', 0.001953125)\n"
     ]
    }
   ],
   "source": [
    "### WangLandau.py, Notebook Version,  for 2-D spins\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "L = 8\n",
    "N  = int(L*L)\n",
    "xx=2.0*arange(0,N+1)-N\n",
    "sp = zeros( (L, L) )                                               # Grid size, spins\n",
    "hist = zeros( (N + 1) )\n",
    "prhist = zeros( (N + 1) )                                                # Histograms\n",
    "S = zeros( (N + 1), float)                   # Entropy = log g(E)\n",
    "En=zeros((40),float)\n",
    "entrop=zeros((N),float)\n",
    "delt=zeros((N),float)\n",
    "def iE(e): \n",
    "    return int( (e + 2*N)/4)\n",
    "\n",
    "def IntEnergy():\n",
    "    exponent = 0.0  \n",
    "    ne=0\n",
    "    for T in arange (0.2, 8.2, 0.2 ):                             # Select lambda max\n",
    "        Ener = - 2*N\n",
    "        maxL = 0.0                                                       # Initialize\n",
    "        for i in range(0, N + 1):\n",
    "            if S[i]!= 0 and (S[i] - Ener/T)>maxL:\n",
    "                maxL = S[i] - Ener/T\n",
    "                Ener = Ener + 4\n",
    "        sumdeno  = 0\n",
    "        sumnume = 0\n",
    "        Ener = - 2*N\n",
    "        for i in range(0, N):\n",
    "            if S[i] != 0:\n",
    "                exponent = S[i] - Ener/T - maxL\n",
    "            sumnume   += Ener*exp(exponent)\n",
    "            sumdeno   += exp(exponent)\n",
    "            Ener = Ener +  4.0\n",
    "        U = sumnume/sumdeno/N  # internal energy U(T)/N\n",
    "        En[ne]=U\n",
    "        ne=ne+1  \n",
    "\n",
    "def WL():                    # Wang - Landau sampling\n",
    "    global yy,xx\n",
    "    Hinf = 1.e10             # initial values for Histogram\n",
    "    Hsup = 0.\n",
    "    tol = 1.e-3              # tolerance, stops the algorithm\n",
    "    ip = zeros(L)\n",
    "    im = zeros(L)                                             # BC R or down, L or up\n",
    "    height = abs(Hsup - Hinf)/2.                               # Initialize histogram\n",
    "    ave = (Hsup + Hinf) / 2. # about average of histogram\n",
    "    percent = height / ave  \n",
    "    for i in range(0, L):\n",
    "        for j in range(0, L): sp[i, j] = 1                            # Initial spins\n",
    "    for i in range(0, L):\n",
    "        ip[i] = i + 1\n",
    "        im[i] = i - 1                                             # Case plus, minus\n",
    "    ip[L - 1] = 0\n",
    "    im[0] = L - 1                                                           # Borders\n",
    "    Eold = - 2*N                                                  # Initialize energy\n",
    "    for  j in range(0, N + 1): S[j] = 0                         # Entropy initialized\n",
    "    iter = 0\n",
    "    fac = 1\n",
    "    while  fac > tol :\n",
    "        \n",
    "        # I don't see how to make this critical section run significantly faster:\n",
    "        i = int(N*random.random() )                             # Select random spin\n",
    "        xg = i%L\n",
    "        # Must be i//L, not i/L for Python 3:\n",
    "        yg = i//L           # Localize x, y, grid point\n",
    "        Enew = Eold + 2*(sp[ip[xg], yg] + sp[im[xg], yg] + sp[xg, ip[yg]] \n",
    "             + sp[xg, im[yg]] ) * sp[xg, yg]                          # Change energy\n",
    "        deltaS = S[iE(Enew)]  -  S[iE(Eold)]\n",
    "        if  deltaS <= 0 or random.random() < exp( - deltaS):\n",
    "            Eold = Enew; \n",
    "            sp[xg, yg] *=  - 1                                             # Flip spin\n",
    "        S[iE(Eold)]   += fac;                                        # Change entropy\n",
    "        \n",
    "        if iter%10000 == 0:     # Check flatness every 10000 sweeps\n",
    "            for j in range( 0, N + 1):\n",
    "                if  j == 0 :\n",
    "                    Hsup = 0\n",
    "                    Hinf = 1e10                              # Initialize new histogram\n",
    "                if  hist[j] == 0 : continue                     # Energies never visited\n",
    "                if  hist[j] > Hsup:\n",
    "                    Hsup = hist[j]\n",
    "                if  hist[j] < Hinf : Hinf = hist[j]\n",
    "            height = Hsup - Hinf\n",
    "            ave = Hsup + Hinf\n",
    "            percent = 1.0* height/ave   # 1.0 to make it float number\n",
    "            if percent < 0.3 :                                       # Histogram flat?\n",
    "                print(\" iter \", iter, \"   log(f) \", fac) \n",
    "                for j in range(0, N + 1):\n",
    "                    prhist[j] = hist[j]                                     # to plot\n",
    "                    hist[j] = 0                                           # Save hist\n",
    "                fac *= 0.5      # Equivalent to log(sqrt(f))\n",
    "        iter   += 1\n",
    "        hist[iE(Eold)]   += 1  # Change histogram, add 1, update\n",
    "        if fac >= 0.5:         # just show the first histogram\n",
    "            yy=0.025*hist\n",
    "\n",
    "print(\"wait ....\")                          # not always the same\n",
    "WL() \n",
    "fig=plt.figure()         # figure to plot (a changing line)\n",
    "ax = fig.add_subplot(111, autoscale_on=False,\\\n",
    "                     xlim=(-2, 2), ylim=(-5, 50.0))\n",
    "ax.grid()                                     # plot a grid\n",
    "plt.title(\"First Histogram H(E) vs E/N corresponds to log(f)=1\")\n",
    "plt.xlabel('E/N')\n",
    "for jj in range(0,N+1):\n",
    "    xx[jj]=-2+jj*4.0/(N+1)\n",
    "plt.plot(xx,yy)\n",
    "\n",
    "deltaS = 0.0\n",
    "ji=0\n",
    "for j in range(0, N + 1):\n",
    "    order = j*4  -  2*N\n",
    "    deltaS = S[j]  -  S[0] + log(2)\n",
    "    if S[j] != 0 :  \n",
    "        entrop[ji]=deltaS\n",
    "        delt[ji]=1.*order/N\n",
    "        ji+=1\n",
    "IntEnergy();\n",
    "fig1=plt.figure()         # figure to plot (a changing line)\n",
    "ax1 = fig1.add_subplot(2,1,1)\n",
    "ax1.grid()                                                                 # plot a grid\n",
    "plt.title(\"Energy vs T\")\n",
    "plt.xlabel('T')\n",
    "plt.ylabel('U(T)/N')\n",
    "T=arange (0.2, 8.2, 0.2 )  \n",
    "plt.plot(T,En)\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(delt,entrop)\n",
    "plt.title(\"Density of states\")\n",
    "plt.ylabel('log g(E)')\n",
    "plt.xlabel('E/N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.6.1  WLS Ising Model Implementation<a id=\"17.6.1\"></a>\n",
    "\n",
    "We assume an Ising model with spin-spin interactions between nearest\n",
    "neighbors located in an $L\\times L$ lattice (Figure 17.6). To keep the notation\n",
    "simple, we set $J=1$ so that \n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.32}\n",
    "E =- \\sum_{i \\leftrightarrow j}^{N}\\sigma_i\n",
    "\\sigma_j,\\end{align}$$ \n",
    "\n",
    "where $\\leftrightarrow$ indicates nearest\n",
    "neighbors. Rather than recalculate the energy each time a spin is\n",
    "flipped, only the difference in energy is computed. For example, for\n",
    "eight spins in a 1-D array,\n",
    "\n",
    "$$\\tag*{17.33} -E_{k}= \\sigma_0\\sigma_1\n",
    "+\\sigma_1\\sigma_2+\\sigma_2\\sigma_3+\\sigma_3\\sigma_4+\n",
    "\\sigma_4\\sigma_5+\\sigma_5\\sigma_6+\\sigma_6\\sigma_7\n",
    "+\\sigma_7\\sigma_0,$$\n",
    "\n",
    "where the 0-7 interaction arises because we assume periodic boundary\n",
    "conditions. If spin 5 is flipped, the new energy is\n",
    "\n",
    "$$\\tag*{17.34} -E_{k+1}= \\sigma_0\\sigma_1\n",
    "+\\sigma_1\\sigma_2+\\sigma_2\\sigma_3+\\sigma_3\\sigma_4-\n",
    "\\sigma_4\\sigma_5-\\sigma_5\\sigma_6+\\sigma_6\\sigma_7\n",
    "+\\sigma_7\\sigma_0,$$\n",
    "\n",
    "and the difference in energy is\n",
    "\n",
    "$$\\tag*{17.35}\n",
    "\\Delta E= E_{k+1}- E_{k}= 2 (\\sigma_4\n",
    "+\\sigma_6)\\sigma_5.$$\n",
    "\n",
    "This is cheaper to compute than calculating and then subtracting two\n",
    "energies.\n",
    "\n",
    "![image](Figs/Fig17_6.png)\n",
    "\n",
    "**Figure 17.6** The numbering scheme used in\n",
    "our WLS implementation of the 2-D Ising model with an $8\\times 8$\n",
    "lattice of spins.\n",
    "\n",
    "When we advance to two dimensions with the $8\\times 8$ lattice in\n",
    "Figure 17.6, the change in energy when a spin $\\sigma_{i,j}$ at site\n",
    "$(i,j)$ flips is\n",
    "\n",
    "$$\\tag*{17.36}\n",
    "\\Delta E = 2\n",
    "\\sigma_{i,j}(\\sigma_{i+1,j}+\\sigma_{i-1,j}+\\sigma_{i,j+1}+\\sigma_{i,j-1}),$$\n",
    "\n",
    "which can assume the values $-8, -4, 0, 4$, and 8. There are two states\n",
    "of minimum energy $E = -2N$ for a 2-D system with $N$ spins, and they\n",
    "are ones with all spins pointing in the same direction (either up or\n",
    "down). The maximum energy is $2N$, and it corresponds to alternating\n",
    "spin directions on neighboring sites. Each spin flip on the lattice\n",
    "changes the energy by four units between these limits, and so the values\n",
    "of the energies are\n",
    "\n",
    "$$\\tag*{17.37}\n",
    " E_i = -2N, \\quad -2N+4, \\quad -2N+8,   \\ldots,  \\ 2N-8, \\quad 2N- 4, \\quad 2N.$$\n",
    "\n",
    "These energies can be stored in a uniform 1-D array via the simple\n",
    "mapping\n",
    "\n",
    "$$\\tag*{17.38} E^\\prime = (E + 2N)/4 \\quad \\Rightarrow \\quad E^\\prime = 0,\\;\n",
    " 1, \\; 2,  \\ldots , \\; N.$$\n",
    "\n",
    "Listing 17.2 displays our implementation of Wang-Landau sampling to\n",
    "calculate the density of states and internal energy $U(T)$ (17.21). We\n",
    "used it to obtain the entropy $S(T)$ and the energy histogram $H(E_i)$\n",
    "illustrated in Figure 17.4. Other thermodynamic functions can be\n",
    "obtained by replacing the $E$ in (17.21) with the appropriate variable.\n",
    "The results look like those in Figure 17.5.\n",
    "\n",
    "A problem that may be encountered when calculating these variables is\n",
    "that the sums in (17.21) can become large enough to cause overflows,\n",
    "although the ratio would not. You work around that by factoring out a\n",
    "common large factor, for example,\n",
    "\n",
    "$$\\tag*{17.39}\n",
    "\\sum_{E_i} X(E_i)  g(E_i)  e^{-E_i/k_BT} =  e^\\lambda \\sum_{E_i}\n",
    " X(E_i)   e^{\\ln g(E_i)-E_i/k_BT-\\lambda},$$\n",
    "\n",
    "where $\\lambda$ is the largest value of $\\ln  g(E_i)-E_i/k_BT$ at each\n",
    "temperature. The factor $e^\\lambda$ does not actually need to be\n",
    "included in the calculation of the variable because it is present in\n",
    "both the numerator and denominator and so eventually cancels out.\n",
    "\n",
    "[**Listing 17.2  WangLandau.py**](http://www.science.oregonstate.edu/~rubin/Books/CPbook/Codes/PythonCodes/WangLandau.py) simulates the 2-D Ising model using\n",
    "Wang-Landau sampling to compute the density of states and from that the\n",
    "internal energy.\n",
    "\n",
    "### 17.6.2  WLS Ising Model Assessment<a id=\"17.6.2\"></a>\n",
    "\n",
    "Repeat the assessment conducted in § 17.4.2 for the thermodynamic\n",
    "properties of the Ising model using WLS in place of the Metropolis\n",
    "algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.7  Feynman Path Integral Quantum Mechanics $\\odot$ <a id=\"17.7\"></a>\n",
    "\n",
    "**Problem:** As is well known, a classical particle attached to a linear\n",
    "spring undergoes simple harmonic motion with a position as a function of\n",
    "time given by $x(t) = A\\sin(\\omega_0t+\\phi)$. Your **problem** is to\n",
    "take this classical space-time trajectory $x(t)$ and use it to generate\n",
    "the quantum wave function $\\psi(x,t)$ for a particle bound in a harmonic\n",
    "oscillator potential.\n",
    "\n",
    "## 17.8  Feynman’s Space-Time Propagation (Theory) <a id=\"17.8\"></a>\n",
    "\n",
    "| | |\n",
    "|---|---|\n",
    "|[![image](Figs/Javaapplet4.png)](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Applets/index.html) |[Feynman Path Integrals Applet](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Applets/index.html)|\n",
    "\n",
    "Feynman was looking for a formulation of quantum mechanics that gave a\n",
    "more direct connection to classical mechanics than does Schrödinger\n",
    "theory, and that made the statistical nature of quantum mechanics\n",
    "evident from the start. He followed a suggestion by Dirac that\n",
    "Hamilton’s principle of least action, which can be used to derive\n",
    "classical dynamics, may also be the $\\hbar\\rightarrow 0$ limit of a\n",
    "quantum least-action principle. Seeing that Hamilton’s principle deals\n",
    "with the paths of particles through space-time, Feynman postulated that\n",
    "the quantum-mechanical wave function describing the propagation of a\n",
    "free particle from the space-time point $a=(x_{a}$,$t_a$) to the point\n",
    "$b=(x_{b},\\; t_b$) can expressed as \\[[Feynman & Hibbs(65)](BiblioLinked.html#feyn),\n",
    "[Mannheim(83)](BiblioLinked.html#man)\\]:\n",
    "\n",
    "$$\\tag*{17.40}\n",
    "\\psi(x_b,t_b) = \\int dx_a   G(x_b,t_b;x_a,t_a) \\psi(x_a,t_a),$$\n",
    "\n",
    "where $G$ is the *Green’s function* or *propagator*\n",
    "\n",
    "$$\\tag*{17.41} G(x_b,t_b;x_a,t_a) \\equiv G(b,a) =\\sqrt{\\frac{m}{2\\pi i(t_b-t_a)}}\n",
    "\\exp \\left[{i\\frac{m(x_b-x_a)^2}{2(t_b-t_a)}}\\right].$$\n",
    "\n",
    "Equation (17.40) is a form of Huygens’s wavelet principle in which each\n",
    "point on the wavefront $\\psi(x_a,t_a)$ emits a spherical wavelet\n",
    "$G(b;a)$ that propagates forward in space and time. It states that the\n",
    "new wavefront $\\psi(x_b,t_b)$ is created by summation over and\n",
    "interference with all the other wavelets.\n",
    "\n",
    "![image](Figs/Fig17_7.png)\n",
    "\n",
    "**Figure 17.7** In the Feynman path-integral formulation of quantum\n",
    "mechanics a collection of paths connect the initial space-time point $A$ to the\n",
    "final point $B$. The solid line is the trajectory followed by a classical particle,\n",
    "while the dashed lines are additional paths sampled by a quantum particle. A\n",
    "classical particle somehow “knows” ahead of time that travel along the classical\n",
    "trajectory minimizes the action $S$.\n",
    "\n",
    "Feynman imagined that another way of interpreting (17.40) is as a form\n",
    "of Hamilton’s principle in which the probability amplitude, that is the\n",
    "wave function $\\psi$, for a particle to be at $B$ equals the sum over\n",
    "all *paths* through space-time originating at time $A$ and ending at $B$\n",
    "(Figure 17.7). This view incorporates the statistical nature of quantum\n",
    "mechanics by having different probabilities for travel along the\n",
    "different paths. All paths are possible, but some are more likely than\n",
    "others. (When you realize that Schrödinger theory solves for wave\n",
    "functions and considers paths a classical concept, you can appreciate\n",
    "how different it is from Feynman’s view.) The values for the\n",
    "probabilities of the paths derive from *Hamilton’s classical principle\n",
    "of least action*:\n",
    "\n",
    "> *The most general motion of a physical particle moving along the\n",
    "> classical trajectory $\\bar{x}(t)$ from time $t_a$ to $t_b$ is along a\n",
    "> path such that the action $S[\\bar{x}(t)]$ is an extremum:*\n",
    ">\n",
    "$$\\tag*{17.42}\n",
    "\\delta S[\\bar{x}(t)] = S[\\bar{x}(t)+ \\delta x(t)] - S[\\bar{x}(t)]  = 0,$$\n",
    ">\n",
    "> *with the paths constrained to pass through the endpoints:*\n",
    "\n",
    "$$\\delta (x_a) = \\delta(x_b)= 0.$$\n",
    "\n",
    "This formulation of classical mechanics, which is based on the calculus\n",
    "of variations, is equivalent to Newton’s differential equations if the\n",
    "action $S$ is taken as the line integral of the Lagrangian along the\n",
    "path:\n",
    "\n",
    "$$\\tag*{17.43} S[\\bar{x}(t)] = \\int_{t_a}^{t_b}dt L\\left[x(t),\n",
    "\\dot{x}(t)\\right],  \\quad L = T\\left[x,\n",
    "\\dot{x}\\right] - V[x].$$\n",
    "\n",
    "Here $T$ is the kinetic energy, $V$ is the potential energy,\n",
    "$\\dot{x}=dx/dt$, and square brackets indicate a *functional*\\[*Note:* A\n",
    "*functional* is a number whose value depends on the complete behavior of\n",
    "some function and not just on its behavior at one point. For example,\n",
    "the derivative $f'(x)$ depends on the value of $f$ at $x$, yet the\n",
    "integral $I[f]=\\int_a^bdx f(x)$ depends on the entire function, and is\n",
    "therefore a functional of $f$.\\] of the function $x(t)$ and\n",
    "$\\dot{x}(t)$.\n",
    "\n",
    "Feynman observed that the classical action for a free ($V=0$) particle,\n",
    "\n",
    "$$\\tag*{17.44} S[b,a] = \\frac{m}{2} \\left(\\dot{x}\\right)^2 (t_b-t_a) =\n",
    "\\frac{m}{2} \\frac{(x_b-x_a)^2}{t_b-t_a},$$\n",
    "\n",
    "is related to the free-particle propagator (17.41) by\n",
    "\n",
    "$$\\tag*{17.45} G(b,a) = \\sqrt{\\frac{m}{2\\pi i (t_b-t_a)}} e^{i S[b,a]/\\hbar}.$$\n",
    "\n",
    "This is the much sought-after connection between quantum mechanics and\n",
    "Hamilton’s principle. Feynman went on to postulate a reformulation of\n",
    "quantum mechanics that incorporated its statistical aspects by\n",
    "expressing $G(b,a)$ as the weighted sum over all *paths* connecting $a$\n",
    "to $b$,\n",
    "\n",
    "$$\\tag*{17.46}\n",
    "  G(b,a) = \\sum_{{\\rm paths}}\n",
    "e^{iS[b,a]/\\hbar}  \\quad \\mbox{(path integral)}.$$\n",
    "\n",
    "Here the classical action $S$ (17.43) is evaluated along different paths\n",
    "(Figure 17.7), and the exponential of the action is summed over paths.\n",
    "The sum (17.46) is called a *path integral* because it sums over actions\n",
    "$S[b,a]$, each of which is an integral (on the computer an integral and\n",
    "a sum are the same anyway).\n",
    "\n",
    "The essential connection between classical and quantum mechanics is the\n",
    "realization that in units of $\\hbar \\simeq 10^{-34} \\mbox{Js}$, the\n",
    "action is a very large number, $S/\\hbar \\geq 10^{20}$, and so even\n",
    "though all paths enter into the sum (17.46), the main contributions come\n",
    "from those paths adjacent to the classical trajectory $\\bar{x}$. In\n",
    "fact, because $S$ is an extremum for the classical trajectory, it is a\n",
    "constant to first order in the variation of paths, and so nearby paths\n",
    "have phases that vary smoothly and relatively slowly. In contrast, paths\n",
    "far from the classical trajectory are weighted by a rapidly oscillating\n",
    "$\\exp(iS/\\hbar)$, and when many are included they tend to cancel each\n",
    "other out. In the classical limit, $\\hbar \\rightarrow 0$, only the\n",
    "single classical trajectory contributes and (17.46) becomes Hamilton’s\n",
    "principle of least action! In Figure 17.8 we show an example of an\n",
    "actual trajectory used in path-integral calculations.\n",
    "\n",
    "![image](Figs/Fig17_8.png)\n",
    "\n",
    "**Figure 17.8** *Top:* The probability distribution for the harmonic oscillator\n",
    "ground state as determined with a path-integral calculation (the classical result\n",
    "has maxima at the two turning points). *Bottom:* A space-time quantum path\n",
    "resulting from applying the Metropolis algorithm.\n",
    "\n",
    "### 17.8.1  Bound-State Wave Function (Theory)<a id=\"17.8.1\"></a>\n",
    "\n",
    "Although you may be thinking that you have already seen enough\n",
    "expressions for the Green’s function, there is yet another one we need\n",
    "for our computation. Let us assume that the Hamiltonian operator\n",
    "$\\tilde{H}$ supports a spectrum of eigenfunctions,\n",
    "\n",
    "$$\\tag*{17.27}\n",
    "\\tilde{H}\\psi_n = E_n \\psi_n,$$\n",
    "\n",
    "each labeled by the index $n$. Because $\\tilde{H}$ is Hermitian, its\n",
    "wave functions form a complete orthonormal set in which we may expand a\n",
    "general solution:\n",
    "\n",
    "$$\\tag*{17.48}\n",
    "\\psi(x,t) = \\sum_{n=0}^{\\infty} c_{n}  e^{-iE_{n}t}\n",
    "\\psi_{n}(x), \\quad c_{n} = \\int_{-\\infty}^{+\\infty}dx\n",
    "\\psi_{n}^{*}(x)\\psi(x,t=0),$$\n",
    "\n",
    "where the value for the expansion coefficients $c_{n}$ follows from the\n",
    "orthonormality of the $\\psi_n$’s. If we substitute this $c_n$ back into\n",
    "the wave function expansion (17.48), we obtain the identity\n",
    "\n",
    "$$\\tag*{17.49}\n",
    "\\psi(x,t) = \\int_{-\\infty}^{+\\infty} dx_{0}  \\sum_{n}\n",
    "\\psi_{n}^{*}(x_{0}) \\psi_{n}(x) e^{-iE_{n}t}\n",
    "\\psi(x_{0},t=0).$$\n",
    "\n",
    "Comparison with (17.40) yields the eigenfunction expansion for $G$:\n",
    "\n",
    "$$\\tag*{17.50} G(x,t;x_{0},t_0=0) = \\sum_{n} \\psi_{n}^{*}(x_{0}) \\psi_{n}(x)\n",
    "e^{-iE_{n}t}.$$\n",
    "\n",
    "We relate this to the bound-state wave function (recall that our\n",
    "**problem** is to calculate that) by (1) requiring all paths to start\n",
    "and end at the space position $x_0=x$, (2) by taking $t_0=0$, and (3) by\n",
    "making an analytic continuation of (17.50) to negative imaginary time\n",
    "(permissable for analytic functions):\n",
    "\n",
    "$$\\tag*{17.51} G(x,-i\\tau;x,0) = \\sum_{n}\\left|\\psi_{n}(x)\\right|^2 e^{-E_{n}\\tau} =\n",
    "\\left|\\psi_{0}\\right|^2 e^{-E_{0}\\tau} + \\left|\\psi_{1}\\right|^2 e^{-E_{1}\\tau} +\\cdots,$$\n",
    "\n",
    "$$\\tag*{17.52}\n",
    " \\boxed{\\Rightarrow \\quad  \\left|\\psi_{0}(x)\\right|^{2} =\n",
    "\\lim_{\\tau \\rightarrow \\infty}\n",
    "e^{E_{0}\\tau}G(x,-i\\tau;x,0) . }$$\n",
    "\n",
    "The limit here corresponds to long imaginary times $\\tau$, after which\n",
    "the parts of $\\psi$ with higher energies decay more quickly, leaving\n",
    "only the ground state $\\psi_{0}$.\n",
    "\n",
    "Equation (17.52) provides a closed-form solution for the ground-state\n",
    "wave function directly in terms of the propagator $G$. Although we will\n",
    "soon describe how to compute this equation, look now at Figure 17.8\n",
    "showing some results of a computation. Although we start with a\n",
    "probability distribution that peaks near the classical turning points at\n",
    "the edges of the well, after a large number of iterations we end up with\n",
    "a distribution that resembles the expected Gaussian, which indicates\n",
    "that the formulation appears to be working. On the right we see a\n",
    "trajectory that has been generated via statistical variations about the\n",
    "classical trajectory $x(t)\n",
    "=A\\sin(\\omega_0t+\\phi)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.8.2  Lattice Path Integration (Algorithm)<a id=\"17.8.2\"></a>\n",
    "\n",
    "Because both time and space need to be integrated over when evaluating a path\n",
    "integral, our simulation starts with a lattice of discrete space-time points. We\n",
    "visualize a particle’s trajectory as a series of straight lines connecting one time\n",
    "to the next (Figure 17.9). We divide the time between points $A$ and $B$ into\n",
    "$N$ equal steps of size $\\varepsilon$, and label them with the index $j$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.53}\n",
    " \\varepsilon  =  \\frac{t_b-t_a}{N}\\ \\Rightarrow \\  t_j  = t_a +\n",
    "j\\varepsilon \\quad (j=0, N).\\end{align}$$\n",
    "\n",
    "Although it is more precise to use the\n",
    "actual positions $x(t_j)$ of the trajectory at the times $t_j$ to determine the\n",
    "$x_j$’s (as in Figure 17.9), in practice we discretize space uniformly and have\n",
    "the links end at the nearest regular points. Once we have a lattice, it is easy to\n",
    "evaluate derivatives or integrals on a link\\[*Note:* Although Euler’s rule has a\n",
    "large error, it is often use in lattice calculations because of its simplicity.\n",
    "However, if the Lagrangian contains second derivatives, you should use the\n",
    "more precise central-difference method to avoid singularities.\\]:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.55}\n",
    "\\frac{dx_j}{dt} & \\simeq   \\frac{x_j -x_{j-1}}{t_j -t_{j-1}} =\n",
    "\\frac{x_j -x_{j-1}}{\\varepsilon},\\\\\n",
    "S_j & \\simeq L_j \\Delta t \\simeq \\frac{1}{2} m \\frac{(x_j -x_{j-1})^2}{\\varepsilon}\n",
    "- V(x_j)\\varepsilon,\\end{align}$$\n",
    "\n",
    "where we have assumed that the Lagrangian is\n",
    "constant over each link.\n",
    "\n",
    "|A |B |\n",
    "|:- - -:|:- - -:|\n",
    "|![image](Figs/Fig17_9a.png)|![image](Figs/Fig17_9b.png)|\n",
    "\n",
    "**Figure 17.9** *Top:* A path through a space-time lattice that starts and ends\n",
    "at $\\textit{x = x}_\\textit{a}=\\textit{x}_\\textit{b}.$ The action is an integral over\n",
    "this path, while the *path integral* is a sum of integrals over all paths. The\n",
    "dotted path $\\textit{BD}$ is a transposed replica of path $\\textit{AC}$.\n",
    "*Bottom:* The dashed path joins the initial and final times in two equal time\n",
    "steps; the solid curve uses $\\textit{N}$ steps each of size $\\varepsilon$. The\n",
    "position of the curve at time $\\textit{t}_\\textit{j}$ defines the position\n",
    "$\\textit{x}_\\textit{j}$.\n",
    "\n",
    "Lattice path integration is based on the *composition theorem* for\n",
    "propagators:\n",
    "\n",
    "$$\\tag*{17.56} G(b,a) = \\int dx_j G(x_b,t_b;x_j,t_j) G(x_j,t_j;x_a,t_a) \\quad (t_a\n",
    "<t_j, t_j < t_b).$$\n",
    "\n",
    "For a free particle this yields\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.57}\n",
    "G(b,a) & = \\sqrt{\\frac{m}{2\\pi i (t_b-t_j)}} \\sqrt{\\frac{m}{2\\pi i(t_j-t_a)}} \\int dx_j\n",
    "e^{i(S[b,j]+S[j,a])} \\\\\n",
    "   & =  \\sqrt{\\frac{m}{2\\pi i (t_b-t_a)}}\\int dx_j  e^{iS[b,a]},\\end{align}$$\n",
    "\n",
    "where we have added the actions because line integrals combine as $\n",
    "S[b,j] + S[j,a] =S[b,a]$. For the $N$-linked path in Figure 17.9,\n",
    "equation (17.56) becomes\n",
    "\n",
    "$$\\tag*{17.58} G(b,a) = \\int dx_1\\cdots dx_{N-1} e^{iS[b,a]} , \\quad S[b,a] =\n",
    "\\sum_{j=1}^N S_j,$$\n",
    "\n",
    "where $S_j$ is the value of the action for link $j$. At this point the\n",
    "integral over the *single* path shown in Figure 17.9 has become an\n",
    "$N$-term sum that becomes an infinite sum as the time step $\\varepsilon$\n",
    "approaches zero.\n",
    "\n",
    "To summarize, Feynman’s path-integral postulate (17.46) means that we\n",
    "sum over all paths connecting $A$ to $B$ to obtain the Green’s function\n",
    "$G(b,a)$. This means that we must sum not only over the links in one\n",
    "path but *also* over all the different paths in order to produce the\n",
    "variation in paths required by Hamilton’s principle. The sum is\n",
    "constrained such that paths must pass through $A$ and $B$ and cannot\n",
    "double back on themselves (causality requires that particles move only\n",
    "forward in time). This is the essence of *path integration*. Because we\n",
    "are integrating over functions as well as along paths, the technique is\n",
    "also known as *functional integration*.\n",
    "\n",
    "The propagator (17.46) is the sum over all paths connecting $A$ to $B$, with\n",
    "each path weighted by the exponential of the action along that path, explicitly:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.59}\n",
    "G(x,t;x_{0},t_{0}) & = \\sum \\int dx_{1} dx_{2} \\cdots dx_{N-1} e^{i\n",
    "S[x,x_{0}]},\\\\\n",
    "S[x,x_{0}] & = \\sum_{j=1}^{N-1} S[x_{j+1},x_j] \\simeq\n",
    "\\sum_{j=1}^{N-1} L\\left(x_j, \\dot{x_j}\\right)\\varepsilon,\\tag*{17.60}\\end{align}$$\n",
    "\n",
    "where $L(x_j, \\dot{x_j})$ is the average value of the Lagrangian on link $j$ at\n",
    "time $t=j\\varepsilon$. The computation is made simpler by assuming that the\n",
    "potential $V(x)$ is independent of velocity and does not depend on other $x$\n",
    "values (local potential). Next we observe that $G$ is evaluated with a negative\n",
    "imaginary time in the expression (17.52) for the ground-state wave function.\n",
    "Accordingly, we evaluate the Lagrangian with $t=-i\\tau$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.61}\n",
    "L\\left(x, \\dot{x}\\right) = T - V(x) &= +\\frac{1}{2} m\n",
    "\\left(\\frac{dx}{dt}\\right)^{2} -  V(x),\\\\\n",
    "\\Rightarrow\\quad  L\\left(x, \\frac{dx} {-id\\tau}\\right) &=\n",
    "-\\frac{1}{2}m \\left(\\frac{dx}{d\\tau}\\right)^{2} - V(x).\\tag*{17.62}\\end{align}$$\n",
    "\n",
    "We see that the reversal of the sign of the kinetic energy in $L$ means that $L$\n",
    "now equals the negative of the Hamiltonian evaluated at a real positive time\n",
    "$t=\\tau$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.63}\n",
    "H\\left(x,\\frac{dx}{d\\tau}\\right) &= \\frac{1}{2}m\n",
    "\\left(\\frac{dx}{d\\tau}\\right)^{2} + V(x) = E,\\\\\n",
    " \\Rightarrow \\quad\n",
    "L\\left(x, \\frac{dx} { -id\\tau}\\right) &= -H\\left(x, \\frac{dx} {\n",
    "d\\tau}\\right).\\tag*{17.64}\\end{align}$$\n",
    "\n",
    "In this way we rewrite the $t$-path\n",
    "integral of $L$ as a $\\tau$-path integral of $H$, and so express the action and\n",
    "Green’s function in terms of the Hamiltonian:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.65}\n",
    "S[j+1, j] & =  \\int_{t_{j}}^{t_{j+1}} \\! \\! L(x,t)  dt   =    -i\n",
    "\\int_{\\tau_{j}}^{\\tau_{j+1}}\\!\\! H(x,\\tau)  d\\tau,\\\\\n",
    "\\Rightarrow \\quad G(x,-i\\tau;x_{0},0) & =   \\int dx_{1}\\ldots\n",
    "dx_{N-1} e^{-\\int_0^{\\tau} H(\\tau') d\\tau'} ,\\tag*{17.66}\\end{align}$$\n",
    "\n",
    "where\n",
    "the line integral of $H$ is over an entire trajectory. Next we express the path\n",
    "integral in terms of the average energy of the particle on each link,\n",
    "$E_j=T_j+V_j$, and then sum over links to obtain the summed energy $ {\\cal\n",
    "E}$\\[*Note:* In some cases, such as for an infinite square well, this can cause\n",
    "problems if the trial link causes the energy to be infinite. In that case, one can\n",
    "modify the algorithm to use the potential at the beginning of a link\\]:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.67}\n",
    "&\\int \\! H(\\tau)  d\\tau  \\simeq  \\sum_j \\varepsilon E_j =\n",
    "\\varepsilon {\\cal E}(\\{x_j\\}),&\\\\\n",
    "&{\\cal E}(\\{x_j\\})  =   \\sum_{j=1}^{N}\n",
    "\\left[\\frac{m}{2}\\left(\\frac{ x_{j}-x_{j-1}\n",
    "}{\\varepsilon}\\right)^{2} +V\\left( \\frac{x_{j}+x_{j-1}}{2}\\right)\n",
    "\\right].&\\tag*{17.68}\\end{align}$$\n",
    "\n",
    "In (17.68) we have approximated each\n",
    "path link as a *straight line*, used Euler’s derivative rule to obtain the velocity,\n",
    "and evaluated the potential at the midpoint of each link. We now substitute this\n",
    "$G$ into our solution (17.52) for the ground-state wave function in which the\n",
    "initial and final points in space are the same:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\lim_{\\tau \\rightarrow \\infty}\\frac{ G(x,-i\\tau, x_{0}=x, 0)}{\\int\n",
    "dx G(x,-i\\tau, x_{0}=x, 0)} & = \\frac{\\int dx_{1}\\cdots dx_{N-1}\n",
    "\\exp\\left[-\\int_{0}^{\\tau} H d\\tau'\\right]}{\\int dx dx_{1}\\cdots dx_{N-1}\n",
    "\\exp\\left[-\\int_{0}^{\\tau} H d\\tau'\\right]}\\tag*{17.69} \\\\\n",
    "\\Rightarrow\\quad \\left|\\psi_{0}(x)\\right|^{2} & =  \\frac{1}{Z}\n",
    "\\lim_{\\tau \\rightarrow \\infty} \\int dx_{1}\\cdots dx_{N-1}\n",
    "e^{-\\varepsilon {\\cal E}}, \\\\\n",
    "Z & = \\lim_{\\tau \\rightarrow \\infty} \\int dx\n",
    "dx_{1}\\cdots dx_{N-1} e^{-\\varepsilon {\\cal E}}.\\tag*{17.70}\\end{align}$$\n",
    "\n",
    "The\n",
    "similarity of these expressions to thermodynamics, even with a partition\n",
    "function $Z$, is no accident; by making the time parameter of quantum\n",
    "mechanics imaginary, we have converted the time-dependent Schrödinger\n",
    "equation to the heat diffusion equation:\n",
    "\n",
    "$$\\tag*{17.71} i \\frac{\\partial \\psi} {\\partial (-i\\tau)} =\n",
    "\\frac{-\\nabla^2}{2m}\\psi\\quad \\Rightarrow\\quad\n",
    "   \\frac{\\partial \\psi} {\\partial \\tau } =  \\frac{ \\nabla^2} { 2m}\\psi.$$\n",
    "\n",
    "It is not surprising then that the sum over paths in Green’s function\n",
    "has each path weighted by the Boltzmann factor ${\\cal P}\n",
    "\\ = \\ e^{-\\varepsilon  {\\cal E}}$ usually associated with\n",
    "thermodynamics. We make the connection complete by identifying the\n",
    "temperature with the inverse time step:\n",
    "\n",
    "$$\\begin{align}\n",
    " {\\cal P}  =  e^{-\\varepsilon  {\\cal\n",
    "E}} = e^{- {\\cal E}/k_{B}T}\\quad \\Rightarrow\\quad\n",
    "k_{B}T = \\frac{1}{\\varepsilon} \\equiv\n",
    "\\frac{\\hbar}{\\varepsilon}.\\tag*{17.72}\\end{align}$$\n",
    "\n",
    "Consequently, the\n",
    "$\\varepsilon \\rightarrow 0$ limit, which makes time continuous, is a\n",
    "“high-temperature” limit. The $\\tau\\rightarrow\\infty$ limit, which is\n",
    "required to project the ground-state wave function, means that we must\n",
    "integrate over a path that is long in imaginary time, that is, long\n",
    "compared to a typical time $\\hbar/  \\Delta E$. Just as our simulation of\n",
    "the Ising model required us to wait a long time for the system to\n",
    "equilibrate, so the present simulation requires us to wait a long time\n",
    "so that all but the ground-state wave function has decayed. Alas, this\n",
    "is the solution to our **problem** of finding the ground-state wave\n",
    "function.\n",
    "\n",
    "To summarize, we have expressed the Green’s function as a path integral\n",
    "that requires integration of the Hamiltonian along paths and a summation\n",
    "over all the paths (17.69). We evaluate this path integral as the sum\n",
    "over all the trajectories in a space-time lattice. Each trial path\n",
    "occurs with a probability based on its action, and we use the Metropolis\n",
    "algorithm to include statistical fluctuation in the links, as if they\n",
    "are in thermal equilibrium. This is similar to our work with the Ising\n",
    "model, however now, rather than reject or accept a *flip in spin* based\n",
    "on the change in energy, we reject or accept a *change in a link* based\n",
    "on the change in energy. The more iterations we let the algorithm run\n",
    "for, the more time the deduced wave function has to equilibrate to the\n",
    "ground state.\n",
    "\n",
    "In general, Monte-Carlo Green’s function techniques work best if we\n",
    "start with a good guess at the correct answer, and then have the\n",
    "algorithm calculate variations on our guess. For the present problem\n",
    "this means that if we start with a path in space-time close to the\n",
    "classical trajectory, the algorithm may be expected to do a good job at\n",
    "simulating the quantum fluctuations about the classical trajectory.\n",
    "However, it does not appear to be good at finding the classical\n",
    "trajectory from arbitrary locations in space-time. We suspect that the\n",
    "latter arises from $\\delta S/\\hbar$ being so large that the weighting\n",
    "factor $\\exp(\\delta S/\\hbar)$ fluctuates wildly (essentially averaging\n",
    "out to zero) and so loses its sensitivity.\n",
    "\n",
    "#### A Time-Saving Trick\n",
    "\n",
    "As we have formulated the computation, we pick a value of $x$ and perform an\n",
    "expensive computation of line integrals over all space and time to obtain\n",
    "$\\left|psi_0(x)\\right|^2$ at one $x$. To obtain the wave function at another\n",
    "$x$, the entire simulation must be repeated from scratch. Rather than go\n",
    "through all that trouble again and again, we will compute the entire $x$\n",
    "dependence of the wave function in one fell swoop. The trick is to insert a delta\n",
    "function into the probability integral (17.69), thereby fixing the initial position\n",
    "to be $x_0$, and then to integrate over all values for $x_0$: \n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.73}\n",
    "\\left|\\psi_{0}(x)\\right|^{2}  & =  \\int dx_{1}\\cdots dx_{N}\n",
    " e^{-\\varepsilon   {\\cal E}(x,x_{1},\\ldots)}\\\\\n",
    "& =  \\int dx_{0} \\cdots dx_{N} \\delta(x-x_{0})   e^{-\\varepsilon\n",
    " {\\cal E}(x,x_{1},\\ldots)}. \\tag*{17.74}\\end{align}$$\n",
    " \n",
    "This equation\n",
    "expresses the wave function as an average of a delta function over all paths, a\n",
    "procedure that might appear totally inappropriate for numerical computation\n",
    "because there is tremendous error in representing a singular function on a\n",
    "finite-word-length computer. Yet when we simulate the sum over all paths with\n",
    "(17.74), there will always be some $x$ value for which the integral is nonzero,\n",
    "and we need to accumulate only the solution for various (discrete) $x$ values to\n",
    "determine $|psi_0(x)|^2$ for all $x$.\n",
    "\n",
    "To understand how this works in practice, consider path $AB$ in Figure 17.9 for\n",
    "which we have just calculated the summed energy. We form a new path by\n",
    "having one point on the chain jump to point $C$ (which changes two links). If\n",
    "we replicate section $AC$ and use it as the extension $AD$ to form the top\n",
    "path, we see that the path $CBD$ has the same summed energy (action) as path\n",
    "$ACB$, and in this way can be used to determine $|psi(x_j')|^2$. That being the\n",
    "case, once the system is equilibrated, we determine new values of the wave\n",
    "function at new locations $x_j'$ by flipping links to new values and calculating\n",
    "new actions. The more frequently some $x_j$ is accepted, the greater the wave\n",
    "function at that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.8.3  Lattice Implementation<a id=\"17.8.3\"></a>\n",
    "\n",
    "The program `QMC.py` in Listing 17.3 evaluates the integral (17.46) by\n",
    "finding the average of the integrand $\\delta(x_{0}-x)$ with paths\n",
    "distributed according to the weighting function\n",
    "$\\exp[-\\varepsilon  {\\cal E}(x_{0},\n",
    "x_{1},\\ldots,x_{N})]$. The physics enters via (17.76), the calculation\n",
    "of the summed energy $ {\\cal E}(x_{0},x_{1},\n",
    "\\ldots,x_{N})$. We evaluate the action integral for the harmonic\n",
    "oscillator potential \n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.75}\n",
    "V(x) = \\frac{1}{2} x^2,\\end{align}$$ \n",
    "\n",
    "and for a particle of mass $m=1$. Using a\n",
    "convenient set of natural units, we measure lengths in $\\sqrt{1/m\\omega}\n",
    "\\equiv \\sqrt{\\hbar/m\\omega}=1$ and times in $1/\\omega=1$. Correspondingly, the\n",
    "oscillator has a period $T=2\\pi$. Figure 17.8 shows results from an\n",
    "application of the Metropolis algorithm. In this computation we started\n",
    "with an initial path close to the classical trajectory and then examined\n",
    "a half million variations about this path. All paths are constrained to\n",
    "begin and end at $x=1$ (which turns out to be somewhat less than the\n",
    "maximum amplitude of the classical oscillation). \n",
    "\n",
    "When the time\n",
    "difference $t_b-t_a$ equals a short time like $2T$, the system has not\n",
    "had enough time to equilibrate to its ground state and the wave function\n",
    "looks like the probability distribution of an excited state (nearly\n",
    "classical with the probability highest for the particle to be near its\n",
    "turning points where its velocity vanishes). However, when $t_b-t_a$\n",
    "equals the longer time $20T$, the system has had enough time to decay to\n",
    "its ground state and the wave function looks like the expected Gaussian\n",
    "distribution. In either case (Figure 17.8 right), the trajectory through\n",
    "space-time fluctuates about the classical trajectory. This fluctuation\n",
    "is a consequence of the Metropolis algorithm occasionally going uphill\n",
    "in its search; if you modify the program so that searches go only\n",
    "downhill, the space-time trajectory will be a very smooth trigonometric\n",
    "function (the classical trajectory), but the wave function, which is a\n",
    "measure of the fluctuations about the classical trajectory, will vanish!\n",
    "The explicit steps of the calculation are \\[[MacKeown(85)](BiblioLinked.html#mac2), [MacKeown &\n",
    "Newman(87)](BiblioLinked.html#mac)\\]:\n",
    "\n",
    "1.  Construct a grid of $N$ time steps of length\n",
    "    $\\varepsilon$ (Figure 17.9). Start at $t=0$ and extend to time $\\tau\n",
    "    =N\\varepsilon$ \\[this means $N$ time intervals and $(N+1)$ lattice\n",
    "    points in time\\]. Note that time always increases monotonically\n",
    "    along a path.\n",
    "\n",
    "2.  Construct a grid of $M$ space points separated by steps of size\n",
    "    $\\delta$. Use a range of $x$ values several time larger than the\n",
    "    characteristic size or range of the potential being used and start\n",
    "    with $M \\simeq N$.\n",
    "\n",
    "3.  When calculating the wave function, any $x$ or $t$ value falling\n",
    "    between lattice points should be assigned to the closest\n",
    "    lattice point.\n",
    "\n",
    "4.  Associate a position $x_{j}$ with each time $\\tau_{j}$, subject to\n",
    "    the boundary conditions that the initial and final positions always\n",
    "    remain the same, $x_{N}=x_{0}=x$.\n",
    "\n",
    "5.  Choose a path of straight-line links connecting the lattice points\n",
    "    corresponding to the classical trajectory. Observe that the $x$\n",
    "    values for the links of the path may have values that increase,\n",
    "    decrease, or remain unchanged (in contrast to time, which\n",
    "    always increases).\n",
    "\n",
    "6.  Evaluate the energy $ {\\cal E}$ by summing the kinetic and potential\n",
    "    energies for each link of the path starting at $j=0$:\n",
    "\n",
    "    $$\\tag*{17.76}\n",
    "     {\\cal E}(x_{0},x_{1}, \\ldots, x_{N}) \\simeq \\sum_{j=1}^{N}\n",
    "    \\left[ \\frac{m}{2} \\left(\\frac{x_{j}-x_{j-1}}{\\varepsilon}\n",
    "    \\right)^{2} + V\\left(\\frac{x_{j}+x_{j-1}}{2}\\right) \\right].$$\n",
    "\n",
    "7.  Begin a sequence of repetitive steps in which a random position\n",
    "    $x_{j}$ associated with time $t_j$ is changed to the position $x_j'$\n",
    "    (point $C$ in Figure 17.9). This changes *two* links in the path.\n",
    "\n",
    "8.  For the coordinate that is changed, use the Metropolis algorithm to\n",
    "    weigh the change with the Boltzmann factor.\n",
    "\n",
    "9.  For each lattice point, establish a running sum that represents the\n",
    "    value of the wave function squared at that point.\n",
    "\n",
    "10. After each single-link change (or decision not to change), increase\n",
    "    the running sum for the new $x$ value by $1$. After a sufficiently\n",
    "    long running time, the sum divided by the number of steps is the\n",
    "    simulated value for $|psi(x_{j})|^{2}$ at each lattice point\n",
    "    $x_{j}$.\n",
    "\n",
    "11. Repeat the entire link-changing simulation starting with a\n",
    "    different seed. The average wave function from a number of\n",
    "    intermediate-length runs is better than that from one very long run.\n",
    "\n",
    "[**Listing 17.3  QMC.py**](http://www.science.oregonstate.edu/~rubin/Books/CPbook/Codes/PythonCodes/QMC.py) determines the ground-state probability via a\n",
    "Feynman path integration using the Metropolis algorithm to simulate variations\n",
    "about the classical trajectory.\n",
    "\n",
    "### 17.8.4  Assessment and Exploration<a id=\"17.8.4\"></a>\n",
    "\n",
    "1.  Plot some of the actual space-time paths used in the simulation\n",
    "    along with the classical trajectory.\n",
    "\n",
    "2.  For a more continuous picture of the wave function, make the $x$\n",
    "    lattice spacing smaller; for a more precise value of the wave\n",
    "    function at any particular lattice site, sample more points\n",
    "    (run longer) and use a smaller time step $\\varepsilon$.\n",
    "\n",
    "3.  Because there are no sign changes in a ground-state wave function,\n",
    "    you can ignore the phase, assume $\\psi(x) = \\sqrt{\\psi^{2}(x) }$,\n",
    "    and then estimate the energy via\n",
    "\n",
    "    $$\\tag*{17.77}\n",
    "    E = \\frac{ \\left\\langle \\psi\\right| H \\left| \\psi\\right\\rangle }{\\langle \\psi|\\psi\\rangle} =\n",
    "    \\frac{ \\omega}{2\\langle \\psi|\\psi\\rangle} \\int_{-\\infty}^{+\\infty}\n",
    "    \\psi^{*}(x) \\left(-\\frac{d^{2}}{d x^{2}} + x^{2} \\right)\n",
    "    \\psi(x) dx,$$\n",
    "\n",
    "    where the space derivative is evaluated numerically.\n",
    "\n",
    "4.  Explore the effect of making $\\hbar$ larger and thus permitting\n",
    "    greater fluctuations around the classical trajectory. Do this by\n",
    "    decreasing the value of the exponent in the Boltzmann factor.\n",
    "    Determine if this makes the calculation more or less robust in its\n",
    "    ability to find the classical trajectory.\n",
    "\n",
    "5.  Test your $\\psi$ for the gravitational potential (see quantum\n",
    "    bouncer below):\n",
    "\n",
    "    $$\\tag*{17.78}\n",
    "    V(x) = mg|x|,\\quad  x(t) = x_0 + v_0 t + \\frac{1}{2}\n",
    "    gt^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 17.9  Exploration: Quantum Bouncer’s Paths $\\odot$ <a id=\"17.9\"></a>\n",
    "\n",
    "Another problem for which the classical trajectory is well known is that\n",
    "of a *quantum bouncer* \\[*Note:* Oscar A. Restrepo assisted in the\n",
    "preparation of this section.\\]. Here we have a particle dropped in a\n",
    "uniform gravitational field, hitting a hard floor, and then bouncing.\n",
    "When treated quantum mechanically, quantized levels for the particle\n",
    "result \\[[Gibbs(75)](BiblioLinked.html#gibbs), [Goodings & Szeredi(92)](BiblioLinked.html#goodings), [Whineray(92)](BiblioLinked.html#whineray),\n",
    "[Banacloche(99)](BiblioLinked.html#banacloche), [Vallée(00)](BiblioLinked.html#vallee)\\]. In 2002 an experiment to discern this\n",
    "gravitational effect at the quantum level was performed by  \\[[Nesvizhevsky et al.(02)](BiblioLinked.html#nesv)\\] and described in \\[[Shaw(92)](BiblioLinked.html#shaw)\\]. It\n",
    "consisted of dropping ultracold neutrons from a height of 14 $\\mu$m unto\n",
    "a neutron mirror and watching them bounce. It found a neutron ground\n",
    "state at 1.4 peV.\n",
    "\n",
    "We start by determining the analytic solution to this problem for stationary\n",
    "states and then generalize it to include time dependence. The time-independent\n",
    "Schrödinger equation for a particle in a uniform gravitation potential is\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.79}\n",
    "-\\frac{\\hbar^2}{2m} \\frac{d^2\\psi(x)}{dx^2} + mxg \\psi(x) & =  E\n",
    "\\psi(x),\\\\\n",
    "\\psi(x \\leq 0) & =  0,\\quad\\mbox{(boundary\n",
    "condition)}.\\tag*{17.80}\\end{align}$$ \n",
    "\n",
    "The boundary condition (17.80) is a\n",
    "consequence of the hard floor at $x=0$. A change of variables converts (17.79)\n",
    "to a dimensionless form, \n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{17.81}\n",
    "\\frac{d^2\\psi}{dz^2}-(z-z_E) \\psi &=  0,\\\\\n",
    "z= x \\left(\\frac{2gm^2}{\\hbar^2}\\right)^{ {1/3}},  \\quad&\\quad\n",
    " z_E = E\\left(\\frac{2}{\\hbar^2mg^2}\\right)^{1/ 3}. \\tag*{17.82}\\end{align}$$\n",
    " \n",
    "This equation has an analytic solution in terms of Airy functions\n",
    "Ai($z$):\n",
    "\n",
    "$$\\tag*{17.83}\n",
    "\\psi(z)=   N_n \\; {\\rm Ai}(z-z_{E}),$$\n",
    "\n",
    "where $N_n$ is a normalization constant and $z_E$ is the scaled value of\n",
    "the energy. The boundary condition $\\psi(0)=0$ implies that\n",
    "\n",
    "$$\\tag*{17.84}\n",
    "\\psi(0)= N_E\\;{\\rm Ai}(-z_E)=0,$$\n",
    "\n",
    "which means that the allowed energies of the system are discrete and\n",
    "correspond to the zeros $z_n$ of the Airy functions \\[Press et al.(94)\\]\n",
    "at negative argument. To simplify the calculation, we take $\\hbar=1$,\n",
    "$g=2$, and $m=\\frac{1}{2}$, which leads to $z=x$ and $z_E=E$.\n",
    "\n",
    "![image](Figs/Fig17_10.png)\n",
    "\n",
    "**Figure 17.10** The analytic and quantum Monte Carlo solution for the\n",
    "quantum bouncer. The continuous line is the Airy function squared and the\n",
    "dashed line $|psi_\\text{0}(\\textit{z})|^2$ after a million trajectories.\n",
    "\n",
    "The time-dependent solution for the quantum bouncer is constructed by\n",
    "forming the infinite sum over all the discrete eigenstates, each with a\n",
    "time dependence appropriate to its energy:\n",
    "\n",
    "$$\\tag*{17.85}\n",
    "\\psi(z,t)=\\sum_{n=1}^\\infty  C_nN_n   {\\rm Ai}(z-z_{n}) e^{-i\n",
    "E_n t/\\hbar},$$\n",
    "\n",
    "where the $C_n$’s are constants.\n",
    "\n",
    "Figure 17.10 shows the results of solving for the quantum bouncer’s\n",
    "ground-state probability $|psi_0(z)|^2$ using Feynman’s path integration.The\n",
    "time increment $dt$ and the total time $t$ were selected by trial and error in\n",
    "such a way as to make $|psi(0)|^2 \\simeq 0$ (the boundary condition). To\n",
    "account for the fact that the potential is infinite for negative $x$ values, we\n",
    "selected trajectories that have positive $x$ values over all their links. This\n",
    "incorporates the fact that the particle can never penetrate the floor. Our\n",
    "program is given in Listing 17.4, and it yields the results in Figure 17.10 after\n",
    "using $10^6$ trajectories and a time step $\\varepsilon =d\\tau=0.05$. Both\n",
    "results were normalized via a trapezoid integration. As can be seen, the\n",
    "agreement between the analytic result and the path integration is satisfactory.\n",
    "\n",
    "[**Listing 17.4  QMCbouncer.py**](http://www.science.oregonstate.edu/~rubin/Books/CPbook/Codes/PythonCodes/QMCbouncer.py) uses Feynman path integration to compute the path of a quantum particle\n",
    "in a gravitational field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
