{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Chapter 5*<br> Differentiation & Integration \n",
    "\n",
    "| | | |\n",
    "|:---:|:---:|:---:|\n",
    "| ![image](Figs/Cover.png)|[From **COMPUTATIONAL PHYSICS**, 3rd Ed, 2015](http://physics.oregonstate.edu/~rubin/Books/CPbook/index.html) <br>RH Landau, MJ Paez, and CC Bordeianu (deceased) <br>Copyrights: <br> [Wiley-VCH, Berlin;](http://www.wiley-vch.de/publish/en/books/ISBN3-527-41315-4/) and [Wiley & Sons, New York](http://www.wiley.com/WileyCDA/WileyTitle/productCd-3527413154.html)<br>  R Landau, Oregon State Unv, <br>MJ Paez, Univ Antioquia,<br> C Bordeianu, Univ Bucharest, 2015.<br> Support by National Science Foundation.|![image](Figs/BackCover.png)|\n",
    "\n",
    "**5 Differentiation & Integration**<br>\n",
    "[5.1 Differentiation](#5.1)<br>\n",
    "[5.2 Forward Difference (Algorithm)](#5.2)<br>\n",
    "[5.3 Central Difference (Algorithm)](#5.3)<br>\n",
    "[5.4 Extrapolated Difference (Algorithm)](#5.1)<br>\n",
    "[5.5 Error Assessment](#5.1)<br>\n",
    "[5.6 Second Derivatives (Problem)](#5.1)<br>\n",
    "[5.6.1 Second-Derivative Assessment](#5.6.1)<br>\n",
    "[5.7 Integration](#5.7)<br>\n",
    "[5.8 Quadrature as Box Counting (Math)](#5.8)<br>\n",
    "[5.9 Algorithm: Trapezoid Rule](#5.9)<br>\n",
    "[5.10 Algorithm: Simpson’s Rule](#5.10)<br>\n",
    "[5.11 Integration Error (Assessment)](#5.11)<br>\n",
    "[5.12 Algorithm: Gaussian Quadrature](#5.12)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.12.1 Mapping Integration Points](#5.1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.12.2 Gaussian Points Derivation](#5.12.1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.12.3 Integration Error Assessment](#5.12.3)<br>\n",
    "[5.13 Higher-Order Rules (Algorithm)](#5.13)<br>\n",
    "[5.14 Monte Carlo Integration by Stone Throwing](#5.14)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.14.1 Stone Throwing Implementation](#5.14.1)<br>\n",
    "[5.15 Mean Value Integration (Theory & Math)](#5.15)<br>\n",
    "[5.16 Integration Exercises](#5.16)<br>\n",
    "[5.17 Multidimensional Monte Carlo Integration (Problem)](#5.17)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.17.1 Multi Dimension Integration Error Assessment](#5.17.1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.17.2 Implementation: 10-D Monte Carlo Integration](#5.17.2)<br>\n",
    "[5.18 Integrating Rapidly Varying Functions (Problem)](#5.18)<br>\n",
    "[5.19 Variance Reduction (Method)](#5.19)<br>\n",
    "[5.20 Importance Sampling (Method)](#5.20)<br>\n",
    "[5.21 Von Neumann Rejection (Method)](#5.21)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.21.1 Simple Random Gaussian Distribution](#5.21)<br>\n",
    "[5.22 Nonuniform Assessment](#5.22)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.22.1 Implementation](#5.22.1)<br> \n",
    "\n",
    "*We start this chapter with a short discussion of numerical\n",
    "differentiation, an important if rather simple topic. We derive the\n",
    "forward-difference, central-difference, and extrapolated-difference\n",
    "methods for differentiation. They will be used throughout the book. The\n",
    "majority of this chapter deals with numerical integration, a basic tool\n",
    "of scientific computation. We derive Simpson’s rule, the trapezoid rule,\n",
    "and the Gaussian quadrature rule. We discuss Gaussian quadrature (our\n",
    "personal workhorse) in its various forms, and indicate how to map the\n",
    "standard Gauss points to a wide range of intervals. We end the chapter\n",
    "with a discussion of Monte Carlo integration techniques, which are\n",
    "fundamentally different from all the other rules.*\n",
    "\n",
    "** This Chapter’s Lecture, Slide Web Links, Applets & Animations**\n",
    "\n",
    "| | |\n",
    "|---|---|\n",
    "|[All Lectures](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/index.html)|[![anything](Figs/RHLlectureMod4.png)](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/index.html)|\n",
    "\n",
    "| *Lecture (Flash)*| *Slides* | *Sections*|*Lecture (Flash)*| *Slides* | *Sections*|  \n",
    "|- - -|:- - -:|:- - -:|- - -|:- - -:|:- - -:|\n",
    "| [Numerical Differentiation](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Differentiation/Differentiation.html)|[pdf](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slide/Slides_NoAnimate_pdf/Differentiate.pdf)| 7.1-7.6| [Trial and Error Searching](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Searching/Searching.html)| [pdf](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pdf/Trial_Err.pdf)|7.7-7.10 |\n",
    "| [N-Dimensional Searching](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/NdimSearch/NdimSearch.html)|[pdf](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pdf/NDsearch.pdf)|8.2| [Numerical Integration](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Integration/Integration.html)|[pdf](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pdf/Integrate.pdf)|6.1-6.3 |\n",
    "|[Applet: Area with MC](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Applets/index.html)||6.5 | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1  Differentiation<a id=\"5.1\"></a> \n",
    "\n",
    "[![image](Figs/RHLlectureMod4.png)](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Differentiation/Differentiation.html)\n",
    "\n",
    "**Problem:** Figure 5.1 shows the trajectory of a projectile with air\n",
    "resistance. The dots indicate the times *t* at which measurements were\n",
    "made and tabulated. Your **problem** is to determine the velocity\n",
    "*d**y*/*d**t* as a function of time. Note that because there is\n",
    "realistic air resistance present, there is no analytic function to\n",
    "differentiate, only this graph or a table of numbers read from it.\n",
    "\n",
    "You probably did rather well in your first calculus course and feel\n",
    "competent at taking derivatives. However, you may never have taken\n",
    "derivatives of a table of numbers using the elementary definition\n",
    "\n",
    "$$\\tag*{5.1}\n",
    "\\frac{dy(t)}{dt}  =  \\lim_{h \\rightarrow 0} \\frac{y(t+h)-\n",
    "y(t)}{h}.$$\n",
    "\n",
    "In fact, even a computer runs into errors with this kind of limit\n",
    "because it is wrought with subtractive cancellation; as *h* is made\n",
    "smaller, the computer’s finite word length causes the numerator to\n",
    "fluctuate between 0 and the machine precision *ϵ*<sub>*m*</sub>, and as\n",
    "the denominator approaches zero, overflow occurs.\n",
    "\n",
    "## 5.2  Forward Difference (Algorithm)<a id=\"5.2\"></a>  \n",
    "\n",
    "![image](Figs/Fig5_1.png) **Figure 5.1** A trajectory of a projectile\n",
    "experiencing air resistance. Forward-difference approximation (slanted\n",
    "dashed line) and central-difference approximation (horizontal line) for\n",
    "the numerical first derivative at time *t*. (A tangent to the curve at\n",
    "*t* yields the correct derivative.) The central difference is seen to be\n",
    "more accurate.\n",
    "\n",
    "The most direct method for numerical differentiation starts by expanding a\n",
    "function in a Taylor series to obtain its value at a small step *h* away:\n",
    "\n",
    "$$\\begin{align} y(t+h) &= y(t) + h \\frac{dy(t)}{dt}+ \\frac{h^{2}}{2!}\n",
    "\\frac{d^2y(t)}{dt^2}+ \\frac{h^{3}}{3!} \\frac{dy^3(t)}{dt^3} +\n",
    "\\cdots,   \\tag*{5.2}\\\\\n",
    "\\Rightarrow \\qquad \\frac{y(t+h) - y(t)}{h}  &=    \\frac{dy(t)}{dt}+ \\frac{h}{2!}\n",
    "\\frac{d^2y(t)}{dt^2}+ \\frac{h^{2}}{3!} \\frac{dy^3(t)}{dt^3} +\n",
    "\\cdots, \\tag*{5.3}\n",
    "   \\end{align}$$\n",
    "   \n",
    "If we ignore the *h*<sup>2</sup> terms in (5.3), we obtain the\n",
    "*forward-difference* derivative algorithm for the derivative (5.2) for\n",
    "*y*′(*t*):[[xml]](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/xml/5.4.xml) \n",
    "\n",
    "$$ \\tag*{5.4}\n",
    "\\left.\\frac{dy(t)}{dt}\\right|_{\\text{fd}} \\equiv\\frac{y(t+h) - y(t)}{h}$$\n",
    "\n",
    "An estimate of the error follows from substituting the Taylor series:\n",
    "\n",
    "$$\\left.\\frac{dy(t)}{dt}\\right|_{\\text{fd}} \\simeq \\frac{dy(t)}{dt} -\n",
    "\\frac{h}{2}\\frac{dy^2(t)}{dt^2} + \\cdots .\\tag*{5.5}$$\n",
    "\n",
    "You can think of this approximation as using two points to represent the\n",
    "function by a straight line in the interval from *x* to *x* + *h*\n",
    "(Figure 5.1 A). The approximation (5.4) has an error proportional to *h*\n",
    "(unless the heavens look down upon you kindly and make $y''$ vanish). We\n",
    "can make the approximation error smaller by making *h* smaller, yet\n",
    "precision will be lost through the subtractive cancellation on the\n",
    "left-hand side (LHS) of (5.4) for too small an *h*.\n",
    "\n",
    "To see how the forward-difference algorithm works, let $y(t) = a + b t^2$. The exact derivative is \n",
    "$y' = 2 b t$, while the computed derivative is\n",
    "\n",
    "$$\\tag*{5.6}\n",
    "\\left.\\frac{dy(t)}{dt}\\right|_{\\text{fd}}\\simeq \\frac{y(t+h)-y(t)}{h}\n",
    "= 2bt +bh.$$\n",
    "\n",
    "This clearly becomes a good approximation only for very small\n",
    "*h* (*h* ≪ 1/*b*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3  Central Difference (Algorithm)<a id=\"5.3\"></a> \n",
    "\n",
    "An improved approximation to the derivative starts with the basic\n",
    "definition (5.1) or geometrically as shown in Figure 5.1 B. Now, rather\n",
    "than making a single step of *h* forward, we form a *central difference*\n",
    "by stepping forward half a step and backward half a step:[[xml]](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/xml/5.7.xml)\n",
    "\n",
    "$$\\begin{align}\\tag*{5.7}\n",
    " \\left. \\frac{dy(t)}{dt}\\right|_{\\text{cd}}  \\equiv D_{\\text{cd}} y(t)   &=\n",
    "\\frac{y(t+h/2)-y(t-h/2)}{h}.\\end{align}$$\n",
    "\n",
    "We estimate the error in the central-difference algorithm by substituting the\n",
    "Taylor series for *y*(*t* + *h*/2) and*y*(*t* − *h*/2) into (5.7):\n",
    "\n",
    "$$\\begin{align}\n",
    "y\\left(t+\\frac{h}{2}\\right)-y\\left(t-\\frac{h}{2}\\right) &\n",
    "\\simeq \\left[y(t) + \\frac{h}{2}y'(t) + \\frac{h^2}{8}y''(t) +\n",
    "\\frac{h^3}{48}y'''(t)+ {\\cal O}(h^4) \\right]\n",
    "  \\\\\n",
    "&\\quad - \\left[y(t) - \\frac{h}{2}y'(t) + \\frac{h^2}{8}y\"(t) -\n",
    "\\frac{h^3}{48}y'''(t)+ {\\cal O}(h^4)\\right]   \\\\\n",
    "& = h y'(t) + \\frac{h^3}{24}y'''(t) + {\\cal O}(h^5), \\\\\n",
    "\\Rightarrow \\quad \\frac{dy(t)}{dt}\\bigg|_{\\text{cd}} & \\simeq   y'(t)\n",
    "+\\frac{1}{24}h^{2}y'''(t) + {\\cal O}(h^4) .\\tag*{5.8}\n",
    "   \\end{align}$$\n",
    "\n",
    "The important difference between this central-difference algorithm and the\n",
    "forward difference one is that when *y*(*t* − *h*/2) is subtracted from\n",
    "*y*(*t* + *h*/2), all terms containing an even power of *h* in the two Taylor\n",
    "series cancel. This make the central-difference algorithm accurate to order\n",
    "*h*<sup>2</sup> (*h*<sup>3</sup> before division by *h*), while the forward\n",
    "difference is accurate only to order *h*. If the *y*(*t*) is smooth, that is, if\n",
    "$y'''h^{2}/24 \\ll y''h/2$, then you can expect the central-difference error to be\n",
    "smaller than with the central difference algorithm.\n",
    "\n",
    "If we now return to our parabola example (5.6), we will see that the\n",
    "central difference gives the exact derivative independent of *h*:\n",
    "\n",
    "$$\\tag*{5.9}\n",
    "\\left. \\frac{dy(t)}{dt}\\right|_{\\text{cd}} \\simeq\n",
    "\\frac{y(t+{h/2})-y(t-{h/2})}{h} = 2bt.$$\n",
    "\n",
    "This is to be expected because the higher derivatives equal zero for a\n",
    "second order polynomial.\n",
    "\n",
    "## 5.4  Extrapolated Difference (Algorithm)<a id=\"5.4\"></a> \n",
    "\n",
    "Because a differentiation rule based on keeping a certain number of terms in a\n",
    "Taylor series also provides an expression for the error (the terms not included),\n",
    "we can reduce the theoretical error further by forming a combination of\n",
    "approximations whose summed errors extrapolate to zero. One such algorithm\n",
    "is the central-difference algorithm (5.7) using a half-step back and a half-step\n",
    "forward. A second algorithm is another central-difference approximation, but\n",
    "this time using quarter-steps:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{5.10}\n",
    "\\left. \\frac{dy(t,h/2)} {dt} \\right|_\\text{cd} & =   \\frac{y(t+h/4)-  y(t-h/4)}{h/2} \\\\\n",
    " & \\simeq   y'(t) + \\frac{h^2}{96}  \\frac{d^3y(t)}{dt^3} + \\cdots.  \\end{align}$$\n",
    " \n",
    " A combination of the two, called the *extended difference algorithm*,\n",
    "eliminates both the quadratic and linear terms:\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\tag*{5.11}\n",
    "\\left.\\frac{dy(t)}{dt}\\right|_\\text{ed} & =    \\frac{4D_\\text{cd}y(t,h/2) - D_\\text{cd}y(t,h)}{3}\\\\\n",
    " & \\simeq    \\frac{dy(t)}{dt} -\\frac{h^4 y^{(5)}(t)} {4\\times 16\\times 120} + \\cdots.\\tag*{5.12}\n",
    "   \\end{align}$$\n",
    "   \n",
    " Here (5.10) is the extended-difference algorithm and (5.12) gives its\n",
    "error, with *D*<sub>cd</sub> representing the central-difference\n",
    "algorithm. If *h* = 0.4 and *y*<sup>(5)</sup> ≃ 1, then there will be\n",
    "only one place of round-off error and the truncation error will be\n",
    "approximately machine precision *ϵ*<sub>*m*</sub>; this is the best you\n",
    "can hope for.\n",
    "\n",
    "When working with these and similar higher-order methods, it is\n",
    "important to remember that while they may work as designed for\n",
    "well-behaved functions, they may fail badly for functions containing\n",
    "noise, as do data from computations or measurements. If noise is\n",
    "evident, it may be better to first smooth the data or fit them with some\n",
    "analytic function using the techniques of [Chapter 7, *Trial-and-Error\n",
    "Searching & Data Fitting*](CP07.ipynb), and then differentiate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5  Error Assessment<a id=\"5.5\"></a> \n",
    "\n",
    "The approximation errors in numerical differentiation decrease with decreasing\n",
    "step size *h*. In turn, round-off errors increase with decreasing step size\n",
    "because you have to take more steps and do more calculations. Remember from\n",
    "our discussion in [Chapter 3, *Errors & Uncertainties in\n",
    "Computations*](CP03.ipynb), that the best approximation occurs for an *h*\n",
    "that makes the total error $\\epsilon_{\\textrm app} + \\epsilon_{\\textrm ro}$ a\n",
    "minimum, and that as a rough guide this occurs when $\n",
    "\\epsilon_{\\textrm ro} \\simeq\n",
    "\\epsilon_{\\textrm app}$.\n",
    "\n",
    "We have already estimated the approximation error in numerical differentiation\n",
    "rules by making a Taylor series expansion of *y*(*x* + *h*). The approximation\n",
    "error with the forward-difference algorithm (5.4) is ${\\cal O}(h)$, while that\n",
    "with the central-difference algorithm (5.8) is ${\\cal O}(h^2)$:\n",
    "\n",
    "$$\\tag*{5.13}\n",
    "\\epsilon_{\\textrm app}^{\\textrm fd} \\simeq \\frac{y\"h}{2}, \\quad\n",
    "\\epsilon_{\\textrm app}^{\\textrm cd} \\simeq\n",
    "\\frac{y\"'h^{2}}{24}.$$\n",
    "\n",
    "To obtain a rough estimate of the round-off error, we observe that\n",
    "differentiation essentially subtracts the value of a function at argument *x*\n",
    "from that of the same function at argument *x* + *h* and then divides by\n",
    "*h*: *y*′≃[*y*(*t* + *h*)−*y*(*t*)]/*h*. As *h* is made continually smaller, we\n",
    "eventually reach the round-off error limit where *y*(*t* + *h*) and *y*(*t*)\n",
    "differ by just machine precision *ϵ*<sub>*m*</sub>:\n",
    "\n",
    "$$\\tag*{5.14}\n",
    "\\epsilon_{\\textrm ro} \\simeq \\frac{\\epsilon_m}{h}.$$\n",
    "\n",
    "Consequently, round-off and approximation errors become equal when\n",
    "$$\\begin{align}\n",
    " &\\epsilon_{\\textrm ro}  \\simeq \\epsilon_{\\textrm app},&  \\tag*{5.15}\\\\\n",
    " \\frac{\\epsilon_{m}}{h}  &\\simeq\n",
    "\\epsilon_{\\textrm app}^{\\textrm fd}   = \\frac{y^{(2)}h}{2}\n",
    ", & \\frac{\\epsilon_{m}}{h} &\\simeq\n",
    "\\epsilon_{\\textrm app}^{\\textrm cd}\n",
    "  =\\frac{y^{(3)}h^{2}}{24},\\tag*{5.16}\\\\\n",
    " \\Rightarrow \\quad h_{\\textrm fd}^{2} & =\n",
    "\\frac{2\\epsilon_{m}}{y^{(2)}},  &  \\Rightarrow \\quad\n",
    "h_{\\textrm cd}^{3} \\displaystyle &=\n",
    "\\frac{24\\epsilon_{m}}{y^{(3)}}.\\tag*{5.17}\n",
    "    \\end{align}$$\n",
    " We take *y*′≃*y*<sup>(2)</sup> ≃ *y*<sup>(3)</sup> (which may be crude\n",
    "in general, although not bad for *e*<sup>*t*</sup> or cos*t*) and assume\n",
    "double precision, *ϵ*<sub>*m*</sub> ≃ 10<sup>−15</sup>:\n",
    "$$\\begin{align}\n",
    "\\tag*{5.18}\n",
    "h_{\\textrm fd} &\\simeq 4\\times 10^{-8}, & h_{\\textrm cd} &\\simeq 3\\times\n",
    "10^{-5},\\\\\n",
    "\\Rightarrow \\quad \\epsilon_{\\textrm fd} &  \\simeq\n",
    "\\frac{\\epsilon_m} {h_{\\text{fd}}} \\simeq 3\\times 10^{-8}, & \\quad\n",
    "\\Rightarrow \\quad\\epsilon_{\\textrm cd}   & \\simeq\n",
    "\\frac{\\epsilon_m} { h_{\\text{cd}}} \\simeq 3\\times 10^{-11}.\\tag*{5.19}\n",
    "   \\end{align}$$\n",
    " This may seem backward because the better algorithm leads to a larger\n",
    "*h* value. It is not. The ability to use a larger *h* means that the\n",
    "error in the central-difference method is about 1000 times smaller than\n",
    "the error in the forward-difference method.\n",
    "\n",
    "The programming for numerical differentiation is simple:\n",
    "\n",
    "    FD = ( y(t+h) - y(t) ) /h;                     // forward diff\n",
    "    CD = ( y(t+h/2) - y(t-h/2) ) /h;               // central diff\n",
    "    ED = (8*(y(t+h/4)-y(t-h/4)) - (y(t+h/2)-y(t-h/2)))/3/h; //extrap\n",
    "\n",
    "\n",
    "1.  Use forward-, central-, and extrapolated-difference algorithms to\n",
    "    differentiate the functions cos*t* and *e*<sup>*t*</sup> at\n",
    "    *t* = 0.1, 1., and 100.\n",
    "\n",
    "    -   Print out the derivative and its relative error ℰ as functions\n",
    "        of *h*. Reduce the step size *h* until it equals machine\n",
    "        precision *h* ≃ *ϵ*<sub>*m*</sub>.\n",
    "\n",
    "    -   Plot log<sub>10</sub>|ℰ| <span>*versus*</span>\n",
    "        log<sub>10</sub>*h* and check whether the number of decimal\n",
    "        places obtained agrees with the estimates in the text.\n",
    "\n",
    "    -   See if you can identify regions where algorithmic\n",
    "        (series truncation) error dominates at large *h* and round-off\n",
    "        error at small *h* in your plot. Do the slopes agree with our\n",
    "        model’s predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6  Second Derivatives (Problem)<a id=\"5.6\"></a> \n",
    "\n",
    "Let’s say that you have measured the position *y*(*t*)\n",
    "<span>*versus*</span> time for a particle (Figure 5.1). Your **problem**\n",
    "now is to determine the force on the particle. Newton’s second law tells\n",
    "us that force and acceleration are linearly related:\n",
    "\n",
    "$$F = ma = m\\frac{d^2 y}{dt^2},\\tag*{5.20}$$\n",
    "\n",
    "where *F* is the force, *m* is the particle’s mass, and *a* is the\n",
    "acceleration. So by determining the derivative\n",
    "*d*<sup>2</sup>*y/dt*<sup>2</sup> from the *y(t)* values, we\n",
    "determine the force.\n",
    "\n",
    "The concerns we expressed about errors in first derivatives are even\n",
    "more valid for second derivatives where additional subtractions may lead\n",
    "to additional cancellations. Let’s look again at the central-difference\n",
    "method:\n",
    "\n",
    "$$\\tag*{5.21}\n",
    "  \\left. \\frac{dy(t)}{dt}\\right|_{cd} \\simeq \\frac{y(t+h/2) - y(t-h/2)}{h} .$$\n",
    "\n",
    "This algorithm gives the derivative at *t* by moving forward and\n",
    "backward from *t* by *h*/2. We take the second derivative $d^2 y/dt^2$\n",
    "to be the central difference of the first derivative:[[xml]](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/xml/5.22.xml)\n",
    "\n",
    "$$\\begin{align}\n",
    "\\frac{d^2 y(t)}{dt^2} & \\simeq    \\frac{y'(t+{h/2}) - y'(t-{h/2})}{h}   \\\\\n",
    "& \\simeq \\frac{[y(t+h) - y(t)] - [y(t)- y(t-h)]}{h^{2}} \\tag*{5.22}\\\\ & =\n",
    "\\frac{y(t+h) + y(t-h) - 2y(t)}{h^{2}}.\\tag*{5.23}\\end{align}$$\n",
    "\n",
    "As we did for first derivatives, we determine the second derivative at\n",
    "*t* by evaluating the function in the region surrounding *t*. Although\n",
    "the form (5.23) is more compact and requires fewer steps than (5.22), it\n",
    "may increase subtractive cancellation by first storing the “large”\n",
    "number *y(t + h)+y(t − h)* and then subtracting another large\n",
    "number 2*y*(*t*) from it. We ask you to explore this difference as an\n",
    "exercise.\n",
    "\n",
    "### 5.6.1  Second-Derivative Assessment<a id=\"5.6.1\"></a> \n",
    "\n",
    "Write a program to calculate the second derivative of cos*t* using the\n",
    "central-difference algorithms (5.22) and (5.23). Test it over four\n",
    "cycles. Start with *h* ≃ *π*/10 and keep reducing *h* until you reach\n",
    "machine precision. Is there any noticeable differences between (5.22)\n",
    "and (5.23)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7  Integration<a id=\"5.7\"></a> \n",
    "\n",
    "**Problem: Integrating a Spectrum** An experiment has measured\n",
    "*d**N*(*t*)/*d**t*, the number of particles entering a counter per unit time.\n",
    "Your **problem** is to integrate this spectrum to obtain the number of\n",
    "particles *N*(1) that entered the counter in the first second:\n",
    "$$\\begin{align}\n",
    "N(1) = \\int_0^1 \\frac{dN(t)}{dt} dt.\\tag*{5.24}\n",
    " \\end{align}$$\n",
    "\n",
    "## 5.8  Quadrature as Box Counting (Math)<a id=\"5.8\"></a> \n",
    "\n",
    "The integration of a function may require some cleverness to do\n",
    "analytically, but is relatively straightforward on a computer.A\n",
    "traditional way to perform numerical integration by hand is to take a\n",
    "piece of graph paper and count the number of boxes or *quadrilaterals*\n",
    "lying below a curve of the integrand. For this reason numerical\n",
    "integration is also called *numerical quadrature* even when it becomes\n",
    "more sophisticated than simple box counting.\n",
    "\n",
    "The Riemann definition of an integral is the limit of the sum over boxes\n",
    "as the width *h* of the box approaches zero (Figure 6.1):[[xml]](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/xml/5.25.xml)\n",
    "\n",
    "$$\\tag*{5.25}\n",
    "  \\int_{a}^{b} f(x)  dx = \\lim_{h\\rightarrow 0} \\left[h\n",
    "    \\sum_{i=1}^{(b-a)/h} f(x_{i}) \\right].$$\n",
    "\n",
    "The numerical integral of a function *f*(*x*) is approximated as the\n",
    "equivalent of a finite sum over boxes of height *f*(*x*) and width\n",
    "*w*<sub>*i*</sub>:\n",
    "\n",
    "$$\\tag*{5.26}\n",
    "\\int_{a}^{b} f(x)  dx \\simeq \\sum_{i=1}^{N} f(x_{i}) w_{i},$$\n",
    "\n",
    "which is similar to the Riemann definition (5.25) except that there is no limit to\n",
    "an infinitesimal box size. Equation (5.26) is the standard form for all integration\n",
    "algorithms; the function *f*(*x*) is evaluated at *N* points in the interval\n",
    "[*a*, *b*\\], and the function values\n",
    "*f*<sub>*i*</sub> ≡ *f*(*x*<sub>*i*</sub>) are summed with each term in\n",
    "the sum weighted by *w*<sub>*i*</sub>. While in general the sum in (5.26)\n",
    "gives the exact integral only when *N* → ∞, it may be exact for finite *N* if the\n",
    "integrand is a polynomial. The different integration algorithms amount to\n",
    "different ways of choosing the points *x*<sub>*i*</sub> and weights\n",
    "*w*<sub>*i*</sub>. Generally, the precision increases as *N* gets larger, with\n",
    "round-off error eventually limiting the increase. Because the “best” integration\n",
    "rule depends on the specific behavior of *f*(*x*), there is no universally best\n",
    "approximation. In fact, some of the automated integration schemes found in\n",
    "subroutine libraries switch from one method to another, as well as change the\n",
    "methods for different intervals until they find ones that work well for each\n",
    "interval.\n",
    "\n",
    "![image](Figs/Fig5_2.png) **Figure 5.2** The integral\n",
    "∫<sub>*a*</sub><sup>*b*</sup>*f*(*x*)*dx* is the area under the graph of\n",
    "*f*(*x*) from *a* to *b*. Here we break up the area into four regions of\n",
    "equal widths *h* and five integration points.\n",
    "\n",
    "In general you should not attempt a numerical integration of an integrand that\n",
    "contains a singularity without first removing the singularity by hand.\\[*Note:* In\n",
    "[Chapter 26, *Integral Equations of Quantum Mechanics*](CP25.ipynb), we\n",
    "show how to remove such a singularity even when the integrand is unknown.\\]\n",
    "You may be able to do this very simply by breaking the interval down into several\n",
    "subintervals so the singularity is at an endpoint where an integration point is not\n",
    "placed or by a change of variable:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{5.27}\n",
    "\\int_{-1}^{1} |x| f(x)  dx & =  \\int_{-1}^{0}f(-x)  dx +\n",
    "\\int_{0}^{1}f(x)  dx, \\\\\n",
    "\\int_{0}^{1}x^{1/3}  dx & =  \\int_{0}^{1} 3y^{3}  dy , \\qquad (y  =\n",
    "x^{1/3}),\\tag*{5.28}\\\\\n",
    "\\int_{0}^{1}\\frac{f(x)  dx}{\\sqrt{1-x^{2}}} & =\n",
    " 2\\int_{0}^{1}\\frac{f(1-y^{2})  dy}{\\sqrt{2-y^{2}}}, \\quad (y^{2}  =  1-x).\\tag*{5.29}\n",
    "   \\end{align}$$\n",
    "   \n",
    " Likewise, if your integrand has a very slow variation in some region,\n",
    "you can speed up the integration by changing to a variable that\n",
    "compresses that region and places few points there, or divides up the\n",
    "interval and performs several integrations. Conversely, if your\n",
    "integrand has a very rapid variation in some region, you may want to\n",
    "change to variables that expand that region to ensure that no\n",
    "oscillations are missed.\n",
    "\n",
    "[**Listing\n",
    "5.1  TrapMethods.py**](http://www.science.oregonstate.edu/~rubin/Books/CPbook/Codes/PythonCodes/TrapMethods.py)\n",
    "integrates the arbitrary function *f*(*y*) via the trapezoid rule. Note\n",
    "how the step size *h* depends on the interval and how the weights at the\n",
    "ends and middle differ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrapMethods.py, Notebook Version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final sum =  9.00000313021\n"
     ]
    }
   ],
   "source": [
    "# TrapMethods.py      Trapezoid integration using a defined function = t^2\n",
    "\n",
    "from numpy import *\n",
    "from __future__ import print_function\n",
    "\n",
    "from sys import version\n",
    "if int(version[0])>2:         #raw_input deprecated in Python 3\n",
    "    raw_input=input   \n",
    "\n",
    "A = 0.0\n",
    "B = 3.0\n",
    "N = 1200\n",
    "\n",
    "def f(y):                                             # The function being integrated\n",
    "    #print('\\n y    = ', y)\n",
    "    #print(' f(y) = ', y*y)\n",
    "    return y*y\n",
    "\n",
    "def wTrap(i, h):                                         # Function determines weight\n",
    "    if ( (i == 1) or (i == N) ):\n",
    "        wLocal = h/2.0\n",
    "    else:\n",
    "        wLocal = h\n",
    "    return wLocal\n",
    "\n",
    "h = (B - A)/(N - 1)\n",
    "suma = 0.0\n",
    "\n",
    "for i in range(1, N + 1):\n",
    "    t = A + (i - 1)*h\n",
    "    w = wTrap(i, h)\n",
    "    suma  = suma + w * f(t)\n",
    "    \n",
    "print('\\n Final sum = ', suma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9  Algorithm: Trapezoid Rule<a id=\"5.9\"></a> \n",
    "\n",
    "The trapezoid and Simpson integration rules both use evenly spaced\n",
    "values of *x* (Figure 5.2). They use *N* points\n",
    "*x*<sub>*i*</sub>(*i* = 1, *N*) evenly spaced at a distance *h* apart\n",
    "throughout the integration region \\[*a*, *b*\\] and *include the\n",
    "endpoints* in the integration region. This means that there are\n",
    "(*N* − 1) intervals of length *h*:\n",
    "\n",
    "$$\\tag*{5.30} h= \\frac{b-a}{N-1},\\qquad x_{i} = a + (i-1) h, \\qquad i=1, N,$$\n",
    "\n",
    "where we start our counting at *i* = 1. The trapezoid rule takes each\n",
    "integration interval *i* and constructs a trapezoid of width *h* in it\n",
    "(Figure 5.2). This approximates *f*(*x*) by a straight line in each\n",
    "interval *i* and uses the average height\n",
    "(*f*<sub>*i*</sub> + *f*<sub>*i* + 1</sub>)/2 as the value for *f*. The\n",
    "area of each such trapezoid is\n",
    "\n",
    "$$\\int_{x_{i}}^{x_{i}+h}f(x) dx \\simeq \\frac{h(f_{i}+f_{i+1})}{2} =\n",
    "\\frac{1}{2}hf_{i} + \\frac{1}{2}hf_{i+1}. \\tag*{5.31}$$\n",
    "\n",
    "In terms of our standard integration formula (5.26), the “rule” in (5.31) is for\n",
    "*N* = 2 points with weights $w_{i} \\equiv \\frac{1}{2}$ (Table 5.1).\n",
    "\n",
    "|Straight-line sections of trapezoid rule.|Parabolas of Simpson’s rule.|\n",
    "|:- - -:|:- - -:|\n",
    "| ![image](Figs/Fig5_3a.png) | ![image](Figs/Fig5_3b.png)|\n",
    "\n",
    "**Figure 5.3** Different shapes used to approximate the areas under a\n",
    "curve.\n",
    "\n",
    "**Table 5.1** Elementary Weights for Uniform-Step Integration Rules\n",
    "\n",
    "| Name | Degree | Elementary Weights| \n",
    "|- - -|:- - -:|- - -| \n",
    "| Trapezoid| 1|$(1,1)\\frac{h}{2}$| \n",
    "| Simpson’s| 2| $(1, 4, 1)\\frac{h}{3}$| \n",
    "| $\\frac{3}{8}$| 3|$(1, 3, 3, 1)\\frac{3}{8}h$| \n",
    "| Milne| 4| $(14,64,24,64,14)\\frac{h}{45}$| \n",
    "\n",
    "In order\n",
    "to apply the trapezoid rule to the entire region \\[*a*, *b*\\], we add the\n",
    "contributions from each subinterval:\n",
    "\n",
    "$$\\tag*{5.32}\n",
    "\\int_{a}^{b}f(x)  dx \\simeq \\frac{h}{2}f_{1} + hf_{2}\n",
    "  +hf_{3} + \\cdots + hf_{N-1} + \\frac{h}{2}f_{N} .$$\n",
    "\n",
    "You will notice that because the internal points are counted twice (as\n",
    "the end of one interval and as the beginning of the next), they have\n",
    "weights of *h*/2 + *h*/2 = *h*, whereas the endpoints are counted just\n",
    "once, and on that account have weights of only *h*/2. In terms of our\n",
    "standard integration rule (5.57), we have[[xml]](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/xml/5.33.xml)\n",
    "\n",
    "$$\\tag*{5.33}\n",
    "  w_{i} = \\left\\{\\frac{h}{2}, h, \\ldots, h,\n",
    "\\frac{h}{2}\\right\\}  \\qquad\n",
    "  \\mbox{(Trapezoid rule)}.$$\n",
    "\n",
    "In Listing 5.1 we provide a simple implementation of the trapezoid rule.\n",
    "\n",
    "## 5.10  Algorithm: Simpson’s Rule<a id=\"5.10\"></a> \n",
    "\n",
    "Simpson’s rule approximates the integrand *f*(*x*) by a parabola for each\n",
    "interval (Figure 5.3 B): \n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{5.34}\n",
    "f(x) \\simeq \\alpha x^{2} + \\beta x + \\gamma ,\n",
    "   \\end{align}$$\n",
    " Again, all intervals equally spaced. The area under the parabola for\n",
    "each interval is\n",
    "\n",
    "$$\\tag*{5.35}\n",
    "\\int_{x_i}^{x_i+h}(\\alpha x^{2} + \\beta x +\\gamma)  dx = \\left.\n",
    "\\frac{\\alpha x^3 } { 3} +   \\frac{\\beta x^2} { 2}\n",
    "    + \\gamma x \\right|_{x_i}^{x_i+h}.$$\n",
    "\n",
    "In order to relate the parameters *α*, *β*, and *γ* to the function, we\n",
    "consider an interval from −1 to +1, in which case\n",
    "\n",
    "$$\\tag*{5.36}\n",
    "\\int_{-1}^{1}(\\alpha x^{2} + \\beta x +\\gamma)  dx =\n",
    "\\frac{2\\alpha}{3} + 2\\gamma.$$\n",
    "\n",
    "But we notice that\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{5.37}\n",
    " f(-1) & = \\alpha -\\beta+\\gamma, \\quad  f(0) = \\gamma, \\quad f(1) = \\alpha + \\beta +\n",
    "  \\gamma,\\\\\n",
    "  \\Rightarrow & \\alpha = \\displaystyle \\frac{f(1)+f(-1)} { 2} -f(0), \\quad\n",
    "   \\beta =       \\frac{f(1)-f(-1)} { 2},  \\quad \\gamma= f(0).\\tag*{5.38}\n",
    "   \\end{align}$$\n",
    "\n",
    "In this way we can express the integral as the weighted sum over the\n",
    "values of the function at three points:\n",
    "\n",
    "$$\\tag*{5.39}\n",
    "\\int_{-1}^{1}(\\alpha x^{2} + \\beta x +\\gamma)  dx =\n",
    "\\frac{f(-1)}{3} + \\frac{4f(0)}{3} + \\frac{f(1)}{3} .$$\n",
    "\n",
    "Because three values of the function are needed, we generalize this\n",
    "result to our problem by evaluating the integral over two adjacent\n",
    "intervals, in which case we evaluate the function at the two endpoints\n",
    "and in the middle (Table 5.1):\n",
    "\n",
    "$$\\begin{align}\n",
    "\\int_{x_{i}-h}^{x_{i}+h}f(x)  dx & =  \\int_{x_{i}}^{x_{i}+h}f(x)\n",
    "dx + \\int_{x_{i}-h}^{x_{i}}f(x) dx\\\\\n",
    "  & \\simeq   \\frac{h}{3}f_{i-1}\n",
    "    + \\frac{4h}{3}f_{i} + \\frac{h}{3}f_{i+1} .\\tag*{5.40}\n",
    "   \\end{align}$$\n",
    "\n",
    "Simpson’s rule requires the elementary integration to be over *pairs* of\n",
    "intervals, which in turn requires that the *total number of intervals be\n",
    "even or that the number of points *N* be odd*. In order to apply\n",
    "Simpson’s rule to the entire interval, we add up the contributions from\n",
    "each pair of subintervals, counting all but the first and last endpoints\n",
    "twice:\n",
    "\n",
    "$$\\int_{a}^{b}\\!\\!f(x)dx \\simeq \\frac{h}{3}f_{1} +\n",
    "\\frac{4h}{3}f_{2}+ \\frac{2h}{3}f_{3} + \\frac{4h}{3}f_{4} + \\cdots\n",
    "+\\frac{4h}{3}f_{N-1} + \\frac{h}{3}f_{N}.\n",
    "\\tag*{5.41}$$\n",
    "\n",
    "In terms of our standard integration rule (5.26), we have[[xml]](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/xml/5.42.xml)\n",
    "\n",
    "$$\\tag*{5.42}\n",
    "  w_{i} = \\left\\{\\frac{h}{3},  \\frac{4h}{3},\n",
    "\\frac{2h}{3},  \\frac{4h}{3},   \\ldots,\n",
    "    \\frac{4h}{3},   \\frac{h}{3} \\right\\} \\qquad   \\mbox{(Simpson's rule)}.$$\n",
    "\n",
    "The sum of these weights provides a useful check on your integration:\n",
    "\n",
    "$$\\tag*{5.43}\n",
    "\\sum_{i=1}^{N} w_{i} = (N-1) h.$$\n",
    "\n",
    "*Remember*, the number of points *N* must be odd for Simpson’s rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11  Integration Error (Assessment)<a id=\"5.11\"></a> \n",
    "\n",
    "In general, you should choose an integration rule that gives an accurate answer\n",
    "using the least number of integration points. We obtain a crude estimate of the\n",
    "*approximation* or *algorithmic error* $\\cal{E}$ for the equal-spacing rules\n",
    "and their relative error *ϵ* by expanding *f*(*x*) in a Taylor series around the\n",
    "midpoint of the integration interval.We then multiply that error by the number\n",
    "of intervals *N* to estimate the error for the entire region \\[*a*, *b*\\]. For the\n",
    "trapezoid and Simpson rules this yields\n",
    "\n",
    "$$\\tag*{5.44} {\\cal E}_t = O\\left(\\frac{[b-a]^{3}}{N^{2}}\n",
    "\\right)f^{(2)},\\quad {\\cal E}_{s} = O\\left(\\frac{[b-a]^{5}}{N^{4}} \\right)\n",
    "f^{(4)},\\quad \\epsilon_{t,s} = \\frac{{\\cal E}_{t,s}}{f},$$\n",
    "\n",
    "where *ϵ* is a measure of the relative error. We see that the\n",
    "third-derivative term in Simpson’s rule cancels (much like the\n",
    "central-difference method does in differentiation). Equations (5.44) are\n",
    "illuminating in showing how increasing the sophistication of an\n",
    "integration rule leads to an error that decreases with a higher inverse\n",
    "power of *N*, yet is also proportional to higher derivatives of *f*.\n",
    "Consequently, for small intervals and functions *f*(*x*) with\n",
    "well-behaved derivatives, Simpson’s rule should converge more rapidly\n",
    "than the trapezoid rule.\n",
    "\n",
    "To model the round-off error in integration, we assume that after *N*\n",
    "steps the *relative* round-off error is random and of the form\n",
    "\n",
    "$$\\tag*{5.45}\n",
    "\\epsilon_{\\textrm ro} \\simeq \\sqrt{N} \\epsilon_{m},$$\n",
    "\n",
    "where *ϵ*<sub>*m*</sub> is the machine precision, *ϵ* ∼ 10<sup>−7</sup>\n",
    "for single precision and *ϵ* ∼ 10<sup>−15</sup> for double precision\n",
    "(the standard for science). Because most scientific computations are\n",
    "performed with doubles, we will assume double precision. We want to\n",
    "determine an *N* that minimizes the total error, that is, the sum of the\n",
    "approximation and round-off errors:\n",
    "\n",
    "$$\\tag*{5.46}\n",
    "\\epsilon_{\\textrm tot} \\simeq  \\epsilon_{\\textrm ro} + \\epsilon_{\\textrm app}.$$\n",
    "\n",
    "This occurs, approximately, when the two errors are of equal magnitude,\n",
    "which we approximate even further by assuming that the two errors are\n",
    "equal:\n",
    "\n",
    "$$\\tag*{5.47}\n",
    "\\epsilon_{\\textrm ro} = \\epsilon_{\\textrm app} =\\frac{{\\cal\n",
    "E}_{\\textrm trap,simp}}{f} .$$\n",
    "\n",
    "To continue the search for optimum *N* for a general function *f*, we\n",
    "set the scale of function size and the lengths by assuming\n",
    "\n",
    "$$\\tag*{5.48}\n",
    "\\frac{f^{(n)}}{f} \\simeq 1 , \\quad b - a = 1 \\quad \\Rightarrow \\quad  h =\n",
    "\\frac{1}{N}.$$\n",
    "\n",
    "The estimate (5.47), when applied to the **trapezoid rule**, yields\n",
    "\n",
    "$$\\begin{align}\n",
    "\\sqrt{N} \\epsilon_{m} & \\simeq   \\frac{f^{(2)} (b-a)^{3}}{f N^{2}} =\n",
    "\\frac{1}{N^{2}},\\\\\n",
    "\\Rightarrow \\quad N & \\simeq   \\frac{1}{(\\epsilon _{m})^{2/5}} =\n",
    "\\left(\\frac{1}{10^{-15}}\\right)^{2/5} = 10^{6},\\\\ \n",
    "\\Rightarrow \\epsilon_{\\textrm ro} & \\simeq \\sqrt{N} \\epsilon_{m}\n",
    "=10^{-12}.\n",
    "   \\end{align}$$\n",
    "\n",
    "The estimate (5.47), when applied to **Simpson’s rule**, yields\n",
    "\n",
    "$$\\begin{align}\n",
    "\\sqrt{N} \\epsilon_{m} & =  \\frac{f^{(4)}(b-a)^{5}}{fN^{4}} =\n",
    "\\frac{1}{N^{4}}, \\tag*{5.49}\\\\ \n",
    "\\Rightarrow N & =  \\frac{1}{(\\epsilon _{m})^{2/9}}\n",
    "=\\left(\\frac{1}{10^{-15}}\\right)^{2/9} = 2154,\\tag*{5.50}\\\\\n",
    "\\Rightarrow \\epsilon_{\\textrm ro} & \\simeq    \\sqrt{N} \\epsilon_{m} = 5\n",
    "\\times 10^{-14}.\\tag*{5.51}\n",
    "   \\end{align}$$\n",
    "\n",
    "These results are illuminating in that they show how\n",
    "\n",
    "-   Simpson’s rule requires fewer point and has less error than the\n",
    "    trapezoid rule.\n",
    "\n",
    "-   It is possible to obtain an error close to machine precision with\n",
    "    Simpson’s rule (and with other higher-order integration algorithms).\n",
    "\n",
    "-   Obtaining the *best* numerical approximation to an integral is not\n",
    "    achieved by letting *N* → ∞ but with a relatively small *N* ≤ 1000.\n",
    "    Larger *N* only makes the round-off error dominate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.12  Algorithm: Gaussian Quadrature<a id=\"5.12\"></a> \n",
    "\n",
    "It is often useful to rewrite the basic integration formula (5.26) with\n",
    "a weighting function *W*(*x*) separate from the integrand:\n",
    "\n",
    "$$\\tag*{5.55}\n",
    "\\int_{a}^{b} f(x)  dx \\equiv \\int_{a}^{b} W(x)g(x)  dx \\simeq\n",
    "\\sum_{i=1}^{N} w_{i} g(x_{i}) .$$\n",
    "\n",
    "In the Gaussian quadrature approach to integration, the *N* points and\n",
    "weights in (5.55) are chosen to make the integration exact if *g*(*x*)\n",
    "were a (2*N* − 1)-degree polynomial. To obtain this incredible\n",
    "optimization, the points *x*<sub>*i*</sub> end up having a specific\n",
    "distribution over \\[*a*, *b*\\]. In general, if *g*(*x*) is smooth or can\n",
    "be made smooth by factoring out some *W*(*x*) (Table 5.2), Gaussian\n",
    "quadrature will produce higher accuracy than the trapezoid and Simpson\n",
    "rules for the same number of points. Sometimes the integrand may not be\n",
    "smooth because it has different behaviors in different regions. In these\n",
    "cases it makes sense to integrate each region separately and then add\n",
    "the answers together. In fact, some “smart” integration subroutines\n",
    "decide for themselves how many intervals to use and which rule to use in\n",
    "each.\n",
    "\n",
    "**Table 5.2** Types of Gaussian Integration Rules\n",
    "\n",
    "|<span>*Integral*</span> | <span>*Name*</span> | <span>*Integral*</span>| <span>*Name*</span> | \n",
    "|- - -|- - -|- - -|- - -| \n",
    "|∫<sub>−1</sub><sup>1</sup> *f*(*y*)*d**y*| Gauss |$\\int_{-1}^{1} \\frac{F(y)}{\\sqrt{1-y^{2}}} dy$| Gauss-Chebyshev|\n",
    "|∫<sub>−∞</sub><sup>∞</sup> *e*<sup>−*y*<sup>2</sup></sup>*F*(*y*)*d**y*|Gauss-Hermite|∫<sub>0</sub <sup>∞</sup> *e*<sup>−*y*</sup>*F*(*y*)*d**y*| Gauss-Laguerre| \n",
    "|$\\int_{0}^{\\infty}\\ \\frac{e^{-y}}{\\sqrt{y}}F(y) dy$|Associated Gauss-Laguerre|| |\n",
    "\n",
    "All the rules indicated in Table 5.2 are Gaussian\n",
    "with the general form (5.55). We can see that in one case the weighting\n",
    "function is an exponential, in another a Gaussian, and in several an integrable\n",
    "singularity. In contrast to the equally spaced rules, there is never an integration\n",
    "point at the extremes of the intervals, yet the values of the points and weights\n",
    "change as the number of points *N* changes, and the points are not spaced\n",
    "equally.\n",
    "\n",
    "The derivation of the Gaussian points will be outlined below, but we\n",
    "point out here that for ordinary Gaussian (Gauss-Legendre) integration,\n",
    "the points *y*<sub>*i*</sub> turn out to be the *N* zeros of the\n",
    "Legendre polynomials, with the weights related to the derivatives,\n",
    "\n",
    "$$\\tag*{5.56} P_{N}(y_{i}) = 0, \\qquad w_{i} = \\frac{2}{([(1-y_{i}^{2}) [P_{N}^{'}\n",
    "(y_{i})]^{2}]}.$$\n",
    "\n",
    "Programs to generate these points and weights are standard in\n",
    "mathematical function libraries, are found in tables such as those in\n",
    "\\[[Abramowitz & Stegun(72)](BiblioLinked.html#AS)\\], or can be computed. The *gauss* program we\n",
    "provide also scales the points to span specified regions. As a check\n",
    "that the program’s points are correct, you may want to compare them to\n",
    "the four-point set in Table 5.3.\n",
    "\n",
    "**Table 5.3** Points and Weights for 4-point Gaussian Quadrature (to\n",
    "check computation)\n",
    "\n",
    "| ±*y*<sub>*i*</sub> |*w*<sub>*i*</sub>|\n",
    "|---|---|\n",
    "|0.33998 10435 84856 |0.65214 51548 62546|\n",
    "|0.86113 63115 94053 | 0.34785 48451 37454|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.12.1  Mapping Integration Points<a id=\"5.12.1\"></a> \n",
    "\n",
    "Our standard convention (5.26) for the general interval \\[*a*, *b*\\] is\n",
    "\n",
    "$$\\tag*{5.57}\n",
    "\\int_{a}^{b} f(x)  dx  \\simeq \\sum_{i=1}^{N} f(x_{i}) w_{i} .$$\n",
    "\n",
    "With Gaussian points and weights, the *y* interval\n",
    "−1 &lt; *y*<sub>*i*</sub> ≤ 1 must be *mapped* onto the *x* interval\n",
    "*a* ≤ *x* ≤ *b*. Here are some mappings we have found useful in our\n",
    "work. In all cases, (*y*<sub>*i*</sub>, *w*<sub>*i*</sub><sup>′</sup>)\n",
    "are the elementary Gaussian points and weights for the interval\n",
    "\\[ − 1, 1\\], and we want to scale to *x* with various ranges.[[xml]](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/xml/5.58.xml)\n",
    "\n",
    "1.  \\[−1,1\\] → \\[*a*,*b*\\] uniformly, (*a* + *b*)/2 = **midpoint:**\n",
    "    $$\\begin{align}\n",
    "    \\tag*{5.58}\n",
    "    x_{i} = \\frac{b+a}{2} + \\frac{b-a}{2}y_{i}, &\n",
    "    w_{i}=  \\frac{b-a}{2} w_{i}^{'},\\\\\n",
    "    \\Rightarrow\\quad   \\int_{a}^{b} f(x)  dx & =\n",
    "    \\frac{b-a}{2}\\int_{-1}^{1} f[x(y)]  dy.\\tag*{5.59}\n",
    "     \\end{align}$$\n",
    "\n",
    "2.  \\[0→∞\\], *a* = **midpoint:**\n",
    "\n",
    "    $$\\tag*{5.60}\n",
    "    x_{i} =  a \\frac{1+y_{i}}{1-y_{i}} ,\\quad w_{i} =\n",
    "    \\frac{2a}{(1-y_{i})^{2}} w_{i}^{'}.$$\n",
    "\n",
    "3.  \\[−∞→∞\\], **scale set by *a*:**\n",
    "\n",
    "    $$\\tag*{5.61}\n",
    "    x_{i} =  a \\frac{y_{i}}{1-y_{i}^{2}} ,\\quad w_{i} =\n",
    "    \\frac{a(1+y_{i}^{2})}{(1-y_{i}^{2})^{2}} w_{i}^{'}.$$\n",
    "\n",
    "4.  \\[*a*→∞\\], *a* + 2*b* = **midpoint:**\n",
    "\n",
    "    $$\\tag*{5.62}\n",
    "    x_{i} =  \\frac{a+2b +ay_{i}} {1-y_{i}} ,\\quad w_{i} =\n",
    "    \\frac{2(b+a)} {(1-y_{i})^{2}} w_{i}^{'} .$$\n",
    "\n",
    "5.  \\[0→*b*\\], *a**b*/(*b* + *a*)=**midpoint:**\n",
    "\n",
    "    $$\\tag*{5.63}\n",
    "    x_{i} =  \\frac{ab(1+y_{i})}{b+a-(b-a)y_{i}} ,\\quad w_{i} =\n",
    "    \\frac{2ab^{2}}{(b+a-(b-a)y_{i})^{2}} w_{i}^{'} .$$\n",
    "\n",
    "    As you can see, even if your integration range extends out to\n",
    "    infinity, there will be points at large but not infinite *x*. As you\n",
    "    keep increasing the number of grid points *N*, the last\n",
    "    *x*<sub>*i*</sub> gets larger but always remains finite.\n",
    "\n",
    "### 5.12.2  Gaussian Points Derivation<a id=\"5.12.2\"></a> \n",
    "\n",
    "We want to perform a numerical integration with *N* integration points:\n",
    "\n",
    "$$\\int_{-1}^{+1}f(x) dx = \\sum_{i=1}^N w_i f(x_i),\\tag*{5.64}$$\n",
    "\n",
    "where *f*(*x*) is a polynomial of degree 2N-1 or less. The unique\n",
    "property of Gaussian quadrature is that (5.64) will be exact, as long as\n",
    "we ignore the effect of round-off error. Determining the\n",
    "*x*<sub>*i*</sub>’s and *w*<sub>*i*</sub>’s requires some knowledge of\n",
    "special functions and some cleverness \n",
    "\\[[Hilderbrand(56)](BiblioLinked.html#hilder)\\]. The knowledge\n",
    "needed is the two properties of Legendre polynomials\n",
    "*P*<sub>*N*</sub>(*x*) of order *N*:\n",
    "\n",
    "1.  *P*<sub>*N*</sub>(*x*) is orthogonal to every polynomial of order\n",
    "    less than *N*.\n",
    "\n",
    "2.  *P*<sub>*N*</sub>(*x*) has *N* real roots in the interval\n",
    "    −1 ≤ *x* ≤ 1.\n",
    "\n",
    "We define now a new polynomial of degree equal to or less than *N*\n",
    "obtained by dividing the integrand *f*(*x*) by the Legendre polynomial\n",
    "*P*<sub>*N*</sub>(*x*):\n",
    "\n",
    "$$\\begin{align} q(x) & = \\frac{f(x)} {P_{N}(x)},\\tag*{5.65}\\\\\n",
    "\\Rightarrow \\quad f(x) & = q(x)P_N(x) + r(x). \\tag*{5.66}\\end{align}$$\n",
    "\n",
    "Here the remainder *r*(*x*) is an (unknown) polynomial of degree *N* or\n",
    "less, which we will not need to determine. If we now substitute (5.66)\n",
    "into (5.64), and use the fact that *P*<sub>*N*</sub> is orthogonal to\n",
    "every polynomial of degree less than or equal to *N*, only the second,\n",
    "*r*(*x*), term remains:\n",
    "\n",
    "$$\\int_{-1}^{+1}f(x) dx = \\int_{-1}^{+1}q(x)P_N(x) dx + \\int_{-1}^{+1}r(x) dx =\n",
    "\\int_{-1}^{+1}r(x) dx.\\tag*{5.67}$$\n",
    "\n",
    "Yet because *r*(*x*) is a polynomial of degree *N* or less, we can use a\n",
    "standard *N* point rule to evaluate the integral exactly (the type of\n",
    "quadrature we did with the Simpson rule).\n",
    "\n",
    "Now that we know it is possible to integrate a 2N-1 or less degree\n",
    "polynomial with just *N* points, we extert some cleverness to determine\n",
    "just what those points will be. We substitute (5.66) into (5.64) and\n",
    "note that\n",
    "\n",
    "$$\\tag*{5.68}\n",
    "\\int_{-1}^{+1}f(x) dx  =\\sum_{i=1}^N w_i  q(x_i)P_N(x_i)  +\\sum_{i=1}^N w_i  r(x_i) =\\sum_{i=1}^N w_i  r(x_i) .$$\n",
    "\n",
    "The cleverness is realizing that if we choose the *N* integration points\n",
    "to be the zeros or roots of the Legendre polynomial\n",
    "*P*<sub>*N*</sub>(*x*), then the first term on the RHS of (5.68) will\n",
    "vanish because *P*<sub>*N*</sub>(*x*<sub>*i*</sub>)=0 for each\n",
    "*x*<sub>*i*</sub>:\n",
    "\n",
    "$$\\tag*{5.69}\n",
    "\\int_{-1}^{+1}f(x) dx  = \\sum_{i=1}^N w_i  r(x_i)   .$$\n",
    "\n",
    "This is our derivation that the *N* integration points over the interval\n",
    "(-1, 1) are the *N* zeros of the Legendre polynomial\n",
    "*P*<sub>*N*</sub>(*x*). As indicated in (5.56), the weights are related\n",
    "to the derivative of the Legendre polynomials evaluated at the roots of\n",
    "the polynomial. The actual derivation of the weights we leave to\n",
    "\\[Hildebrand(56)\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IntegGauss.py, Notebook Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3    3.03164491511e-07\n",
      "   5    2.45470310745e-13\n",
      "   7    4.77395900589e-15\n",
      "   9    3.99680288865e-15\n",
      "   11    1.05471187339e-14\n",
      "   13    2.99760216649e-15\n",
      "   15    3.21964677141e-15\n",
      "   17    4.32986979604e-15\n",
      "   19    5.77315972805e-15\n",
      "   21    6.88338275268e-15\n",
      "   23    7.77156117238e-15\n",
      "   25    7.77156117238e-15\n",
      "   27    7.66053886991e-15\n",
      "   29    8.10462807976e-15\n",
      "   31    6.99440505514e-15\n",
      "   33    7.43849426499e-15\n",
      "   35    7.66053886991e-15\n",
      "   37    6.88338275268e-15\n",
      "   39    6.66133814775e-15\n",
      "   41    5.88418203051e-15\n",
      "   43    5.55111512313e-15\n",
      "   45    5.3290705182e-15\n",
      "   47    4.88498130835e-15\n",
      "   49    2.5202062659e-14\n",
      "   51    2.36477504245e-14\n",
      "   53    2.26485497024e-14\n",
      "   55    2.16493489802e-14\n",
      "   57    1.97619698383e-14\n",
      "   59    1.86517468137e-14\n",
      "   61    1.75415237891e-14\n",
      "   63    1.75415237891e-14\n",
      "   65    1.58761892521e-14\n",
      "   67    1.53210777398e-14\n",
      "   69    1.43218770177e-14\n",
      "   71    1.36557432029e-14\n",
      "   73    1.3211653993e-14\n",
      "   75    1.18793863635e-14\n",
      "   77    1.1768364061e-14\n",
      "   79    1.09912079438e-14\n",
      "   81    1.04360964315e-14\n",
      "   83    1.02140518266e-14\n",
      "   85    9.43689570931e-15\n",
      "   87    9.32587340685e-15\n",
      "   89    9.10382880193e-15\n",
      "   91    8.54871728961e-15\n",
      "   93    8.10462807976e-15\n",
      "   95    7.77156117238e-15\n",
      "   97    7.54951656745e-15\n",
      "   99    7.21644966006e-15\n",
      "   101    7.21644966006e-15\n"
     ]
    }
   ],
   "source": [
    "# IntegGauss.py Gaussian quadrature generates own pts and wts\n",
    "\n",
    "from numpy import *\n",
    "from __future__ import print_function\n",
    "from sys import version\n",
    "\n",
    "if int(version[0])>2:               #raw_input deprecated in Python 3\n",
    "    raw_input=input  \n",
    "max_in = 101                        # Numb intervals\n",
    "vmin = 0.; vmax = 1.                # Int ranges\n",
    "ME = 2.7182818284590452354E0        # Euler's const\n",
    "w = zeros( (2001), float)\n",
    "x = zeros( (2001), float)\n",
    "\n",
    "def f(x):\n",
    "    return (exp( - x) )                                                        # f(x)\n",
    "\n",
    "def gauss(npts, job, a, b, x, w):\n",
    "    m = 0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    t = 0.\n",
    "    t1 = 0.\n",
    "    pp = 0.\n",
    "    p1 = 0.\n",
    "    p2 = 0.\n",
    "    p3 = 0.  \n",
    "    eps = 3.E-14                # Accuracy: ********ADJUST THIS*********!\n",
    "    m =int( (npts + 1)/2 )\n",
    "    for i in range(1, m + 1):\n",
    "        t = cos(math.pi*(float(i) - 0.25)/(float(npts) + 0.5) )\n",
    "        t1 = 1 \n",
    "        while( (abs(t - t1) ) >= eps):\n",
    "            p1 = 1. ;  p2 = 0.  \n",
    "            for j in range(1, npts + 1):\n",
    "                p3 = p2;   p2 = p1 \n",
    "                p1 = ( (2.*float(j) - 1)*t*p2 - (float(j) - 1.)*p3)/(float(j) )\n",
    "            pp = npts*(t*p1 - p2)/(t*t - 1.) \n",
    "            t1 = t; t = t1  -  p1/pp     \n",
    "        x[i - 1] = - t;   x[npts - i] = t \n",
    "        w[i - 1] = 2./( (1. - t*t)*pp*pp) \n",
    "        w[npts - i] = w[i - 1]  \n",
    "    if (job == 0):\n",
    "        for i in range(0, npts):\n",
    "            x[i] = x[i]*(b - a)/2. + (b + a)/2. \n",
    "            w[i] = w[i]*(b - a)/2. \n",
    "    if (job == 1):\n",
    "        for i in range(0, npts):\n",
    "            xi   = x[i]\n",
    "            x[i] = a*b*(1. + xi) / (b + a - (b - a)*xi) \n",
    "            w[i] = w[i]*2.*a*b*b/( (b + a - (b - a)*xi)*(b + a - (b - a)*xi) )\n",
    "    if (job == 2):\n",
    "        for i in range(0, npts):\n",
    "            xi = x[i]\n",
    "            x[i] = (b*xi +  b + a + a) / (1. - xi) \n",
    "            w[i] = w[i]*2.*(a + b)/( (1. - xi)*(1. - xi) )\n",
    "            \n",
    "def gaussint (no, min, max):\n",
    "    quadra = 0.  \n",
    "    gauss (no, 0, min, max, x, w)           # Returns pts & wts\n",
    "    for n in arange(0, no):\n",
    "        quadra   += f(x[n]) * w[n]          # Calculate integral\n",
    "    return (quadra)                   \n",
    "\n",
    "for i in range(3, max_in + 1, 2):\n",
    "    result = gaussint(i, vmin, vmax) \n",
    "    print (\"  \", i, \"  \", abs(result - 1 + 1/ME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.12.3  Integration Error Assessment<a id=\"5.12.3\"></a> \n",
    "\n",
    "|Figure 5.4 A |Figure 5.4 B|\n",
    "|:- - -:|:- - -:|\n",
    "|![image](Figs/Fig5_4a.png)|![image](Figs/Fig5_4b.png)|\n",
    "    \n",
    "**Figure 5.4** Log-log plots of the error in the integration of exponential decay using the trapezoid rule, Simpson’s rule, and Gaussian quadrature <span>*versus*</span> the number of integration points *N*. Approximately 15 decimal places of precision are attainable with double precision (*left*), and 7 places with single precision (*right*). The algorithms are seen to stop converging when round-off error (the fluctuating and increasing part near the bottom) starts to dominate.\n",
    "1.  Write a double-precision program to integrate an arbitrary function\n",
    "    numerically using the trapezoid rule, the Simpson rule, and\n",
    "    Gaussian quadrature. For our assumed **problem** there is an\n",
    "    analytic answer with which to compare:\n",
    "    $$\\tag*{5.70}\n",
    "    \\frac{dN(t) } { dt}  =   e^{-t}\\quad \\Rightarrow\\quad N(1) = \\int_{0}^{1}\n",
    "    e^{-t}  dt = 1- e^{-1}.$$\n",
    "\n",
    "2.  Compute the relative error\n",
    "    *ϵ* = |(*n**u**m**e**r**i**c**a**l* − *e**x**a**c**t*)/*e**x**a**c**t*|\n",
    "    in each case. Present your data in a tabular form with column headers *N*, ϵ*<sub>*T*</sub>,*ϵ*<sub>*S*</sub> and *ϵ*<sub>*G*</sub>. Try *N* values of 2, 10,\n",
    "    20, 40, 80, 160, …. (*Hint*: Even numbers may not be the assumption\n",
    "    of every rule.)\n",
    "\n",
    "3.  Make a log-log plot of relative error *versus* *N* (Figure 5.4). You\n",
    "    should observe that\n",
    "    $$\\begin{align}\n",
    "    \\tag*{5.71}\n",
    "    \\epsilon \\simeq C  N^\\alpha \\quad \\Rightarrow \\quad\n",
    "      \\log\\epsilon =\\alpha\\log N + \\mbox{constant}.\\end{align}$$\n",
    "     This means that a power-law dependence appears as a straight line\n",
    "    on a log-log plot, and that if you use log<sub>10</sub>, then the\n",
    "    ordinate on your log-log plot will be the negative of the number of\n",
    "    decimal places of precision in your calculation.\n",
    "\n",
    "4.  Use your plot or table to estimate the power-law dependence of the\n",
    "    error *ϵ* on the number of points *N*, and to determine the number\n",
    "    of decimal places of precision in your calculation. Do this for both\n",
    "    the trapezoid and Simpson rules and for both the algorithmic and\n",
    "    round-off error regimes. (Note that it may be hard to make *N* large\n",
    "    enough to reach the round-off error regime for the trapezoid rule\n",
    "    because the approximation error is so large.)\n",
    "\n",
    "In Listing 5.2 we give a sample program that performs an integration\n",
    "with Gaussian points. The method `gauss` generates the points and\n",
    "weights and may be useful in other applications as well.\n",
    "\n",
    "[**Listing 5.2  IntegGauss.py**](http://www.science.oregonstate.edu/~rubin/Books/CPbook/Codes/PythonCodes/IntegGauss.py) integrates the function *f*(*x*) via\n",
    "Gaussian quadrature. The points and weights are generated in the method\n",
    "<span>gauss</span>, which remains fixed for all applications. Note that\n",
    "the parameter <span>eps</span>, which controls the level of precision\n",
    "desired, should be set by the user, as should the value for\n",
    "<span>job</span>, which controls the mapping of the Gaussian points onto\n",
    "arbitrary intervals (they are generated for\n",
    "−1 ≤ *x* ≤ 1)\n",
    "\n",
    "## 5.13  Higher-Order Rules (Algorithm)<a id=\"5.13\"></a> \n",
    "\n",
    "As in numerical differentiation, we can use the known functional dependence of\n",
    "the error on interval size *h* to reduce the integration error. For simple rules\n",
    "like the trapezoid and Simpson rules, we have the analytic estimates (5.47),\n",
    "while for others you may have to experiment to determine the *h* dependence.\n",
    "To illustrate, if *A*(*h*) and *A*(*h*/2) are the values of the integral\n",
    "determined for intervals *h* and *h*/2, respectively, and we know that the\n",
    "integrals have expansions with a leading error term proportional to\n",
    "*h*<sup>2</sup>, $$\\begin{align}\n",
    "\\tag*{5.72}\n",
    "A(h) &\\simeq \\int_{a}^{b} f(x) dx + \\alpha h^{2} + \\beta h^{4} +\n",
    "\\cdots ,\\\\\n",
    "A \\left(\\frac{h}{2}\\right) & \\simeq \\int_{a}^{b} f(x) dx +\n",
    "\\frac{\\alpha h^{2}}{4} +\\frac{\\beta h^{4}}{16}  + \\cdots.\\tag*{5.73}\n",
    "   \\end{align}$$\n",
    " Consequently, we make the *h*<sup>2</sup> term vanish by computing the\n",
    "combination\n",
    "\n",
    "$$\\tag*{5.74}\n",
    "\\frac{4}{3}A\\left(\\frac{h}{2}\\right) - \\frac{1}{3}A(h) \\simeq\n",
    " \\int_{a}^{b} f(x) dx - \\frac{\\beta h^{4}}{4} + \\cdots.$$\n",
    "\n",
    "Clearly this particular trick (Romberg’s extrapolation) works only if\n",
    "the *h*<sup>2</sup> term dominates the error and then only if the\n",
    "derivatives of the function are well behaved. An analogous extrapolation\n",
    "can also be made for other algorithms.\n",
    "\n",
    "In Table 5.1 we gave the weights for several equal-interval rules.\n",
    "Whereas the Simpson rule used two intervals, the three-eighths rule uses\n",
    "three, and the Milne rule four \\[*Note:* There is, not coincidentally, a Milne\n",
    "Computer Center at Oregon State University, although there no longer is\n",
    "a central computer there.\\]. These are single-interval rules\n",
    "and must be strung together to obtain a rule *extended* over the entire\n",
    "integration range. This means that the points that end one interval and\n",
    "begin the next are weighted twice. You can easily determine the number\n",
    "of elementary intervals integrated over, and check whether you and we\n",
    "have written the weights right, by summing the weights for any rule. The\n",
    "sum is the integral of *f*(*x*)=1 and must equal *h* times the number of\n",
    "intervals (which in turn equals *b* − *a*):\n",
    "\n",
    "$$\\tag*{5.75}\n",
    "\\sum_{i=1}^{N} w_{i} = h \\times N_{\\textrm intervals} = b-a.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.14  Monte Carlo Integration by Stone Throwing (Problem)<a id=\"5.14\"></a> \n",
    "\n",
    "Imagine yourself as a farmer walking to your furthermost field to add\n",
    "algae-eating fish to a pond having an algae explosion. You get there\n",
    "only to read the instructions and discover that you need to know the\n",
    "area of the pond in order to determine the correct number of the fish to\n",
    "add. Your **problem** is to measure the area of this irregularly shaped\n",
    "pond with just the materials at hand \\[Gould et al.(06)\\].\n",
    "\n",
    "It is hard to believe that Monte Carlo techniques can be used to\n",
    "evaluate integrals. After all, we do not want to gamble on the values!\n",
    "While it is true that other methods are preferable for single and double\n",
    "integrals, it turns out that Monte Carlo techniques are best when the\n",
    "dimensionality of integrations gets large! For our pond problem, we will\n",
    "use a *sampling* technique (Figure 5.5):\n",
    "\n",
    "1.  Walk off a box that completely encloses the pond and remove any\n",
    "    pebbles lying on the ground within the box.\n",
    "\n",
    "2.  Measure the lengths of the sides in natural units like *feet*. This\n",
    "    tells you the area of the enclosing box $A_{\\textrm box}$.\n",
    "\n",
    "3.  Grab a bunch of pebbles, count their number, and then throw them up\n",
    "    in the air in random directions.\n",
    "\n",
    "4. Count the number of splashes in the pond $N_{\\textrm pond}$ and\n",
    "    the number of pebbles lying on the ground within your box\n",
    "    $N_{\\textrm box}$.\n",
    "\n",
    "5.  Assuming that you threw the pebbles uniformly and randomly, the\n",
    "    number of pebbles falling into the pond should be proportional to\n",
    "    the area of the pond $A_{\\textrm pond}$. You determine that area\n",
    "    from the simple ratio\n",
    "\n",
    "    $$\\tag*{5.76}\n",
    "    \\frac{N_{\\textrm pond}}{N_{\\textrm pond}+N_{\\textrm box}} =\n",
    "    \\frac{A_{\\textrm pond}}{A_{\\textrm box}}\\quad \\Rightarrow \\quad A_{\\textrm pond} =\n",
    "    \\frac{N_{\\textrm pond}}{N_{\\textrm pond}+N_{\\textrm box}}   A_{\\textrm box} .$$\n",
    "\n",
    "|A|B|\n",
    "|:- - -:|:- - -:|\n",
    "| ![image](Figs/Fig5_5a.png)|![image](Figs/Fig5_5b.png)|\n",
    "**Figure 5.5** *A:* Throwing stones into a pond as a technique for\n",
    "measuring its area. The ratio of “hits” to total number of stones thrown\n",
    "equals the ratio of the area of the pond to that of the box. *B:* The\n",
    "evaluation of an integral via a Monte Carlo (stone throwing) technique\n",
    "of the ratio of areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.14.1  Stone Throwing Implementation<a id=\"5.14.1\"></a> \n",
    "\n",
    "Use sampling (Figure 5.5) to perform a 2-D integration and thereby\n",
    "determine *π*:\n",
    "\n",
    "1.  Imagine a circular pond enclosed in a square of side 2(*r* = 1).\n",
    "\n",
    "2.  We know the analytic answer that the area of a circle ∮*dA* = *π*.\n",
    "\n",
    "3.  Generate a sequence of random numbers −1 ≤ *r*<sub>*i*</sub> ≤ +1.\n",
    "\n",
    "4.  For *i* = 1 to *N*, pick\n",
    "    (*x*<sub>*i*</sub>, *y*<sub>*i*</sub>)=(*r*<sub>2*i* − 1</sub>, *r*<sub>2*i*</sub>).\n",
    "\n",
    "5.  If\n",
    "    *x*<sub>*i*</sub><sup>2</sup> + *y*<sub>*i*</sub><sup>2</sup> &lt; 1,\n",
    "    let $N_{\\textrm pond} = N_{\\textrm pond} +1$; otherwise let\n",
    "    $N_{\\textrm box} = N_{\\textrm box} +1$.\n",
    "\n",
    "6.  Use (5.76) to calculate the area, and in this way *π*.\n",
    "\n",
    "7.  Increase *N* until you get *π* to three significant figures (we\n",
    "    don’t ask much - - - that’s only slide-rule accuracy).\n",
    "\n",
    "## 5.15  Mean Value Integration (Theory & Math)<a id=\"5.15\"></a> \n",
    "\n",
    "The standard Monte Carlo technique for integration is based on the *mean\n",
    "value theorem* (presumably familiar from elementary calculus):[[xml]](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/xml/5.77.xml)\n",
    "\n",
    "$$\\tag*{5.77} I = \\int_{a}^{b}dx f(x) = (b-a)\\langle f \\rangle .$$\n",
    "\n",
    "The theorem states the obvious if you think of integrals as areas: The\n",
    "value of the integral of some function *f*(*x*) between *a* and *b*\n",
    "equals the length of the interval (*b* − *a*) times the mean value of\n",
    "the function over that interval ⟨*f*⟩ (Figure 5.6). The Monte Carlo\n",
    "integration algorithm uses random points to evaluate the mean in (5.77).\n",
    "With a sequence *a* ≤ *x*<sub>*i*</sub> ≤ *b* of *N* uniform random\n",
    "numbers, we want to determine the *sample mean* by *sampling* the\n",
    "function *f*(*x*) at these points:\n",
    "\n",
    "$$\\tag*{5.78}\n",
    "\\langle f \\rangle \\simeq \\frac{1}{N}\\sum_{i=1}^{N} f(x_{i}).$$\n",
    "\n",
    "![image](Figs/Fig5_6.png) **Figure 5.6** The area under the curve\n",
    "*f*(*x*) is the same as that under the horizontal line whose height\n",
    "*y* = ⟨*f*⟩.\n",
    "\n",
    "This gives us the very simple integration rule:\n",
    "\n",
    "$$\\tag*{5.79}\n",
    "  \\int_{a}^{b} \\ dx \\  f(x) \\simeq\n",
    "(b-a)\\frac{1}{N} \\sum_{i=1}^{N} f(x_{i}) = (b-a) \\langle f\n",
    "\\rangle.$$\n",
    "\n",
    "Equation (5.79) looks much like our standard algorithm for integration\n",
    "(5.26) with the points *x*<sub>*i*</sub> chosen randomly and with\n",
    "uniform weights *w*<sub>*i*</sub> = (*b* − *a*)/*N*. Because no attempt\n",
    "has been made to obtain an optimal answer for a given value of *N*, this\n",
    "does not seem like it would be an efficient means to evaluate integrals;\n",
    "but you must admit it is simple. If we let the number of samples of\n",
    "*f*(*x*) approach infinity *N* → ∞ or if we keep the number of samples\n",
    "finite and take the average of infinitely many runs, the laws of\n",
    "statistics assure us that (5.79) will approach the correct answer, at\n",
    "least if there were no round-off errors.\n",
    "\n",
    "For readers who are familiar with statistics, we remind you that the\n",
    "uncertainty in the value obtained for the integral *I* after *N* samples\n",
    "of *f*(*x*) is measured by the standard deviation *σ*<sub>*I*</sub>. If\n",
    "*σ*<sub>*f*</sub> is the standard deviation of the integrand *f* in the\n",
    "sampling, then for normal distributions we have\n",
    "\n",
    "$$\\sigma_{I} \\simeq \\frac{1}{\\sqrt{N}} \\sigma_{f}.\\tag*{5.80}$$\n",
    "\n",
    "So for large *N*, the error in the value obtained for the integral decreases as\n",
    "$1/\\sqrt{N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PondMatplot.py, Notebook Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PondMatPlot.py: Monte Carlo integration via vonNeumann rejection\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N=100                                            # # points\n",
    "x1=np.arange(0,2*np.pi+2*np.pi/N,2*np.pi/N)      # x values\n",
    "fig,ax=plt.subplots()\n",
    "y1=x1*np.sin(x1)**2                              # integrand\n",
    "ax.plot(x1,y1,'c',lw=4)                          # integrand in cyan\n",
    "ax.set_xlim((0,2*np.pi))                         # limits x axis\n",
    "ax.set_ylim((0,5))                               # for y axis\n",
    "ax.set_xticks([0,np.pi,2*np.pi])                 # set 3 x axis tics\n",
    "ax.set_xticklabels(['0','$\\pi$','2$\\pi$'])       # name 3 tics\n",
    "ax.set_xlabel('x',fontsize=20)\n",
    "ax.set_ylabel('$f(x)=x\\,\\sin^2(x)$',fontsize=20)\n",
    "fig.patch.set_visible(False)\n",
    "xi=[]\n",
    "yi=[]\n",
    "xo=[]\n",
    "yo=[]                                           # Inner & outer pts\n",
    "def fx (x):                                     # integrand\n",
    "    return x*np.sin(x)**2\n",
    "j=0                                             # counter for inside\n",
    "Npts=3000\n",
    "analyt=np.pi**2                                 # analytic answer\n",
    "xx=2.*np.pi*np.random.rand(Npts)                # 0=< x =< 2pi\n",
    "yy=5*np.random.rand(Npts)                       # 0=< y 0< 5\n",
    "for i in range (1,Npts):\n",
    "    if(yy[i]<=fx(xx[i])):                       # below curve\n",
    "        xi.append(xx[i])\n",
    "        yi.append(yy[i])\n",
    "        j+= 1                                   # increase count\n",
    "    else:\n",
    "        xo.append(xx[i])\n",
    "        yo.append(yy[i])\n",
    "boxarea = 2.*np.pi*5                        # Box area\n",
    "area = boxarea*j/(Npts-1)                # area under curve\n",
    "ax.plot(xo,yo,'bo',markersize=3)\n",
    "ax.plot(xi,yi,'ro',markersize=3)\n",
    "ax.set_title('Ans: Analytic = %5.3f, MC =%5.3f'%(analyt,area))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.16  Integration Exercises<a id=\"5.16\"></a> \n",
    "\n",
    "1.  Here are two integrals that quadrature may find challenging:\n",
    "\n",
    "    $$\\tag*{5.81}\n",
    "    F_{1} = \\int_{0}^{2\\pi}\\sin(100x)\\  dx, \\quad F_{2} =\n",
    "    \\int_{0}^{2\\pi}\\sin^{x}(100x) \\ dx.$$\n",
    "\n",
    "    1.  Evaluate these integrals using two different integration rules\n",
    "        and compare the answers.\n",
    "\n",
    "    2.  Explain why the computer may have trouble with these integrals.\n",
    "\n",
    "2.  The next three problems are examples of how *elliptic integrals*\n",
    "    enter into realistic physics problems. It is straight-forward to\n",
    "    evaluate most any integral numerically using the techniques of this\n",
    "    chapter, but it may be difficult for you to know if the answers you\n",
    "    obtain are correct. One way to hone your integral-evaluating skills\n",
    "    is to compare your answers from quadrature to power series\n",
    "    expressions, or to a polynomial approximations of know precision. To\n",
    "    help you in this regard, we present here a polynomial approximation\n",
    "    for an elliptic integral \\[[Abramowitz & Stegun(72)](BiblioLinked.html#AS)\\]:\n",
    "    \n",
    "    $$\\begin{align}\n",
    "    K(m) & = \\int_0^{\\pi/2}(1-m\\sin^2\\theta)^{-1/2} d\\theta \\tag*{5.82}\\\\\n",
    "     & \\simeq a_0+a_1m_1+a_2m_1^2    - [b_0+b_1m_1+b_2m_1^2]\\ln m_1  + \\epsilon(m),\\\\\n",
    "    m_1   &= 1-m, \\quad  0\\leq m\\leq 1, \\quad \\vert\\epsilon(m)\\vert \\leq 3\\times 10^{-5},    \\\\\n",
    "    &\\begin{array}{lll}\n",
    "    a_0 = 1.38629\\  44 & a_1 = 0.11197\\   23 & a_2 = 0.07252\\  96 \\\\\n",
    "    b_0 = 0.5 & b_1 = 0.12134\\  78 & b_2 = 0.02887\\  29 \\\\\n",
    "    \\end{array}.\n",
    "    \\end{align}$$\n",
    "\n",
    "3.  Compute *K*(*m*) by evaluating the integral in (5.82) numerically.\n",
    "    Tune you integral evaluation until you obtain agreement at the\n",
    "    ≤3 × 10<sup>−5</sup> level with the polynomial approximation.\n",
    "\n",
    "4.  In § 15.1.2 we will derive an expression for the period *T* of a\n",
    "    realistic pendulum for which the maximum angle of displacement\n",
    "    *θ*<sub>*m*</sub> is not necessarily small:\n",
    "    $$\\begin{align}\n",
    "      T  & = \\frac{T_0}{\\pi}\n",
    "    \\int_{0}^{\\theta_m}\\frac{d\\theta}{ \\left[\\sin^{2}({\\theta_m}/{2})\n",
    "    - \\sin^{2}({\\theta}/{2})\\right]^{1/2}}   \\tag*{5.83} \\\\\n",
    "     &  \\simeq T_0\\left[1 +\n",
    "    \\left(\\frac{1}{2}\\right)^2 \\sin^{2}\\frac{\\theta_m}{2} + \\left(\\frac{1\\cdot 3}{2\\cdot 4}\\right)^2\n",
    "    \\sin^{4}\\frac{\\theta_m}{2} +  \\cdots \\right],\\tag*{5.84}\\end{align}$$\n",
    "     where *T*<sub>0</sub> is the period for small-angle oscillations.\n",
    "    The integral in (5.84) can be expressed in terms of an elliptic\n",
    "    integral of the first kind. If you think of an elliptic integral as\n",
    "    a generalized trigonometric function, then this is a closed-form\n",
    "    solution; otherwise, it’s an integral needing numerical evaluation.\n",
    "\n",
    "    1.  Use numerical quadrature to determine the ratio\n",
    "        *T*/*T*<sub>0</sub> for five values of *θ*<sub>*m*</sub> between\n",
    "        0 and *π*. Show that you have attained at least four places of\n",
    "        accuracy by progressively increasing the number of integration\n",
    "        points until changes occur only in the fifth place, or beyond.\n",
    "\n",
    "    2.  Use the power series (5.84) to determine the ratio\n",
    "        *T*/*T*<sub>0</sub>. Continue summing terms until changes in the\n",
    "        sum occur only in the fifth place, or beyond.\n",
    "\n",
    "    3.  Plot the values you obtain for *T*/*T*<sub>0</sub> *versus*\n",
    "        *θ*<sub>*m*</sub> for both the integral and power\n",
    "        series solution. Note that any departure from 1 indicates\n",
    "        breakdown of the familiar small-angle approximation for\n",
    "        the pendulum.\n",
    "\n",
    "5.  In the classic E&M text \\[[Jackson(88)](BiblioLinked.html#jackson)\\], there is the problem of an\n",
    "    infinite, grounded, thin, plane sheet of conducting material with a\n",
    "    hole of radius *a* cut in it. The hole contains a conducting disc of\n",
    "    slightly smaller radius kept at potential *V* and separated from the\n",
    "    sheet by a thin ring of insulating material. Jackson solves for the\n",
    "    potential a perpendicular distance *z* above the *edge* of the disk\n",
    "    in terms of an elliptic integral:\n",
    "\n",
    "    $$\\tag*{5.85}\n",
    "    \\Phi(z)=\\frac{V}{2}\\left( 1 -\\frac{kz}{\\pi a}\\int_0^{\\pi/2} \\frac{d\\phi}{\\sqrt{1-k^2\\sin^2 \\phi}}\\right),$$\n",
    "\n",
    "    where *k* = 2*a*/(*z*<sup>2</sup> + 4*a*<sup>2</sup>)<sup>1/2</sup>.\n",
    "    Use numerical integration to calculate and then plot the potential\n",
    "    for *V* = 1, *a* = 1 and values of *z* in the interval (0.05, 10).\n",
    "    Compare to a 1/*r* fall off.\n",
    "\n",
    "    ![image](Figs/Fig5_7.png)**Figure 5.7** A ring of radius a carries a\n",
    "    current I. Find vector potential at point P.\n",
    "\n",
    "6.  Figure 5.7 shows a current loop of radius *a* carrying a current\n",
    "    *I*. The point *P* is a distance *r* from the center of the loop\n",
    "    with spherical coordinates (*r*, *θ*, *ϕ*). \\[Jackson(88)\\]\n",
    "    solves for the *ϕ* component of the vector potential at point *P* in\n",
    "    terms of elliptic integrals:\n",
    "    \n",
    "    $$\\begin{align}\n",
    "    \\tag*{5.86}\n",
    "    A_\\phi(r,\\theta) & = \\frac{\\mu_0}{4\\pi}\\frac{4Ia}{\\sqrt{a^2+r^2+2ar\\sin \\theta}}\n",
    "    \\left[ \\frac{(2-k^2)K(k)-2E(k)}{k^2} \\right], \\\\\n",
    "    K(k)& =  \\int_0^{\\pi/2} \\frac{d\\phi}{\\sqrt{1-k^2\\sin^2 \\phi}},\\quad\n",
    "    E(k)  =  \\int_0^{\\pi/2} \\sqrt{1-k^2\\sin^2 \\phi} d\\phi,\\tag*{5.87}\\\\\n",
    "    k^2 & = \\frac{4ar \\sin \\theta}{a^2+r^2+2ar\\sin \\theta}.\\tag*{5.88}\\end{align}$$\n",
    "     \n",
    "     Here *K*(*k*) is a complete elliptic integral of the first kind and\n",
    "    *E*(*k*) is a complete elliptic integral of the second kind. For\n",
    "    *a* = 1, *I* = 3 and *μ*<sub>0</sub>/4*π* = 1, compute and plot\n",
    "\n",
    "    1.  *A*<sub>*ϕ*</sub>(*r* = 1.1, *θ*) *versus* *θ*.\n",
    "\n",
    "    2.  *A*<sub>*ϕ*</sub>(*r*, *θ* = *π*/3) *versus* *r*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.17  Multidimensional Monte Carlo Integration (Problem)<a id=\"5.17\"></a> \n",
    "\n",
    "Let’s say that we want to calculate some properties of a small atom such\n",
    "as magnesium with 12 electrons. To do that we need to integrate atomic\n",
    "wave functions over the three coordinates of each of 12 electrons. This\n",
    "amounts to a 3 × 12 = 36−*D* integral. If we use 64 points for each\n",
    "integration, this requires about 64<sup>36</sup> ≃ 10<sup>65</sup>\n",
    "evaluations of the integrand. If the computer were fast and could\n",
    "evaluate the integrand a million times per second, this would take about\n",
    "10<sup>59</sup>*s*, which is significantly longer than the age of the\n",
    "universe ( ∼ 10<sup>17</sup>*s*).\n",
    "\n",
    "Your **problem** is to find a way to perform multidimensional\n",
    "integrations so that you are still alive to savor the results.\n",
    "Specifically, evaluate the 10-D integral\n",
    "\n",
    "$$\\tag*{5.89} I = \\int_{0}^{1} dx_{1}\\int_{0}^{1} dx_{2} \\cdots\n",
    "\\int_{0}^{1} dx_{10} \\left(x_{1} + x_{2} + \\cdots + x_{10}\\right)^{2}.$$\n",
    "\n",
    "Check your numerical answer against the analytic one, $\\frac{155}{6}$.\n",
    "\n",
    "It is easy to generalize mean value integration to many dimensions by\n",
    "picking random points in a multidimensional space. For example, in 2-D:\n",
    "\n",
    "$$\\tag*{5.90}\n",
    "\\int_{a}^{b} dx \\int_{c}^{d} dy   f(x,y)\n",
    "\\simeq(b-a)(d-c)\\frac{1}{N} \\sum_{i}^{N} f(\\textbf{x}_{i}) =\n",
    "(b-a)(d-c)\\langle f \\rangle.\\quad$$\n",
    "\n",
    "### 5.17.1  Multi Dimension Integration Error Assessment<a id=\"5.17.1\"></a> \n",
    "\n",
    "When we perform a multidimensional integration, the relative error in the\n",
    "Monte Carlo technique, being statistical, decreases as $1/\\sqrt{N}$. This is valid\n",
    "even if the *N* points are distributed over *D* dimensions. In contrast, when\n",
    "we use these same *N* points to perform a *D*-dimensional integration as *D*\n",
    "separate 1-D integrals using a rule such as Simpson’s, we use *N*/*D* points for\n",
    "each integration. For fixed *N*, this means that the number of points used for\n",
    "each integration decreases as the number of dimensions *D* increases, and so\n",
    "the error in each integration *increases* with *D*. Furthermore, the total error\n",
    "will be approximately *N* times the error in each integral. If you put these\n",
    "trends together and do the analysis for a particular integration rule, you will find\n",
    "that at a value of *D* ≃ 3−4 the error in Monte Carlo integration is\n",
    "approximately equal to that of conventional schemes. For larger values of *D*,\n",
    "the Monte Carlo method is always more accurate!\n",
    "\n",
    "### 5.17.2  Implementation: 10-D Monte Carlo Integration<a id=\"5.17.2\"></a> \n",
    "\n",
    "Use a built-in random-number generator to perform the 10-D Monte Carlo\n",
    "integration in (5.89).\n",
    "\n",
    "1.  Conduct 16 trials and take the average as your answer.\n",
    "\n",
    "2.  Try sample sizes of *N* = 2, 4, 8, …, 8192.\n",
    "\n",
    "3. Plot the relative error *versus* $1/\\sqrt{N}$ and see if linear\n",
    "    behavior occurs.\n",
    "\n",
    "4.  What is your estimate for the accuracy of the integration?\n",
    "\n",
    "5.  Show that for a dimension *D* ≃ 3−4, the error in multidimensional\n",
    "    Monte Carlo integration is approximately equal to that of\n",
    "    conventional schemes, and that for larger values of *D*, the Monte\n",
    "    Carlo method is more accurate.\n",
    "\n",
    "## 5.18  Integrating Rapidly Varying Functions (Problem)<a id=\"5.18\"></a> \n",
    "\n",
    "It is common in many physical applications to integrate a function with\n",
    "an approximately Gaussian dependence on *x*. The rapid falloff of the\n",
    "integrand means that our Monte Carlo integration technique would require\n",
    "an incredibly large number of points to place sufficient points where\n",
    "the integrand is large. Your **problem** is to make Monte Carlo\n",
    "integration more efficient for rapidly varying integrands.\n",
    "\n",
    "## 5.19  Variance Reduction (Method)<a id=\"5.19\"></a> \n",
    "\n",
    "If the function being integrated never differs much from its average\n",
    "value, then the standard Monte Carlo mean value method (5.79) should\n",
    "work well with a large, but manageable, number of points. Yet for a\n",
    "function with a large *variance* (i.e., one that is not “flat”), many of\n",
    "the evaluations of the function may occur for *x* values at which the\n",
    "function is very small, and thus makes an insignificant contribution to\n",
    "the integral; this is, basically, a waste of time. The method can be\n",
    "improved by mapping the function *f* into a different function *g* that\n",
    "has a smaller variance over the interval. We indicate two methods here\n",
    "and refer you to \\[[Press et al.(94)](BiblioLinked.html#press)\\] and \\[[Koonin(86)](BiblioLinked.html#koonin)\\] for more\n",
    "details.\n",
    "\n",
    "The first method is a *variance reduction* or *subtraction technique* in\n",
    "which we devise a flatter function on which to apply the Monte Carlo\n",
    "technique. Suppose we construct a function *g*(*x*) with the following\n",
    "properties on \\[*a*, *b*\\]:\n",
    "\n",
    "$$\\tag*{5.91} | f(x) - g(x) | \\leq \\epsilon , \\quad \\int_{a}^{b}dx\\ g(x) = J.$$\n",
    "\n",
    "We now evaluate the integral of the difference *f*(*x*)−*g*(*x*) and add\n",
    "the result to *J* to obtain the required integral\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{5.92}\n",
    "\\int_{a}^{b}dx  f(x) = \\int_{a}^{b}dx \\left [f(x) - g(x)\\right] +\n",
    "J.\n",
    "   \\end{align}$$\n",
    "\n",
    "If we are clever enough to find a simple *g*(*x*) that makes the\n",
    "variance of *f*(*x*)−*g*(*x*) less than that of *f*(*x*), and that we\n",
    "can integrate analytically, we can obtain even more accurate answers in\n",
    "less time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.20  Importance Sampling (Method)<a id=\"5.20\"></a> \n",
    "\n",
    "A second method for improving Monte Carlo integration is called\n",
    "*importance sampling* because samples the integrand in the most\n",
    "important regions. It derives from the identity\n",
    "\n",
    "$$\\tag*{5.93} I = \\int_{a}^{b} dx\\ f(x) = \\int_{a}^{b} dx w(x)\n",
    "\\frac{f(x)}{w(x)}.$$\n",
    "\n",
    "If we now use a *probability distribution* for our random numbers that\n",
    "includes *x*(*x*), the integral can be approximated as\n",
    "\n",
    "$$\\tag*{5.94} I = \\left\\langle \\frac{f}{w} \\right\\rangle \\simeq\\frac{1}{N}\n",
    "\\sum_{i=1}^{N}\n",
    "\\frac{f(x_{i})}{w(x_{i})}.$$\n",
    "\n",
    "The improvement arising from (5.94) is that with a judicious choice of\n",
    "weighting function *w*(*x*)∝*f*(*x*), we can make *f*(*x*)/*w*(*x*) more\n",
    "constant and thus easier to integrate accurately.\n",
    "\n",
    "![image](Figs/Fig5_8.png) **Figure 5.8** The von Neumann rejection\n",
    "technique for generating random points with weight W(x). A random point\n",
    "is accepted if it lies below the curve of W(x) and rejected if it lies\n",
    "above. This generates a random distribution weighted by whatever W(x)\n",
    "function is plotted.\n",
    "\n",
    "## 5.21  Von Neumann Rejection (Method)<a id=\"5.21\"></a> \n",
    "\n",
    "A simple and ingenious method for generating random points with a\n",
    "probability distribution *w*(*x*) was deduced by von Neumann, and is\n",
    "implemented in Listing 5.3. This method is essentially the same as the\n",
    "rejection or sampling method used to guess the area of a pond, only now\n",
    "the pond has been replaced by the weighting function *w*(*x*), and the\n",
    "arbitrary box around the lake by the arbitrary constant *W*<sub>0</sub>.\n",
    "Imagine a graph of *w*(*x*) *versus* *x* (Figure 5.8). Walk off your box\n",
    "by placing the line *W* = *W*<sub>0</sub> on the graph, with the only\n",
    "condition being *W*<sub>0</sub> ≥ *w*(*x*). We next “throw stones” at\n",
    "this graph and count only those splashes that fall into the *w*(*x*)\n",
    "pond. That is, we generate uniform distributions in *x* and *y* ≡ *W*\n",
    "with the maximum *y* value equal to the width of the box\n",
    "*W*<sub>0</sub>:\n",
    "\n",
    "$$\\tag*{5.95} (x_{i}, W_{i}) = (r_{2i-1}, W_{0}r_{2i}).$$\n",
    "\n",
    "We then reject all *x*<sub>*i*</sub> that do not fall into the pond:\n",
    "\n",
    "$$\\tag*{5.96}\n",
    "\\mbox{If} \\ W_{i} \\lt w(x_{i}),  \\ \\mbox{accept}, \\quad\n",
    "  \\mbox{If} \\ W_{i} \\gt w(x_{i}),\\  \\mbox{reject}.$$\n",
    "\n",
    "The *x*<sub>*i*</sub> values so accepted will have the weighting\n",
    "*w*(*x*) (Figure 5.8). The largest acceptance occurs where *w*(*x*) is\n",
    "large, in this case for midrange *x*. In [Chapter 17, *Thermodynamic\n",
    "Simulations & Feynman Quantum Path Integrals*](CP17.ipynb), we apply a\n",
    "variation of the rejection technique known as the *Metropolis\n",
    "algorithm*. This algorithm has now become the cornerstone of computation\n",
    "thermodynamics.\n",
    "\n",
    "[**Listing 5.3  vonNeuman.py**](http://www.science.oregonstate.edu/~rubin/Books/CPbook/Codes/PythonCodes/vonNeuman.py) uses vonNeuman rejection to generate a\n",
    "weighted random distribution of\n",
    "numbers.\n",
    "\n",
    "### 5.21.1  Simple Random Gaussian Distribution<a id=\"5.21.1\"></a> \n",
    "\n",
    "The central limit theorem can be used to deduce a Gaussian distribution\n",
    "via a simple <span> </span> summation. The theorem states, under rather\n",
    "general conditions, that if {*r*<sub>*i*</sub>} is a sequence of\n",
    "mutually independent random numbers, then the sum\n",
    "\n",
    "$$x_{N} = \\sum_{i=1}^{N} r_{i}\\tag*{5.97}$$\n",
    "\n",
    "is distributed normally. This means that the generated *x* values have\n",
    "the distribution\n",
    "\n",
    "$$\\tag*{5.98} P_{N}(x)=\n",
    "\\frac{\\exp\\left[-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right]} {\\sqrt{2\\pi\n",
    "\\sigma^{2}}}, \\quad \\mu = N\\langle r\\rangle,\n",
    "\\enspace\\sigma^{2} = N (\\langle r^{2}\\rangle - \\langle\n",
    "r\\rangle^{2}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.22  Nonuniform Assessment ⊙<a id=\"5.22\"></a> \n",
    "\n",
    "Use the von Neumann rejection technique to generate a normal\n",
    "distribution of standard deviation 1 and compare it to the simple\n",
    "Gaussian method.\n",
    "\n",
    "### 5.22.1  Implementation⊙<a id=\"5.22.1\"></a> \n",
    "\n",
    "In order for *w*(*x*) to be the weighting function for random numbers\n",
    "over \\[*a*, *b*\\], we want it to have the properties\n",
    "\n",
    "$$\\tag*{5.99}\n",
    "\\int_{a}^{b} dx  w(x) = 1, \\quad [w(x) \\gt; 0], \\quad\n",
    "d {\\mathcal{P}} (x \\rightarrow x + dx) = w(x) dx ,$$\n",
    "\n",
    "where $d{\\cal P}$ is the probability of obtaining an *x* in the range\n",
    "*x* → *x* + *d**x*. For the uniform distribution over \\[*a*, *b*\\],\n",
    "*w*(*x*)=1/(*b* − *a*).\n",
    "\n",
    "Inverse transform/change of variable method ⊙:\n",
    " Let us consider a change of variables that takes our original integral\n",
    "*I* (5.93) to the form\n",
    "\n",
    "$$\\tag*{5.100} I = \\int_a^b dx f(x) = \\int_{0}^{1} dW\n",
    "\\frac{f[x(W)]}{w[x(W)]}.$$\n",
    "\n",
    "Our aim is to make this transformation such that there are equal\n",
    "contributions from all parts of the range in *W*; that is, we want to\n",
    "use a uniform sequence of random numbers for *W*. To determine the new\n",
    "variable, we start with *u*(*r*), the uniform distribution over\n",
    "\\[0, 1\\],\n",
    "\n",
    "$$\\tag*{5.101}\n",
    "    u(r) =\\begin{cases}\n",
    "    1, & \\mbox{for }  0 \\leq r \\leq 1,\\\\\n",
    "    0, & \\mbox{otherwise}.\n",
    "    \\end{cases}$$\n",
    "\n",
    "We want to find a mapping *r* ↔ *x* or probability function *w*(*x*) for\n",
    "which probability is conserved:\n",
    "\n",
    "$$\\tag*{5.102} w(x) dx = u(r) dr, \\quad \\Rightarrow \\quad w(x) = \\left|\n",
    "\\frac{dr}{dx}\\right| u(r).$$\n",
    "\n",
    "This means that even though *x* and *r* are related by some (possibly)\n",
    "complicated mapping, *x* is also random with the probability of *x*\n",
    "lying in *x* → *x* + *d**x* equal to that of *r* lying in\n",
    "*r* → *r* + *d**r*.\n",
    "\n",
    "To find the mapping between *x* and *r* (the tricky part), we change\n",
    "variables to *W*(*x*) defined by the integral\n",
    "\n",
    "$$\\tag*{5.103} W(x) = \\int_{-\\infty}^{x} dx' w(x').$$\n",
    "\n",
    "We recognize *W*(*x*) as the (incomplete) integral of the probability density\n",
    "*u*(*r*) up to some point *x*. It is another type of distribution function, the\n",
    "integrated probability of finding a random number less than the value *x*. The\n",
    "function *W*(*x*) is on that account called a *cumulative distribution function*\n",
    "and can also be thought of as the area to the left of *r* = *x* on the plot of\n",
    "*u*(*r*) *versus* *r*. It follows immediately from the definition (5.103) that\n",
    "*W*(*x*) has the properties \n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{5.104}\n",
    "W(-\\infty) & = 0; \\quad W(\\infty) = 1, \\\\\n",
    "\\frac{dW(x)}{dx} & =  w(x), \\quad  dW(x) = w(x) dx = u(r) dr.\\tag*{5.105}\n",
    "   \\end{align}$$\n",
    "   \n",
    " Consequently, *W*<sub>*i*</sub> = {*r*<sub>*i*</sub>} is a uniform\n",
    "sequence of random numbers, and we just need to invert (5.103) to obtain\n",
    "*x* values distributed with probability *w*(*x*).\n",
    "\n",
    "The crux of this technique is being able to invert (5.103) to obtain\n",
    "*x* = *W*<sup>−1</sup>(*r*). Let us look at some analytic examples to\n",
    "get a feel for these steps (numerical inversion is possible and frequent\n",
    "in realistic cases).\n",
    "\n",
    "Uniform weight function *w*:\n",
    " We start with the familiar uniform distribution\n",
    "\n",
    "$$\\tag*{5.106} w(x) =\\begin{cases}\n",
    "\\frac{1}{b-a}, & \\mbox{if }  a \\leq x \\leq b ,\\\\\n",
    "0, & \\mbox{otherwise}.\\end{cases}$$\n",
    "\n",
    "After following the rules, this leads to\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{5.107}\n",
    "W(x) & = \\int_{a}^{x}dx' \\frac{1}{b-a} = \\frac{x-a}{b-a}\\\\\n",
    "\\Rightarrow\\quad x & =  a + (b-a)W\\quad \\Rightarrow\\quad  W^{-1}(r)  = a +\n",
    "(b-a)r,\\tag*{5.108}\n",
    "   \\end{align}$$\n",
    "\n",
    "where *W*(*x*) is always taken as uniform. In this way we generate\n",
    "uniform random 0 ≤ *r* ≤ 1 and uniform random *a* ≤ *x* ≤ *b*.\n",
    "\n",
    "Exponential weight:\n",
    "We want random points with an exponential distribution:\n",
    "\n",
    "$$\\begin{align} w(x) & =\\begin{cases}\n",
    " \\frac{1}{\\lambda} e^{-x/\\lambda}, & \\mbox{for } x &gt; 0,\\\\\n",
    "    0, & \\mbox{for } x &lt; 0,\n",
    "    \\end{cases}\\\\\n",
    "\\quad  W(x) &\\ =\\   \\int_{0}^{x}dx'\\frac{1}{\\lambda} e^{-x'/\\lambda} = 1\n",
    "- e^{-x/\\lambda}, \\tag*{5.109}\\\\\n",
    "\\Rightarrow\\quad x & = -\\lambda \\ln (1-W) \\equiv -\\lambda \\ln\n",
    "(1-r).\\tag*{5.110}\n",
    "   \\end{align}$$\n",
    "\n",
    "In this way we generate uniform random *r*: \\[0, 1\\] and obtain\n",
    "*x* = −*λ*ln(1 − *r*) distributed with an exponential probability\n",
    "distribution for *x* &gt; 0. Notice that our prescription (5.93)\n",
    "and (5.94) tells us to use *w*(*x*)=*e*<sup>−*x*/*λ*</sup>/*λ* to remove\n",
    "the exponential-like behavior from an integrand and place it in the\n",
    "weights and scaled points (0 ≤ *x*<sub>*i*</sub> ≤ ∞). Because the\n",
    "resulting integrand will vary less, it may be approximated better as a\n",
    "polynomial:\n",
    "\n",
    "$$\\tag*{5.111}\n",
    "\\int_{0}^{\\infty}dx  e^{-x/\\lambda} f(x) \\simeq\n",
    "\\frac{\\lambda}{N}\\sum_{i=1}^{N} f(x_{i}),\\quad\n",
    "    x_{i} = -\\lambda \\ln (1-r_{i}).$$\n",
    "\n",
    "Gaussian (normal) distribution:\n",
    "We want to generate points with a normal distribution:\n",
    "\n",
    "$$\\tag*{5.112} w(x') = \\frac{1}{\\sqrt{2\\pi} \\sigma}\n",
    "e^{-(x'-\\overline{x})^{2}/2\\sigma^{2}}.$$\n",
    "\n",
    "This by itself is rather hard but is made easier by generating uniform\n",
    "distributions in angles and then using trigonometric relations to convert them to\n",
    "a Gaussian distribution. But before doing that, we keep things simple by\n",
    "realizing that we can obtain (5.112) with mean $\\overline{x}$ and standard\n",
    "deviation *σ* by scaling and a translation of a simpler *w*(*x*):\n",
    "\n",
    "$$\\tag*{5.113} w(x)= \\frac{1}{{\\sqrt{2\\pi}}} e^{-x^2/2} ,\\quad x' = \\sigma x +\n",
    "\\overline{x}.$$\n",
    "\n",
    "We start by generalizing the statement of probability conservation for\n",
    "two different distributions (5.102) to two dimensions \\[Press et\n",
    "al.(94)\\]:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tag*{5.114}\n",
    "p(x,y) dx dy &\\ =\\ u(r_1,r_2) dr_1 dr_2\\\\\n",
    " \\Rightarrow\\quad p(x,y)\n",
    " &\\ =\\   u(r_1,r_2)\\left|  \\frac{\\partial (r_1,r_2)} {\\partial\n",
    "(x,y)}\\right|.\\tag*{5.115}\n",
    "   \\end{align}$$\n",
    "\n",
    "We recognize the term in vertical bars as the Jacobian determinant:\n",
    "\n",
    "$$\\tag*{5.116} J = \\left| \\frac{\\partial(r_1,r_2)} {\\partial(x,y)} \\right| =\n",
    "\\frac{\\partial r_1} {\\partial x} \\frac{\\partial r_2}{\\partial y} -\n",
    "\\frac{\\partial r_2}{\\partial x} \\frac{\\partial r_1}{\\partial y}.$$\n",
    "\n",
    "To specialize to a Gaussian distribution, we consider 2*π**r* as angles\n",
    "obtained from a uniform random distribution *r*, and *x* and *y* as\n",
    "Cartesian coordinates that will have a Gaussian distribution. The two\n",
    "are related by\n",
    "\n",
    "$$\\tag*{5.117} x = \\sqrt{-2 \\ln r_1} \\cos2\\pi r_2 , \\quad y = \\sqrt{-2 \\ln\n",
    "r_1}\\sin2\\pi r_2.$$\n",
    "\n",
    "The inversion of this mapping produces the Gaussian distribution\n",
    "\n",
    "$$\\tag*{5.118} r_1 = e^{-(x^2+y^2)/2}, \\quad r_2 = \\frac{1}{ 2\\pi} \\tan^{-1}\n",
    "\\frac{y} { x}, \\quad J =-  \\frac{e^{-(x^2+y^2)/2} } { 2\\pi}.$$\n",
    "\n",
    "The solution to our prob lem is at hand. We use (5.117) with\n",
    "*r*<sub>1</sub> and *r*<sub>2</sub> uniform random distributions, and\n",
    "*x* and *y* are then Gaussian random distributions centered around\n",
    "*x* = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
